Page,Text,Confidence,Definition Label
6,"The framework allows users to zoom in on specific risks that are typical of AI, such as bias, explainability and robustness",Medium,definition
6,Support risk assessment: Provide the basis for related work to develop a risk assessment framework to help with de-risking and mitigation and to develop a common framework for reporting about AI incidents that facilitates global consistency and interoperability in incident reporting,High,
6,"Support risk management: Help inform related work on mitigation, compliance and enforcement along the AI system lifecycle, including as it pertains to corporate governance",High,
6,Each one has its own properties and attributes or sub-dimensions relevant to assessing policy considerations of particular AI systems,Low,definition
page,text,confidence,definition
19,"People & Planet are at the centre of the framework. This dimension considers the potential of AI actors to develop applied AI systems that promote human-centric, trustworthy AI that benefits people and planet",low,definition
21,AI actors are those who play an active role throughout the AI system lifecycle and can include organisations and individuals that deploy or operate AI,medium,definition
22,System operators who plan and design and operate and monitor AI systems; Data collectors and processors who collect and process data; Developers and modellers who build and use models and verify and validate them; System integrators who deploy AI systems,high,definition
24,"The framework provides a structured way to assess AI systems' potential to promote the development of human-centric, trustworthy AI as set out in the OECD AI Principles, i.e. AI systems that benefit people and planet; uphold human rights, democratic values and fairness; are transparent and explainable; are robust, secure and safe; and whose operators are accountable",medium,
25,"Human rights provide a set of universal minimum standards based on, among others, values of human dignity, autonomy and equality, in line with the rule of law",medium,definition
26,Users can range in competency from AI experts to amateur end-users,high,definition
26,"The following stakeholders may be impacted directly or indirectly, and consciously or unconsciously by the AI system: Workers/employees, Consumers, Business, Government agencies/regulators, Scientists/researchers, Children or other vulnerable or marginalised groups",high,
26,Optionality can be understood as the extent to which users can opt out of the effects or the influence of the AI system,medium,definition
26,Users cannot opt out of the AI system's output; Users can opt out of the AI system's output; Users can challenge or correct the AI system's output; Users can reverse the AI system's output ex-post,high,
26-27,"Some AI systems generate outputs that can impact individuals' human rights, either negatively or positively",medium,
27,Having humans in the loop of certain AI system processes and/or a human appeal process are important to reducing risk,high,
27,"Risk-assessment frameworks would usually also include the likelihood the risk will occur, its impact and mitigation measures",high,
27,"Such high-stakes situations often require formal transparency and accountability mechanisms, including transparency about the role of AI and human involvement in the process (e.g. human-in-the-loop), the full consequences of the AI system's action on all stakeholders and the availability of appeals processes",high,
27,AI-based outcomes should not be the only decisive factor when applications or decisions have a significant impact on people's lives,high,
27,the GDPR stipulates that a human must be in the loop if a decision has legal or similarly significant effects on people,high,
27,"Many AI systems use human data as inputs and generate outputs that can impact individuals' and societies' well-being, either positively or negatively",medium,
Page,Text,Confidence Level,
32,"Critical functions are economic and social activities for which the interruption or disruption would have serious consequences. They include: 1) the health, safety, and security of citizens; 2) the effective functioning of services essential to the economy and society, and of the government; or 3) economic and social prosperity more broadly",Low,definition
33,"Operating and monitoring an AI system involves continuously assessing its recommendations and impacts (both intended and unintended) in light of the system's objectives as well as the ethical considerations that go into its operation. In this phase, problems are identified and adjustments made by reverting to other phases or, if necessary, retiring an AI system from production",High,
34,"Transparent, accessible information about the AI system's objectives and assumptions: Provide interested stakeholders with access to useful information",High,
34,Performance monitoring mechanisms: Such as metrics to assess the performance and accuracy of the AI system,High,
34,"Tools or processes for developing or maintaining trustworthy AI: Using tools like guidelines; governance frameworks; product development or lifecycle tools including for model robustness; risk management frameworks; sector-specific codes of conduct; process standards; technical validation approaches; technical documentation; technical standards; toolkits, toolboxes or software tools; educational material; change-management processes; certification (technical and/or process-related); or tools for protection against adverse attacks",High,
34,"Key actors in the Economic Context dimension are often AI system operators who plan and design the AI system and, following deployment, operate and monitor it. System operators relate to accountability; transparency and explainability; and safety, security and robustness",Medium,definition
38,Identified data: Data that can be unambiguously associated with a specific person because they contain personal identifiable information,Medium,definition
38,"Pseudonymised data: Data for which all personal identifiers are substituted by aliases. The alias assignment is such that it cannot be reversed by reasonable efforts, except for the party that performed the assignment",Medium,definition
38,"Unlinked pseudonymised data: Data for which all personal identifiers are irreversibly erased or substituted by aliases. The linkage cannot be re-established by reasonable efforts, including by the party that performed the assignment",Medium,definition
38,Data identifiability can help assess the level of risk to privacy and inform the need for legal and technical protection and access control,High,
39,"Anonymised data: Data that are not linked to attributes that can be altered (i.e. attributes' values are randomised or generalised) in such a way that there is a reasonable level of confidence that a person cannot be identified, directly or indirectly, by the data alone or in combination with other data",Medium,definition
39,"Data appropriateness: Data are appropriate for the purpose for which they are to be used, following standard practice in the industry sector",High,
39,Sample representativeness: Selected variables and training or evaluation data accurately depict/reflect the population in the AI system environment,High,
39,"Adequate sample size: Sample size displays an appropriate level of granularity, coverage and sufficiency of data",High,
39,"Completeness and coherence of sample: Sample is complete, with minimal missing or partial values. Outliers must not affect the quality of data",High,
39,"Low data noise: Data is infrequently incorrect, corrupted or distorted",High,
39,"Data appropriateness impacts the accuracy and reliability of the outcome of AI systems and relates to their robustness, security and safety",High,
39,The use of inappropriate data/input in an AI system can lead to erroneous and possibly dangerous conclusions,Medium,
39,"Data quality has important policy implications for human rights and fairness, as well as to the robustness and safety of an AI system: from both fairness and robustness perspectives, datasets must be inclusive, diverse and representative so they do not misrepresent specific (sub) groups",High,
41,"Standardisation of data formats facilitates interoperability and data re-use across applications and for accessibility, and can help ensure that data are findable, catalogued, searchable and re-usable. The use of standardised formats may improve an AI system's robustness and security by making it easier to address security vulnerabilities","medium, definition",
41,Performing checks: For data quality and appropriateness.,high,
41,Transparent information about the data and inputs used in the AI system: Providing interested stakeholders with access to meaningful information on the data and inputs used in the AI system.,high,
41,Labelling data: Such as tagging data with informative data.,medium,
41,Protecting personal data.,high,
41,Documenting data and dataset characteristics.,high,
41,"Using tools or processes for trustworthy AI: Such as guidelines, governance frameworks, product development/lifecycle tools, risk management, sector-specific codes of conduct, process standards, technical validation approaches, technical documentation, technical standards, toolkits/toolboxes/software tools, educational material, change-management processes, and certification",high,
43,"It is important to note that AI models can be built to achieve a specific set of objectives but then used with different objectives, as in the case of transfer learning","low, definition",
43,"Is it clear what the objectives of the AI system are, i.e. is it possible to formalise the problem that the system is being asked to solve?",high,
43,Does the AI system provide useful and meaningful information for understanding its performance and outputs/decisions?,high,
43,Can all of the AI system's outputs – both intermediary and final – for achieving a given goal be explained?,high,
43,Can the determinant data or knowledge that an AI system uses to make decisions be identified?,high,
43,"Do two similar-looking cases verifiably result in similar outcomes, i.e. can the consistency and integrity of AI system outcomes be verified?",high,
43,Do safety metrics exist that can evaluate the safety of an AI system for a given use case?,high,
43,How does the entity deploying the AI system test for safety during development?,high,
43,"What measures has the entity deploying the AI system taken to do an adversarial evaluation – that is, explore the AI system through the lens of being a ""bad actor"" and trying to break it?",high,
43,Does the AI system change significantly if it is trained with variations of the data available?,high,
43,Are there measures in place to validate and verify the AI system's outcomes?,high,
43,"What measures are in place to facilitate traceability in the AI system, including in relation to datasets, processes and decisions made during the AI system lifecycle?",high,
47,"Model evolution and model drift (where a model degrades because of changes in data, input or output) are directly relevant to safety, security and robustness as well as accountability and liability","medium, definition",
47,"There may be a trade-off between the adaptive nature of an AI system (i.e. whether the model evolves in the field based on input from its environment) and the quality of its outcomes. This trade-off may be more acute with real-time data, as more conflicting data may arrive faster, creating a further risk of compromising the quality of the outcomes","medium, definition",
48,"Understanding how an AI system's model was developed and/or maintained is a key consideration for assigning roles and responsibilities throughout a risk-management process. It is also relevant to assessing the system's robustness, security and safety as well as accountability",high,
48,"Model verification and validation involves data scientists, data/model/systems engineers and governance experts","medium, definition",
48,"Verification and validation to execute and tune models, including metrics to authorise the system for broader deployment",high,
48,"Federated learning helps to address critical issues like privacy, data security and data access rights by building models without sharing data","medium, definition",
49,"When it comes to testing to assess performance across various dimensions and considerations, characteristics of the team of AI system developers – such as gender, country, cultural background – have been shown to impact the way AI systems are built, as developers can incorporate unconscious biases",medium,
49,"Make stakeholders aware of their interactions with AI systems, including in the workplace",high,
49,Enable those affected by an AI system to understand and challenge the outcome and how it was produced by the AI model,high,
50,"For policy purposes, understanding the purpose of an AI system is important for identifying the necessary level of human oversight, the explainability needed, and the extent of testing required",medium,
50,"Model-building and interpretation involve the creation or selection of models/algorithms, their calibration and/or training and inferencing (use). It also involves verification and validation, whereby models are executed and tuned (maximising performance) with tests to assess performance across various dimensions and considerations","medium, definition",