1_Compliance with this Regulation should be enforceable by means of the imposition of penalties and other enforcement measures. Member States should take all necessary measures to ensure that the provisions of this Regulation are implemented_GV.PO-01_GV.RR-02_GV.OV-03_Medium
1_When assessing the amount of the fines, Member States should, in each individual case, take into account all relevant circumstances of the specific situation, with due regard in particular to the nature, gravity and duration of the infringement and of its consequences and to the size of the provider_GV.RM-06_GV.OV-03_ID.RA-05_High
3_Affected persons should have the right to obtain an explanation where a deployer's decision is based mainly upon the output from certain high-risk AI systems that fall within the scope of this Regulation and where that decision produces legal effects or similarly significantly affects those persons_GV.OC-03_GV.PO-01_RS.CO-03_transparency_High
3_Persons acting as whistleblowers on the infringements of this Regulation should be protected under the Union law_GV.RR-04_GV.OC-03_RS.CO-02_High
16_'recall of an AI system' means any measure aiming to achieve the return to the provider or taking out of service or disabling the use of an AI system made available to deployers_ID.AM-08_PR.PS-02; PR.PS-03_RS.MI-02_Medium
19_'notifying authority' means the national authority responsible for setting up and carrying out the necessary procedures for the assessment, designation and notification of conformity assessment bodies and for their monitoring_GV.RR-02_GV.OV-01_GV.SC-02_Low
20_'conformity assessment' means the process of demonstrating whether the requirements set out in Chapter III, Section 2 relating to a high-risk AI system have been fulfilled_ID.RA-01_GV.OC-03_ID.IM-01_Low
21_'conformity assessment body' means a body that performs third-party conformity assessment activities, including testing, certification and inspection_GV.SC-02_ID.RA-09_GV.OC-02_Low
27_'AI literacy' means skills, knowledge and understanding that allow providers, deployers and affected persons to make an informed deployment of AI systems, as well as to gain awareness about the opportunities and risks of AI and possible harm it can cause_PR.AT-01; PR.AT-02_ID.RA-05_GV.OC-02_High
31_The placing on the market, the putting into service or the use of an AI system that deploys subliminal techniques beyond a person's consciousness or purposefully manipulative or deceptive techniques is prohibited_GV.PO-01_ID.RA-03_RS.MI-01_High
33_The placing on the market, the putting into service or the use of AI systems that create or expand facial recognition databases through the untargeted scraping of facial images from the internet or CCTV footage is prohibited_GV.PO-01_PR.DS-01_ID.RA-03_privacy_High
36_The use of 'real-time' remote biometric identification system in publicly accessible spaces shall be authorised only if the law enforcement authority has completed a fundamental rights impact assessment and has registered the system in the EU database_ID.RA-05_GV.OC-03_ID.AM-02_privacy_High
41_The estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose, and under conditions of reasonably foreseeable misuse_ID.RA-04_ID.RA-05_GV.RM-06_High
44_The extent to which persons who are potentially harmed or suffer an adverse impact are dependent on the outcome produced with an AI system_ID.RA-05_GV.OC-02_ID.RA-04_Medium
47_High-risk AI systems shall comply with the requirements laid down in this Section, taking into account their intended purpose as well as the generally acknowledged state of the art_GV.PO-01_ID.RA-09_GV.OC-03_High
48_A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems_GV.RM-01_ID.RA-05_ID.IM-04_High
48_Where a product contains an AI system, providers shall be responsible for ensuring that their product is fully compliant with all applicable requirements under applicable Union harmonisation legislation_GV.RR-02_GV.OC-03_ID.AM-08_High
49_The risk management system shall be understood as a continuous iterative process planned and run throughout the entire lifecycle of a high-risk AI system, requiring regular systematic review and updating_GV.RM-02_ID.IM-01_ID.AM-08_High
49_The identification and analysis of the known and the reasonably foreseeable risks that the high-risk AI system can pose to health, safety or fundamental rights_ID.RA-03_ID.RA-04_GV.RM-06_High
49_The evaluation of other risks possibly arising, based on the analysis of data gathered from the post-market monitoring system_ID.RA-05_DE.AE-02_ID.RA-04_High
49_The adoption of appropriate and targeted risk management measures designed to address the risks identified_GV.RM-04_ID.RA-06_GV.RM-02_High
50_The risk management measures shall give due consideration to the effects and possible interaction resulting from the combined application of the requirements_ID.RA-05_GV.RM-06_ID.RA-04_High
50_Elimination or reduction of risks identified and evaluated through adequate design and development of the high-risk AI system_ID.RA-06_PR.PS-06_ID.IM-01_High
50_Where appropriate, implementation of adequate mitigation and control measures addressing risks that cannot be eliminated_ID.RA-06_RS.MI-01_GV.RM-04_High
50_Provision of information required and, where appropriate, training to deployers_PR.AT-01; PR.AT-02_GV.SC-02_RS.CO-03_Medium