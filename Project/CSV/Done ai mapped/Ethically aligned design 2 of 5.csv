page_text_First proposal_Second proposal_Third proposal_labels_confidence_definitions

60_The responsibility for the behavior of algorithms remains with the designer, the user, and a set of well-designed guidelines that guarantee the importance of human autonomy in any interaction_GV.RR-02_GV.PO-01_PR.AT-01_accountability_High_

61_The effect of human mobility on state systems reliant on A/IS impacts the State structure itself, and thus the systems that the structure relies on, in the end influencing everything from democracy to citizenship. Where the State, through A/IS, invests in and gathers big data through mechanisms for registration and identification of people, mainly immigrants, human mobility becomes a foundational component in a system geared toward the preservation of human dignity_GV.OC-03_ID.AM-07_ID.RA-03_privacy_Medium_

65_A machine can follow simple rules. Rule-based systems can be implemented as formal systems, also referred to as 'axiomatic systems', and in the case of machine ethics, a set of rules is used to determine which actions are morally allowable and which are not_PR.PS-01_GV.PO-01_ID.RA-01__Medium_definition

65_Since it is not possible to cover every situation by a rule, an inference engine is used to deduce new rules from a small set of simple rules called axioms by combining them. The morality of a machine comprises the set of rules that is deducible from the axioms_ID.RA-04_PR.PS-06___Low_definition

65_Formal systems have an advantage since properties such as decidability and consistency of a system can be effectively examined. If a formal system is decidable, every rule is either morally allowable or not, and the 'unknown' is eliminated. If the formal system is consistent, one can be sure that no two rules can be deduced that contradict each other_ID.RA-05_GV.RM-06___Medium_

71_Common indicators of well-being include satisfaction with life, healthy life expectancy, economic standard of living, trust in government, social support, perceived freedom to make life decisions, income equality, access to education, and poverty rates_GV.OC-02_GV.RM-01___Low_definition

74_A/IS creators should protect human dignity, autonomy, rights, and well-being of those directly and indirectly affected by the technology. As part of this effort, it is important to include multiple stakeholders, minorities, marginalized groups, and those often without power or a voice in consultation_GV.RR-01; GV.OC-02_GV.SC-02___High_

74_Policymakers, regulators, monitors, and researchers should consider issuing guidance on areas such as A/IS labor and the proper role of humans vs. A/IS in work transparency, trust, and explainability; manipulation and deception; and other areas that emerge_GV.OV-01_GV.PO-02_GV.RM-04_transparency_High_

74_Ongoing literature review and analysis should be performed by research and other communities to curate and aggregate information on positive and negative A/IS impacts, along with demonstrated approaches to realize positive ones and ameliorate negative ones_ID.IM-01_ID.IM-02_GV.OV-02__High_

75_A/IS may deceive and harm humans by posing as humans. With the increased ability of artificial systems to meet the Turing test, an intelligence test for a computer that allows a human to distinguish human intelligence from artificial intelligence, there is a significant risk that unscrupulous operators will abuse the technology for unethical commercial or outright criminal purposes_ID.RA-03_ID.RA-04___Medium_definition

76_A/IS should not be designed to deceive, befriend, bond with, influence, control, or manipulate their human users, particularly when users are unaware of the deception designed into the system_PR.AA-01_GV.PO-01_GV.RR-02_transparency_High_

96_Commercially marketed A/IS should not be persons in a legal sense, nor marketed as persons. Rather their artifactual (authored, designed, and built deliberately) nature should always be made as transparent as possible, at least at point of sale and in available documentation_GV.OC-03_GV.PO-01__transparency_High_

96_For deception to be used under any circumstance, a logical and reasonable justification must be provided by the designer, and this rationale should be certified by an external authority, such as a licensing body or regulatory agency_GV.RR-02_GV.OV-03__transparency_High_

99_Design features of an affective system that nudges human beings should include the ability to accurately distinguish between users, including detecting characteristics such as whether the user is an adult or a child_PR.AA-02_PR.AA-03_PR.DS-01__High_

102_It is important that human workers' interaction with other workers not always be intermediated by affective systems (or other technology) which may filter out autonomy, innovation, and communication_GV.RR-02_PR.AT-01___High_

102_Human points of contact should remain available to customers and other organizations when using A/IS_GV.OC-04_GV.RR-02___High_

102_Even where A/IS are less expensive, more predictable, and easier to control than human employees, a core network of human employees should be maintained at every level of decision-making in order to ensure preservation of human autonomy, communication, and innovation_GV.RR-01_GV.RR-03___High_

110_Individuals may provide consent without fully understanding specific terms and conditions agreements. But they are also not equipped to fully recognize how the nuanced use of their data to inform personalized algorithms affects their choices at the risk of eroding their agency_PR.DS-01_PR.AT-01_GV.OC-02_transparency; privacy_Medium_

111_The scope of how long one should or could control the downstream use of their data can be difficult to calculate as consent-based models of personal data have trained users to release rights on any claims for use of their data which are entirely provided to the service, manufacturer, and their partners_PR.DS-01_PR.DS-02_ID.AM-07_data protection_Medium_

112_Terms should be presented in a way that allows a user to easily read, interpret, understand, and choose to engage with any A/IS. Consent should be both conditional and dynamic, where 'dynamic' means downstream uses of a person's data must be explicitly called out, allowing them to cancel a service and potentially rescind or 'kill' any data they have shared with a service to date via the use of a 'Smart Contract' or specific conditions as described in mutual terms and conditions between two parties at the time of exchange_PR.DS-01; PR.DS-02_GV.OC-02_PR.AA-02_transparency; privacy_High_

113_Under current business models, it is common for people to consent to the sharing of discrete data like credit card transaction data, answers to test questions, or how many steps they walk. However, once aggregated these data and the associated insights may lead to complex and sensitive conclusions being drawn about individuals. This end use of the individual's data may not have been part of the initial sharing agreement_PR.DS-01_ID.RA-04_GV.OC-03_privacy_Medium_

115_For purposes of privacy, a person must be able to set up complex permissions that reflect a variety of wishes_PR.AA-05_PR.DS-01_PR.DS-02_privacy_High_

115_The agent should help a person foresee and mitigate potential ethical implications of specific machine learning data exchanges_ID.RA-04_ID.RA-05_GV.RM-01__High_

118_Educational data offer a unique opportunity to model individuals' thought processes and could be used to predict or change individuals' behavior in many situations. Governments and organizations should classify educational data as being sensitive and implement special protective standards_PR.DS-01_ID.AM-07_PR.DS-02_data protection_High_

118_Children's data should be held in 'escrow' and not used for any commercial purposes until a child reaches the age of majority and is able to authorize use as they choose_PR.DS-01_PR.AA-02_GV.OC-03_data protection; privacy_High_