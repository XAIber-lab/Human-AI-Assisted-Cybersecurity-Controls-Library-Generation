page_text_First proposal_Second proposal_Third proposal_labels_confidence_definition
3;"ensure that Europeans can benefit from new technologies developed and functioning according to Union values, fundamental rights and principles"_GV.RR-01_GV.PO-01_GV.OC-03__Medium_No
3;"Following the publication of the White Paper, the Commission launched a broad stakeholder consultation, which was met with a great interest by a large number of stakeholders who were largely supportive of regulatory intervention to address the challenges and concerns raised by the increasing use of AI"_GV.OC-02_GV.RM-01__Low_Yes
3;"rules for AI available in the Union market or otherwise affecting people in the Union should therefore be human centric, so that people can trust that the technology is used in a way that is safe and compliant with the law, including the respect of fundamental rights"_GV.OC-03_GV.PO-01_GV.RR-01_transparency_High_No
3;"protect ethical principles"_GV.RR-01_GV.PO-01___High_No
3;"promote the uptake of AI and of addressing the risks associated with certain uses of such technology"_ID.RA-05_GV.RM-01___Medium_No
4;"ensure legal certainty to facilitate investment and innovation in AI"_GV.RM-01_GV.OC-01___Medium_No
4;"enhance governance and effective enforcement of existing law on fundamental rights and safety requirements applicable to AI systems"_GV.OV-03_GV.PO-02___High_No
4;"facilitate the development of a single market for lawful, safe and trustworthy AI applications and prevent market fragmentation"_GV.SC-01_GV.RM-01___Medium_No
4;"a balanced and proportionate horizontal regulatory approach to AI that is limited to the minimum necessary requirements to address the risks and problems linked to AI"_ID.RA-05; ID.RA-06_GV.RM-02___High_No
4;"flexible mechanisms that enable it to be dynamically adapted as the technology evolves and new concerning situations emerge"_GV.PO-02_ID.IM-01___High_No
5;"The use of AI systems for real-time remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons"_ID.RA-05_GV.OC-03__privacy_High_Yes
11;"Ex-post enforcement should ensure that once the AI system has been put on the market, public authorities have the powers and resources to intervene in case AI systems generate unexpected risks"_DE.CM-09_RS.MA-01_ID.RA-06__High_No
11;"monitor compliance of operators with their relevant obligations under the regulation"_DE.CM-03_GV.OV-03___High_No
11;"Market surveillance authorities would also control the market and investigate compliance with the obligations and requirements for all high-risk AI systems"_DE.CM-09_RS.AN-03___High_No
11;"monitoring and reporting obligations for providers of AI systems with regard to post-market monitoring and reporting and investigating on AI-related incidents and malfunctioning"_DE.CM-09_RS.CO-03_RS.AN-07__High_No
13;"AI systems that pose significant risks to the health and safety or fundamental rights of persons shall comply with mandatory requirements and follow conformity assessment procedures"_ID.RA-05_GV.PO-01___High_Yes
13;"obligations for testing, risk management, documentation and human oversight throughout the AI systems' lifecycle"_ID.AM-08_PR.PS-06_ID.RA-06__High_No
13;"register those stand-alone high-risk AI systems in an EU database for public transparency and oversight"_ID.AM-02_GV.OV-03__transparency_High_No
13;"sets out the legal requirements for high-risk AI systems in relation to data and data governance, documentation and recording keeping, transparency and provision of information to users, human oversight, robustness, accuracy and security"_PR.DS-01; PR.DS-02_PR.PS-01_GV.PO-01_data protection; transparency_High_No
14;"a solid quality management system, ensure the accomplishment of the required conformity assessment procedure based on technical documentation"_PR.PS-01_ID.AM-08_GV.SC-09__High_No
14;"For high-risk AI systems, the requirements of high quality data, documentation and traceability, transparency, human oversight, accuracy and robustness"_PR.DS-01_ID.AM-08_PR.PS-04_data protection; transparency_High_No
14;"classification of an AI system as high-risk is based on the intended purpose of the AI system"_ID.RA-05_ID.AM-05___Medium_Yes
14;"properly documented ex ante compliance with all requirements and compliance with robust quality and risk management systems"_PR.PS-01_GV.SC-09_ID.RA-06__High_No
14;"New ex ante re-assessments of the conformity will be needed in case of substantial modifications to the AI systems"_ID.RA-07_PR.PS-01___High_No
14;"providers shall put a quality management system in place that ensures compliance with this Regulation"_PR.PS-01_GV.SC-09___High_No
14;"Member States shall establish adequate testing facilities to provide independent evaluation"_PR.PS-06_ID.IM-02___High_No
15;"research for legitimate purposes should follow recognised ethical standards for scientific research"_GV.RR-01_PR.AT-02___High_No
20;"Standards should be consistent with fundamental rights and be non-discriminatory"_GV.PO-01_GV.OC-03___High_No
20;"practices that contradict Union values of respect for human dignity, freedom, equality, democracy and the rule of law should be prohibited"_GV.RR-01_GV.PO-01_GV.OC-03__High_No
