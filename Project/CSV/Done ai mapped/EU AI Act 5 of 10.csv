page_text_First proposal_Second proposal_Third proposal_labels_confidence_definitions
1_High-risk AI systems shall be tested for the purpose of identifying the most appropriate and targeted risk management measures. Testing shall ensure that high-risk AI systems perform consistently for their intended purpose and that they are in compliance with the requirements set out in this Section_ID_RA-01_ID_IM-02_ID_RA-05__high_
1_Testing procedures may include testing in real-world conditions in accordance with Article 60_ID_IM-02_ID_RA-01___medium_
1_The testing of high-risk AI systems shall be performed, as appropriate, at any time throughout the development process, and, in any event, prior to their being placed on the market or put into service. Testing shall be carried out against prior defined metrics and probabilistic thresholds that are appropriate to the intended purpose of the high-risk AI system_ID_IM-02_ID_RA-09_PR_PS-06__high_
1_With a view to eliminating or reducing risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, the training to be expected by the deployer, and the presumable context in which the system is intended to be used_PR_AT-01; PR_AT-02_ID_RA-05_GV_RR-04__high_
2_Training, validation and testing data sets shall be subject to data governance and management practices appropriate for the intended purpose of the high-risk AI system_PR_DS-01_ID_AM-07_GV_PO-01_data protection_high_
2_providers shall give consideration to whether in view of its intended purpose the high-risk AI system is likely to have an adverse impact on persons under the age of 18 and, as appropriate, other vulnerable groups_ID_RA-05_GV_OC-02_GV_RM-01__high_
3_relevant data-preparation processing operations, such as annotation, labelling, cleaning, updating, enrichment and aggregation_ID_AM-07_PR_DS-01___medium_definition
3_examination in view of possible biases that are likely to affect the health and safety of persons, have a negative impact on fundamental rights or lead to discrimination prohibited under Union law, especially where data outputs influence inputs for future operations_ID_RA-05_GV_OC-03_ID_RA-04__high_
3_appropriate measures to detect, prevent and mitigate possible biases identified according to point (f)_ID_RA-01_ID_RA-06_PR_DS-01__high_
3_the identification of relevant data gaps or shortcomings that prevent compliance with this Regulation, and how those gaps and shortcomings can be addressed_ID_RA-01_ID_IM-01_ID_IM-03__high_
4_Training, validation and testing data sets shall be relevant, sufficiently representative, and to the best extent possible, free of errors and complete in view of the intended purpose_PR_DS-01_ID_AM-07__data protection_high_
4_Data sets shall take into account, to the extent required by the intended purpose, the characteristics or elements that are particular to the specific geographical, contextual, behavioural or functional setting within which the high-risk AI system is intended to be used_ID_AM-07_GV_OC-01___high_
5_the special categories of personal data are subject to technical limitations on the re-use of the personal data, and state-of-the-art security and privacy-preserving measures, including pseudonymisation_PR_DS-01_PR_DS-02_PR_AA-05_privacy_high_
5_the special categories of personal data are subject to measures to ensure that the personal data processed are secured, protected, subject to suitable safeguards, including strict controls and documentation of the access, to avoid misuse and ensure that only authorised persons have access to those personal data with appropriate confidentiality obligations_PR_DS-01_PR_AA-05_PR_AA-01_privacy_high_
5_the special categories of personal data are not to be transmitted, transferred or otherwise accessed by other parties_PR_DS-02_PR_AA-05_PR_DS-01_privacy_high_
5_the special categories of personal data are deleted once the bias has been corrected or the personal data has reached the end of its retention period, whichever comes first_PR_DS-01_ID_AM-08___high_
12_High-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which they are in use_GV_RR-02_PR_AT-01___high_
12_Human oversight shall aim to prevent or minimise the risks to health, safety or fundamental rights that may emerge when a high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse_ID_RA-05_GV_OV-03___high_
13_to properly understand the relevant capacities and limitations of the high-risk AI system and be able to duly monitor its operation, including in view of detecting and addressing anomalies, dysfunctions and unexpected performance_PR_AT-02_DE_CM-09_DE_AE-02__high_
13_to remain aware of the possible tendency of automatically relying or over-relying on the output produced by a high-risk AI system (automation bias), in particular for high-risk AI systems used to provide information or recommendations for decisions to be taken by natural persons_PR_AT-01_PR_AT-02___high_
13_to correctly interpret the high-risk AI system's output, taking into account, for example, the interpretation tools and methods available_PR_AT-02_PR_AT-01___high_
13_to decide, in any particular situation, not to use the high-risk AI system or to otherwise disregard, override or reverse the output of the high-risk AI system_GV_RR-02_PR_AT-02___high_
13_to intervene in the operation of the high-risk AI system or interrupt the system through a 'stop' button or a similar procedure that allows the system to come to a halt in a safe state_PR_IR-03_PR_AT-02___high_
15_High-risk AI systems shall be designed and developed in such a way that they achieve an appropriate level of accuracy, robustness, and cybersecurity, and that they perform consistently in those respects throughout their lifecycle_PR_IR-03_ID_AM-08_PR_PS-06__high_
15_High-risk AI systems shall be as resilient as possible regarding errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems_PR_IR-03_PR_PS-06___high_
15_High-risk AI systems that continue to learn after being placed on the market or put into service shall be developed in such a way as to eliminate or reduce as far as possible the risk of possibly biased outputs influencing input for future operations (feedback loops), and as to ensure that any such feedback loops are duly addressed with appropriate mitigation measures_ID_RA-01_PR_PS-06_ID_RA-06__high_
16_High-risk AI systems shall be resilient against attempts by unauthorised third parties to alter their use, outputs or performance by exploiting system vulnerabilities_PR_IR-01_PR_PS-01___high_
16_The technical solutions aiming to ensure the cybersecurity of high-risk AI systems shall be appropriate to the relevant circumstances and the risks_PR_IR-01_ID_RA-05___high_
16_The technical solutions to address AI specific vulnerabilities shall include, where appropriate, measures to prevent, detect, respond to, resolve and control for attacks trying to manipulate the training data set (data poisoning), or pre-trained components used in training (model poisoning), inputs designed to cause the AI model to make a mistake (adversarial examples or model evasion), confidentiality attacks or model flaws_PR_IR-01_ID_RA-01_DE_CM-09__high_
19_The provider shall put a quality management system in place that ensures compliance with this Regulation. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions_GV_PO-01_ID_IM-03___high_
19_techniques, procedures and systematic actions to be used for the development, quality control and quality assurance of the high-risk AI system_ID_IM-03_PR_PS-06___high_
20_examination, test and validation procedures to be carried out before, during and after the development of the high-risk AI system, and the frequency with which they have to be carried out_ID_IM-02_ID_RA-01___high_
20_systems and procedures for data management, including data acquisition, data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data_PR_DS-01_ID_AM-07_ID_AM-08__high_
20_the setting-up, implementation and maintenance of a post-market monitoring system_DE_CM-09_ID_IM-03___high_
20_procedures related to the reporting of a serious incident_RS_CO-02_RS_CO-03___high_
22_SMEs, including start-ups, may provide the elements of the technical documentation specified in Annex IV in a simplified manner. To that end, the Commission shall establish a simplified technical documentation form targeted at the needs of small and microenterprises_GV_OC-02_GV_PO-01___medium_
24_High-risk AI systems shall keep the logs automatically generated by that high-risk AI system, to the extent such logs are under their control, for a period appropriate to the intended purpose of the high-risk AI system, of at least six months, unless provided otherwise in applicable Union or national law, in particular in Union law on the protection of personal data_PR_PS-04_ID_AM-07___high_
36_Deployers shall assign human oversight to natural persons who have the necessary competence, training and authority, as well as the necessary support_GV_RR-02_PR_AT-02___high_
37_Without prejudice to paragraphs 1 and 2, to the extent the deployer exercises control over the input data, that deployer shall ensure that input data is relevant and sufficiently representative in view of the intended purpose of the high-risk AI system_PR_DS-01_ID_AM-07___high_
38_Deployers shall monitor the operation of the high-risk AI system on the basis of the instructions for use and, where relevant, inform providers in accordance with Article 72_DE_CM-09_RS_CO-03___high_
39_Before putting into service or using a high-risk AI system at the workplace, deployers who are employers shall inform workers' representatives and the affected workers that they will be subject to the use of the high-risk AI system_GV_OC-02_RS_CO-02___high_
41_In no case shall such high-risk AI system for post-remote biometric identification be used for law enforcement purposes in an untargeted way, without any link to a criminal offence, a criminal proceeding, a genuine and present or genuine and foreseeable threat of a criminal offence, or the search for a specific missing person_GV_PO-01_GV_OC-03___high_