page_text_First proposal_Second proposal_Third proposal_labels_confidence_definitions
2_Take appropriate measures throughout the development of advanced AI systems, including prior to and throughout their deployment and placement on the market, to identify, evaluate, and mitigate risks across the AI lifecycle_ID.RA-05; ID.RA-06_GV.RM-01_GV.SC-01__high_
2_This includes employing diverse internal and independent external testing measures, through a combination of methods such as red-teaming, and implementing appropriate mitigation to address identified risks and vulnerabilities_ID.RA-01; ID.RA-09_ID.IM-02_PR.DS-01__high_
2_developers should seek to enable traceability, in relation to datasets, processes, and decisions made during system development_ID.AM-08_PR.DS-01_GV.SC-09__medium_
2_Organizations should use, as and when appropriate commensurate to the level of risk, AI systems as intended and monitor for vulnerabilities, incidents, emerging risks and misuse after deployment, and take appropriate action to address these_DE.CM-09_ID.RA-07_RS.MI-01__high_
3_consider, for example, facilitating third-party and user discovery and reporting of issues and vulnerabilities after deployment_ID.RA-08_RS.CO-02_RS.CO-03__high_
3_Organizations are further encouraged to maintain appropriate documentation of reported incidents and to mitigate the identified risks and vulnerabilities, in collaboration with other stakeholders_RS.AN-06; RS.AN-07_ID.RA-07_RS.CO-03__high_
3_Mechanisms to report vulnerabilities, where appropriate, should be accessible to a diverse set of stakeholders_RS.CO-02; RS.CO-03_ID.RA-08___medium_
3_Publicly report advanced AI systems' capabilities, limitations and domains of appropriate and inappropriate use, to support ensuring sufficient transparency, thereby contributing to increase accountability_GV.OC-02_GV.PO-01_GV.OV-03_transparency_high_
3_This should include publishing transparency reports containing meaningful information for all new significant releases of advanced AI systems_GV.OC-02_RS.CO-03__transparency_high_
3_Organizations should make the information in the transparency reports sufficiently clear and understandable to enable deployers and users as appropriate and relevant to interpret the model/system's output and to enable users to use it appropriately_GV.OC-02_PR.AT-01_GV.RR-02_transparency_high_
3_Work towards responsible information sharing and reporting of incidents among organizations developing advanced AI systems including with industry, governments, civil society, and academia_RS.CO-03_GV.OC-02_GV.SC-02__high_
3_This includes responsibly sharing information, as appropriate, including, but not limited to evaluation reports, information on security and safety risks, dangerous intended or unintended capabilities, and attempts by AI actors to circumvent safeguards across the AI lifecycle_RS.CO-03_ID.RA-02_DE.AE-07__high_
3_Develop, implement and disclose AI governance and risk management policies, grounded in a risk-based approach â€“ including privacy policies, and mitigation measures, in particular for organizations developing advanced AI systems_GV.PO-01; GV.PO-02_GV.RM-01_GV.RM-02_privacy_high_
3_This includes disclosing where appropriate privacy policies, including for personal data, user prompts and advanced AI system outputs_GV.PO-01_PR.DS-01__privacy_high_
3_Organizations are expected to establish and disclose their AI governance policies and organizational mechanisms to implement these policies in accordance with a risk-based approach_GV.PO-01; GV.PO-02_GV.RM-01___high_
4_Invest in and implement robust security controls, including physical security, cybersecurity and insider threat safeguards across the AI lifecycle_PR.AA-05; PR.AA-06_PR.PS-01_PR.IR-01__high_
4_These may include securing model weights and algorithms, servers, and datasets, such as through operational security measures for information security and appropriate cyber/physical access controls_PR.DS-01; PR.DS-02_PR.AA-05_PR.PS-01__high_
4_Develop and deploy reliable content authentication and provenance mechanisms, where technically feasible, such as watermarking or other techniques to enable users to identify AI-generated content_ID.AM-08_PR.DS-01; PR.DS-02___high_
4_This includes, where appropriate and technically feasible, content authentication such provenance mechanisms for content created with an organization's advanced AI system_PR.DS-01_ID.AM-08___medium_
4_The provenance data should include an identifier of the service or model that created the content, but need not include user information_ID.AM-08_PR.DS-01___medium_definition
4_Organizations should also endeavor to develop tools or APIs to allow users to determine if particular content was created with their advanced AI system such as via watermarks_PR.DS-01_ID.AM-08_GV.OC-02__high_
4_Organizations are further encouraged to implement other mechanisms such as labeling or disclaimers to enable users, where possible and appropriate, to know when they are interacting with an AI system_GV.OC-02_PR.AT-01__transparency_high_
4_Prioritize research to mitigate societal, safety and security risks and prioritize investment in effective mitigation measures_ID.IM-01; ID.IM-02_GV.RM-01_ID.RA-06__high_
4_This includes conducting, collaborating on and investing in research that supports the advancement of AI safety, security and trust, and addressing key risks, as well as investing in developing appropriate mitigation tools_ID.IM-01; ID.IM-02_GV.RM-01_RS.MI-01__high_
5_Organizations should prioritize responsible stewardship of trustworthy and human-centric AI and also support digital literacy initiatives_GV.RR-01_PR.AT-01___medium_
5_Advance the development of and, where appropriate, adoption of international technical standards_GV.PO-01_GV.SC-01___medium_
5_This includes contributing to the development and, where appropriate, use of international technical standards and best practices, including for watermarking, and working with Standards Development Organizations_GV.PO-01_GV.SC-01_ID.IM-01__medium_
5_Implement appropriate data input measures and protections for personal data and intellectual property_PR.DS-01; PR.DS-02_PR.DS-10__data protection; privacy_high_
5_Organizations are encouraged to take appropriate measures to manage data quality, including training data and data collection, to mitigate against harmful biases_PR.DS-01_ID.AM-07_ID.IM-01_data protection_high_
5_Appropriate transparency of training datasets should also be supported and organizations should comply with applicable legal frameworks_GV.OC-03_PR.DS-01__transparency; data protection_high_
2_Organizations should not develop or deploy advanced AI systems in a way that undermines democratic values, are particularly harmful to individuals or communities, facilitate terrorism, enable criminal misuse, or pose substantial risks to safety, security, and human rights, and are thus not acceptable_GV.PO-01_GV.OC-03_GV.RR-01__high_
2_While harnessing the opportunities of innovation, organizations should respect the rule of law, human rights, due process, diversity, fairness and non-discrimination, democracy, and human-centricity, in the design, development and deployment of advanced AI systems_GV.OC-03_GV.RR-01_GV.PO-01__high_
2_States must abide by their obligations under international human rights law to promote that human rights are fully respected and protected, while private sector activities should be in line with international frameworks such as the United Nations Guiding Principles on Business and Human Rights and the OECD Guidelines for Multinational Enterprises_GV.OC-03_GV.PO-01___high_
2_Identify and mitigate vulnerabilities, and, where appropriate, incidents and patterns of misuse, after deployment including placement on the market_ID.RA-01_ID.RA-07_RS.MI-01__high_
3_transparency reporting should be supported and informed by robust documentation processes_GV.OC-02_RS.AN-06__transparency_medium_
3_This should include accountability and governance processes to evaluate and mitigate risks, where feasible throughout the AI lifecycle_GV.RM-01; GV.RM-02_ID.RA-05_GV.OV-03__high_
4_addressing key risks, as well as investing in developing appropriate mitigation tools_ID.RA-06_RS.MI-01___medium_
4_Prioritize the development of advanced AI systems to address the world's greatest challenges, notably but not limited to the climate crisis, global health and education_GV.OC-01_GV.RM-07___low_definition
1_We call on organizations in consultation with other relevant stakeholders to follow these actions, in line with a risk-based approach, while governments develop more enduring and/or detailed governance and regulatory approaches_GV.RM-01_GV.OC-02___medium_
1_We also commit to develop proposals, in consultation with the OECD, GPAI and other stakeholders, to introduce monitoring tools and mechanisms to help organizations stay accountable for the implementation of these actions_GV.OV-03_DE.CM-09___medium_
1_We encourage organizations to support the development of effective monitoring mechanisms, which we may explore to develop, by contributing best practices_DE.CM-09_ID.IM-01___medium_
1_We look forward to developing these principles further as part of the comprehensive policy framework, with input from other nations and wider stakeholders in academia, business and civil society_GV.PO-01____low_definition
1_We also reiterate our commitment to elaborate an international code of conduct for organizations developing advanced AI systems based on the guiding principles_GV.PO-01____low_definition
1_Different jurisdictions may take their own unique approaches to implementing these guiding principles in different ways_GV.OC-03____low_definition
