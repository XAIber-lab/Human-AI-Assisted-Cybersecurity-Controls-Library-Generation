5_"Trustworthiness is the demonstrable likelihood that the system performs according to designed behavior under any set of conditions as evidenced by characteristics including, but not limited to, safety, security, privacy, reliability and resilience"_GV.OC-02_ID.RA-05_PR.PS-01_privacy_High_definition
6_"In computer security, a chain of trust is established by validating each component of hardware and software from the bottom up"_PR.PS-01_ID.RA-09_PR.AA-03__Medium_definition
9_"The EU AI Act establishes a set of horizontal mandatory requirements for trustworthy AI, which include a prohibition against a small number of AI uses that create 'unacceptable risk,' including AI uses that violate fundamental rights"_GV.OC-03_GV.PO-01_ID.RA-05__High_
9_"High-risk AI systems are required to undergo an ex ante conformity assessment"_ID.RA-05_GV.OC-03___High_
9_"The classification of high-risk AI systems is based on the intended purpose of the AI system, and only eight pre-listed areas are considered high-risk. These areas include: biometric identification and categorization of natural persons; management and operation of critical infrastructure; education and vocational training; employment, workers management, and access to self-employment; access to and enjoyment of essential private services and public services and benefits; law enforcement; migration, asylum, and border control management; and administration of justice and democratic processes"_GV.OC-03_ID.RA-05___Medium_definition
11_"The EU AI Act also contains requirements for 'high-risk' AI systems, including data and data governance, documentation and record keeping, transparency and provision of information to users, human oversight, robustness, accuracy, and security"_GV.PO-01_PR.DS-01_ID.AM-08_data protection, transparency_High_
11_"Certain AI systems that pose limited risks are subject to transparency requirements. For example, AI systems that interact with humans, that are used to detect emotions or determine association with social categories based on biometric data, or that generate or manipulate content are all subject to transparency obligations"_GV.OC-03_GV.PO-01__transparency_High_
11_"people will need to be informed if they are interacting with an AI system"_GV.RR-02_PR.AT-01__transparency_High_
11_"commitments related to environmental sustainability, accessibility for people with disabilities, stakeholders' participation in the design and development of AI systems, and diversity of development teams are all considered voluntary"_GV.OC-02_GV.PO-01___Medium_
12_"You should be protected from unsafe or ineffective systems. For example, systems should have ongoing monitoring and evaluation, and be removed from use if necessary"_DE.CM-09_ID.RA-05_RS.MI-01__High_
13_"You should not face discrimination by algorithms and systems should be used and designed in an equitable way. For example, designers should conduct proactive equity assessments and ensure the use of representative data and protection against proxies for demographic features"_GV.PO-01_ID.RA-05__transparency_High_
13_"You should be protected from abusive data practices via built-in protections and you should have agency over how data about you is used. For example, designers, developers, and deployers should seek permission about collection and use of your data where possible, and not use defaults that are privacy invasive"_PR.DS-01_GV.PO-01__privacy, data protection_High_
13_"Surveillance technologies should be subject to heightened oversight, including restrictions in high-stakes settings"_GV.OV-03_GV.PO-01_ID.RA-05_privacy_High_
13_"You should know that an automated system is being used and understand how and why it contributes to outcomes that impact you. For example, you should be given notice that AI systems are in use, the individual or organization responsible for the system, and explanations of outcomes in a clear, timely, and accessible way"_GV.RR-02_PR.AT-01__transparency_High_
13_"You should be able to opt out, where appropriate, and have access to a person who can quickly consider and remedy problems you encounter. For example, you should be able to choose a human alternative when possible"_GV.PO-01_RS.CO-02___High_
14_"The AI RMF defines trustworthy AI as being 'valid and reliable, safe, secure and resilient, accountable and transparent, explainable and interpretable, privacy-enhanced, and fair with harmful bias managed'"_GV.OC-02_GV.PO-01__privacy, transparency_High_definition
14_"The govern function is intended to help cultivate a culture of risk management; the map function is intended to help recognize context and identify risks; the measure function is intended to help assess, analyze, or track risks; and the manage function is intended to help prioritize and act upon identified risks"_GV.RM-01_GV.RM-06_ID.RA-05__High_
14_"The core of the AI RMF is composed of four functions: govern, map, measure, and manage"_GV.RM-01____Medium_definition
14_"The AI RMF is designed to be applied in an iterative manner and used throughout the AI lifecycle"_ID.IM-03_GV.RM-01___High_
8_"trustworthy AI as having three components that should be met throughout the system's lifecycle: 1. Trustworthy AI should be lawful, complying with all applicable laws and regulations; 2. ethical, ensuring adherence to ethical principles and values; and 3. robust, both from a technical and social perspective"_GV.OC-03_GV.PO-01_ID.IM-03__High_
9_"The approach is grounded in fundamental rights, including international human rights law and a framework of democracy and the rule of law"_GV.OC-03____Medium_definition
5_"independent auditing, technical standards, and federal regulation will all be critical"_GV.OC-03_GV.PO-02___Medium_
12_"The five principles are the following: 1. You should be protected from unsafe or ineffective systems. 2. You should not face discrimination by algorithms and systems should be used and designed in an equitable way. 3. You should be protected from abusive data practices via built-in protections and you should have agency over how data about you is used. 4. You should know that an automated system is being used and understand how and why it contributes to outcomes that impact you. 5. You should be able to opt out, where appropriate, and have access to a person who can quickly consider and remedy problems you encounter"_GV.PO-01_GV.OC-02_GV.RR-02_privacy, transparency_High_
