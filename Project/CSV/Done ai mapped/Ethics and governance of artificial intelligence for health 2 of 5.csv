page_text_First proposal_Second proposal_Third proposal_labels_confidence_definition
2_AI systems should be designed demonstrably and systematically to conform to the principles and human rights with which they cohere; more specifically, they should be designed to assist humans, whether they be medical providers or patients, in making informed decisions_GV.RR-02_GV.PO-01_PR.PS-06_High_
2_Human oversight may depend on the risks associated with an AI system but should always be meaningful and should thus include effective, transparent monitoring of human values and moral considerations_GV.OV-03_GV.RM-01_ID.RA-05_transparency_High_
3_Respect for autonomy also entails the related duties to protect privacy and confidentiality and to ensure informed, valid consent by adopting appropriate legal frameworks for data protection. These should be fully supported and enforced by governments and respected by companies and their system designers, programmers, database creators and others_GV.PO-01; GV.OC-03_PR.DS-01; PR.DS-02_PR.DS-10_privacy; data protection_High_
3_AI technologies should not be used for experimentation or manipulation of humans in a health-care system without valid informed consent_GV.OC-03_GV.RR-02_PR.AT-01_privacy_High_
3_The use of machine-learning algorithms in diagnosis, prognosis and treatment plans should be incorporated into the process for informed and valid consent_GV.OC-03_PR.AT-01_PR.AT-02_transparency_High_
3_Essential services should not be circumscribed or denied if an individual withholds consent and that additional incentives or inducements should not be offered by either a government or private parties to individuals who do provide consent_GV.OC-03_GV.PO-01_PR.AA-05_privacy_High_
3_Data protection laws are one means of safeguarding individual rights and place obligations on data controllers and data processors. Such laws are necessary to protect privacy and the confidentiality of patient data and to establish patients' control over their data_GV.OC-03_PR.DS-01_Medium_privacy; data protection_Definition
3_AI technologies should not harm people. They should satisfy regulatory requirements for safety, accuracy and efficacy before deployment, and measures should be in place to ensure quality control and quality improvement_GV.RM-06_ID.RA-01_ID.RA-04_High_
3_Funders, developers and users have a continuous duty to measure and monitor the performance of AI algorithms to ensure that AI technologies work as designed and to assess whether they have any detrimental impact on individual patients or groups_DE.CM-09_DE.AE-02_DE.AE-04_High_
3_AI should be intelligible or understandable to developers, users and regulators_GV.OC-02_PR.AT-01; PR.AT-02__transparency_High_
4_Transparency requires that sufficient information be published or documented before the design and deployment of an AI technology_GV.OC-04_GV.OC-05_RS.CO-03_transparency_High_
4_Such information should facilitate meaningful public consultation and debate on how the AI technology is designed and how it should be used_GV.OC-02_GV.RM-05_RS.CO-03_transparency_High_
4_All algorithms should be tested rigorously in the settings in which the technology will be used in order to ensure that it meets standards of safety and efficacy_ID.RA-09_PR.PS-06_ID.IM-02_High_
4_The examination and validation should include the assumptions, operational protocols, data properties and output decisions of the AI technology_ID.RA-01_ID.RA-04_DE.AE-02_High_
4_Tests and evaluations should be regular, transparent and of sufficient breadth to cover differences in the performance of the algorithm according to race, ethnicity, gender, age and other relevant human characteristics_ID.IM-02_DE.CM-09_DE.AE-02_transparency_High_
4_There should be robust, independent oversight of such tests and evaluation to ensure that they are conducted safely and effectively_GV.OV-03_ID.IM-01_DE.AE-02_High_
4_Health-care institutions, health systems and public health agencies should regularly publish information about how decisions have been made for adoption of an AI technology and how the technology will be evaluated periodically, its uses, its known limitations and the role of decision-making_GV.OV-01_GV.OV-02_RS.CO-03_transparency_High_
5_Humans require clear, transparent specification of the tasks that systems can perform and the conditions under which they can achieve the desired level of performance_GV.RR-02_PR.AT-01_GV.OC-04_transparency_High_
5_When something does go wrong in application of an AI technology, there should be accountability_RS.AN-03_RS.CO-02_RS.CO-03_High_
5_Appropriate mechanisms should be adopted to ensure questioning by and redress for individuals and groups adversely affected by algorithmically informed decisions_RS.AN-03_RS.CO-02_RS.MI-02_High_
5_This should include access to prompt, effective remedies and redress from governments and companies that deploy AI technologies for health care_RS.MA-04_RS.MI-01_RS.MI-02_High_
5_Redress should include compensation, rehabilitation, restitution, sanctions where necessary and a guarantee of non-repetition_RS.MI-02_RC.RP-02_RC.RP-05_High_
6_Inclusiveness requires that AI used in health care is designed to encourage the widest possible appropriate, equitable use and access, irrespective of age, gender, income, ability or other characteristics_GV.OC-02_PR.AA-05_PR.AT-01_High_
6_Institutions (e.g. companies, regulatory agencies, health systems) should hire employees from diverse backgrounds, cultures and disciplines to develop, monitor and deploy AI_GV.RR-02_PR.AT-02_GV.RR-03_High_
6_AI technologies should be designed by and evaluated with the active participation of those who are required to use the system or will be affected by it, including providers and patients, and such participants should be sufficiently diverse_GV.OC-02_PR.AT-01_ID.IM-02_High_
6_AI technology – like any other technology – should be shared as widely as possible_GV.OC-04_GV.SC-02_PR.AA-05_Medium_
6_AI technologies should be available not only in HIC and for use in contexts and for needs that apply to high-income settings but they should also be adaptable to the types of devices, telecommunications infrastructure and data transfer capacity in LMIC_PR.IR-03_PR.IR-04_GV.SC-01_High_
6_Industry and governments should strive to ensure that the "digital divide" within and between countries is not widened and ensure equitable access to novel AI technologies_GV.OC-02_PR.IR-03_GV.SC-01_High_
6_AI technologies should not be biased. Bias is a threat to inclusiveness and equity because it represents a departure, often arbitrary, from equal treatment_ID.RA-01_ID.RA-04_PR.AT-01_High_
6_AI developers should ensure that AI data, and especially training data, do not include sampling bias and are therefore accurate, complete and diverse_ID.RA-01_PR.DS-01_ID.AM-07_data protection_High_
7_AI technologies should be accompanied by means to provide patients with knowledge and skills to better understand their health status and to communicate effectively with health-care providers_PR.AT-01_PR.AT-02_GV.OC-02_High_
7_The effects of use of AI technologies must be monitored and evaluated, including disproportionate effects on specific groups of people when they mirror or exacerbate existing forms of bias and discrimination_DE.CM-09_DE.AE-02_DE.AE-04_High_
7_Special provision should be made to protect the rights and welfare of vulnerable persons, with mechanisms for redress if such bias and discrimination emerges or is alleged_GV.OC-03_RS.MA-04_RS.MI-02_High_
7_Responsiveness requires that designers, developers and users continuously, systematically and transparently examine an AI technology to determine whether it is responding adequately, appropriately and according to communicated expectations and requirements in the context in which it is used_DE.CM-09_DE.AE-02_ID.IM-03_transparency_High_
7_AI technologies should be introduced only if they can be fully integrated and sustained in the health-care system_GV.RM-01_PR.IR-03_PR.IR-04_High_
7_AI systems should be designed to minimize their ecological footprints and increase energy efficiency_PR.IR-04_GV.SC-01_GV.RM-01_High_
3_Preventing harm requires that use of AI technologies does not result in any mental or physical harm. AI technologies that provide a diagnosis or warning that an individual cannot address because of lack of appropriate, accessible or affordable health care should be carefully managed and balanced against any "duty to warn" that might arise from incidental and other findings, and appropriate safeguards should be in place to protect individuals from stigmatization or discrimination due to their health status_GV.RM-04_ID.RA-04_ID.RA-05_High_
4_Transparency should include accurate information about the assumptions and limitations of the technology, operating protocols, the properties of the data (including methods of data collection, processing and labelling) and development of the algorithmic model_GV.OC-04_ID.RA-01_PR.DS-01_transparency; data protection_High_
5_It is the responsibility of human stakeholders to ensure that they can perform those tasks and that they are used under appropriate conditions_GV.RR-02_PR.AT-01_PR.AT-02_High_
5_Although AI technologies perform specific tasks, it is the responsibility of human stakeholders to ensure that they can perform those tasks and that they are used under appropriate conditions_GV.RR-02_PR.AT-01__Medium_Definition
5_The use of AI technologies in medicine requires attribution of responsibility within complex systems in which responsibility is distributed among numerous agents. When medical decisions by AI technologies harm individuals, responsibility and accountability processes should clearly identify the relative roles of manufacturers and clinical users in the harm_GV.RR-02_RS.AN-03_RS.CO-02_High_
5_Institutions have not only legal liability but also a duty to assume responsibility for decisions made by the algorithms they use, even if it is not feasible to explain in detail how the algorithms produce their results_GV.RR-01_GV.RR-02_RS.CO-02_High_
9_The significant investments that would be required might discourage use. This is discussed in greater detail in section 6.2. The quality and availability of data may not be adequate for use of AI, especially in LMIC_GV.RM-03_ID.AM-07__Low_Definition
9_Data are unlikely to be available on the most vulnerable or marginalized populations, including those for whom health-care services are lacking, or they might be inaccurate. Data may also be difficult to collect because of language barriers, and mistrust may lead people to provide incorrect or incomplete information_ID.AM-07_PR.DS-01__Medium_data protection; Definition
9_There may not be appropriate or enforceable regulations, stakeholder participation or oversight, all of which are required to ensure that ethical and legal concerns can be addressed and human rights are not violated_GV.OC-03_GV.PO-01__Medium_
10_Like all new heath technologies, even if an AI technology does not trigger an ethics warning, its benefits may not be justified by the extra expense or cost (beyond information and communication technology infrastructure) associated with the procurement, training and technology investment required_GV.RM-03_GV.SC-06__Medium_
10_Enough consideration may not be given to whether an AI technology is appropriate and adapted to the context of LMIC, such as diverse languages and scripts in a country or among countries_GV.OC-01_GV.OC-02__Medium_