page_text_First proposal_Second proposal_Third proposal_labels_confidence_definitions
3_Until standards are in place and mature testing has taken hold, organizations are using red teams to explore and enumerate the immediate risks presented by AI_ID.RA-05; ID.RA-06_GV.RM-01_GV.OV-02__Medium_Definition
3_The responsible use and development of AI requires categorizing, assessing, and mitigating enumerated risks where practical. This is true from a pure AI standpoint but also from a standard information security perspective_GV.RM-01; GV.RM-06_ID.RA-05_GV.PO-01__High_
3_Our AI red team is a cross-functional team made up of offensive security professionals and data scientists. We use our combined skills to assess our ML systems to identify and help mitigate any risks from the perspective of information security_GV.RR-02_PR.AT-02_ID.RA-01__Medium_Definition
3_Required assessment activities and the various tactics, techniques, and procedures (TTPs) are clearly defined. TTPs can be added without changing existing structures_GV.PO-01_ID.IM-01___High_
3_The systems and technologies in scope for our assessments are clearly defined. This helps us remain focused on ML systems and not stray into other areas_ID.AM-02; ID.AM-08_GV.SC-04___Medium_
3_All efforts live within a single framework that stakeholders can reference and immediately get a broad overview of what ML security looks like_GV.OC-02_GV.RM-05___Medium_
3_This framework enables us to address specific issues in specific parts of the ML pipeline, infrastructure, and technologies_ID.IM-01_GV.SC-09___Low_Definition
3_Technical vulnerabilities can affect any level of infrastructure or just a specific application. They can be dealt with in the context of their function and risk-rated accordingly_ID.RA-01; ID.RA-04_GV.RM-06___Medium_
3_Harm-and-abuse scenarios that are foreign to many information security practitioners are not only included but are integrated_ID.RA-03_GV.SC-07___Low_
3_GRC is the top level of information security efforts, ensuring that business security requirements are enumerated, communicated, and implemented_GV.PO-01; GV.PO-02_GV.OC-03___High_Definition
3_Even if ML didn't come with its own vulnerabilities, it is still developed, stored, and deployed on an infrastructure that is subject to standards set by GRC efforts_GV.PO-01_ID.AM-08_PR.PS-01__High_
3_All assets within an organization are subject to being compliant with GRC standards. And if they aren't, it's ideally only because management filed and approved an exception_GV.PO-02_ID.AM-05_GV.OC-03__High_
4_Development pipelines span multiple and sometimes incongruent systems. Each phase of the lifecycle is both unique in function and dependent on the prior phase_ID.AM-08_GV.SC-09___Medium_Definition
4_Because of this, ML systems tend to be tightly integrated, and the compromise of any one part of the pipeline likely affects other upstream or downstream development phases_ID.RA-04; ID.RA-05_GV.SC-07___High_
6_Compartmentalizing each phase with security controls reduces attack surfaces and increases visibility into ML systems_PR.IR-01_ID.AM-03_PR.PS-01__High_
6_An example control might be that pickles are blocked outside of development environments, and production models must be converted to something less prone to code execution, like ONNX_PR.PS-01; PR.PS-05_PR.DS-01___High_
6_This enables R&D to continue using pickles during development but prevents them from being used in sensitive environments_PR.PS-01_PR.AA-05___Medium_
6_Organizations should seek to add mitigating controls where the complete avoidance of issues is not practical_GV.RM-04_ID.RA-06___High_
6_Inside a development flow, it's important to understand the tools and their properties at each stage of the lifecycle_ID.AM-02_PR.PS-01_GV.SC-07__High_
6_Teams should just be aware of this fact and ensure that the appropriate network security rules are in place_PR.IR-01_PR.AA-05___High_
6_Consider the scope of all technologies within the development pipeline. This includes easy things like two-factor authentication on ML services like HuggingFace_PR.AA-01; PR.AA-03_ID.AM-02___High_
8_With a principled methodology, you can create foundations from which to build continuous security improvement, reaching toward standards and maturity from product design to production deployment_GV.PO-01_ID.IM-01_GV.OV-02__High_
8_Your organization may already have mature processes to discover, manage, and mitigate risks associated with traditional applications_GV.RM-03_ID.IM-01___Medium_Definition
8_We hope that this framework and methodology similarly prepare you to identify and mitigate new risks from the ML components deployed in your organization_ID.RA-05_GV.RM-03___Medium_
3_The risks that our organization cares about and wants to eliminate are addressed_GV.RM-01_ID.RA-05___Low_
3_Information security has a lot of useful paradigms, tools, and network access that enable us to accelerate responsible use in all areas_GV.PO-01_PR.PS-01___Low_Definition
3_Technical risk: ML systems or processes are compromised as the result of a technical vulnerability or shortcoming_ID.RA-01_ID.RA-04___High_Definition
3_Reputational risk: Model performance or behavior reflects poorly on the organization. In this new paradigm, this could include releasing a model that has a broad societal impact_GV.OC-02_GV.RM-03___High_Definition
3_Compliance risk: The ML system is out of compliance, leading to fines or reduced market competitiveness, much like PCI or GDPR_GV.OC-03_GV.RM-03___High_Definition
3_These high-level risk categories are present in all information systems, including ML systems_GV.RM-03_ID.RA-05___Medium_Definition
3_Think of these categories like individually colored lenses on a light. Using each colored lens provides a different perspective of risks with respect to the underlying system, and sometimes the risks can be additive_GV.RM-06_ID.RA-05___Low_Definition
3_For example, a technical vulnerability that leads to a breach can cause reputational damage. Depending on where the breach occurred, compliance could also require breach notification, fines, and so on_ID.RA-04_RS.CO-02___Medium_
4_Models require data to be trained. Data is usually collected from both public and private sources with a specific model in mind_ID.AM-07_PR.DS-01_PR.DS-02_data protection_Medium_Definition
4_The collected data is processed in any number of ways before being introduced to an algorithm for both training and inference_PR.DS-01; PR.DS-02_ID.AM-07__data protection_Low_Definition
4_After a model is trained, it is validated to ensure accuracy, robustness, interpretability, or any number of other metrics_ID.RA-09_PR.PS-01__transparency_High_
4_After the model has been deployed, the system is monitored. This includes aspects of the system that may not relate to the ML model directly_DE.CM-09_PR.PS-04_DE.AE-02__High_
6_For example, MLFlow has no authentication by default. Starting an MLFlow server knowingly or unknowingly opens that host for exploitation through deserialization_PR.AA-01; PR.AA-03_PR.IR-01___High_
6_Jupyter servers are often started with arguments that remove authentication and TensorBoard has no authentication_PR.AA-01; PR.AA-03_PR.IR-01___High_
7_A Flask server was deployed with debug privileges enabled and exposed to the Internet. It was hosting a model that provided inference for HIPAA-protected data_PR.AA-05_PR.IR-01_GV.OC-03_privacy_High_
7_PII was downloaded as part of a dataset and several models have been trained on it. Now, a customer is asking about it_PR.DS-01_GV.OC-03_RS.CO-02_privacy_High_
7_A public bucket with several ML artifacts, including production models, was left open to the public. It has been improperly accessed and files have been changed_PR.AA-05_PR.DS-01_DE.AE-02__High_
7_Someone can consistently bypass content filters despite the models being accurate and up-to-date_PR.AA-05_DE.CM-09_DE.AE-02__High_
7_A model isn't performing as well as it should in certain geographic regions_DE.CM-09_ID.RA-01___Medium_
7_Someone is scanning the internal network from an inference server used to host an LLM_DE.CM-01_DE.AE-02_RS.MA-02__High_
7_System monitoring services have detected someone sending a well-known dataset against the inference service_DE.CM-09_DE.AE-02_RS.MA-02__High_
7_Does it sound like a technical vulnerability caused the issue?_ID.RA-01____Low_
7_Does this affect any ML processes?_ID.RA-04____Low_
7_Who is responsible for the models? Would they know if changes have been made?_GV.RR-02_DE.CM-09___Medium_
