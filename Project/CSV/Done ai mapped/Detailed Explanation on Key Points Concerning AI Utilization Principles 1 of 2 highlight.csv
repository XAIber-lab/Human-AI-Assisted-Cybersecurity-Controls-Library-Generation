text_extract;highlight_color
"Users should make efforts to utilize AI systems or AI services in a proper scope and manner, under the proper assignment of roles between humans and AI systems, or among users.";yellow
"AI service providers are expected to provide AI software updates and AI inspections/repairs, etc. services to improve AI functions and mitigate risks in their utilization. In particular, if it is assumed that the update affects other linked AI systems, AI service providers are expected to provide information on these risks.";green
"Depending on the nature and usage mode of AI systems or AI services to be provided, AI service providers are expected to confirm the reliability of users in advance in cases where the use of an AI is likely to harm human lives, bodies, or property. Furthermore, after an AI service is provided, there may be a necessity for recording and saving input and output logs on the service in order to make sure that no end users misuse or make malicious use of the AI service or AI system.";green
"It is desirable to provide corresponding information before using AI.";red
"If the information cannot be provided in advance, with consideration for assumed risks based on the nature and usage mode of AI, it is desirable to have a system in place to respond to feedback from consumer users.";yellow
"The necessity for human intervention is considered according to the field and application of the AI in accordance with the following example criteria. [Example perspective considered as criteria for the necessity of human intervention]: Nature of end users rights, benefits and intention affected by AI's decision, Reliability of AI's decision (compared with that of human decisions), Allowable time necessary for human decisions, Expected ability of users making decisions, Necessity for protecting target for decision";green
"If it is considered appropriate for consumer users to give final approval to an AI's decision, they are recommended to acquire the necessary skills and knowledge to make appropriate decisions.";yellow
"AI service providers, business users and data providers are expected to cooperate with related stakeholders and to work on preventive or remedial measures (including information sharing, stopping and starting of AI, elucidation of causes, and measures to prevent recurrence, etc.) in accordance with the nature, and conditions, etc. of accidents that have occurred or may occur in the future";green
"AI service providers, business users, and data providers are expected to pay attention to the quality of data (e.g. data accuracy and integrity) used for learning or other AI methods, with consideration for the characteristics of the AI to be used and its usage.";green
"Exclude the data which humans cannot understand or identify from those for learning, Actively adopt the data for learning if it is easily misrecognized by machines (learner), Be careful not to cause an error when annotating (labeling) (especially for supervised learning).";green
"Create a data set while being conscious of the data format used (input) at the utilization phase, Acquire and store logs on how pre-processing is performed (the provenance of data pre-processing).";green
"It is assumed that the accuracy of an AI's judgment can become impaired or decline afterwards. Therefore, AI service providers, business users, and data providers are expected to define reference levels concerning accuracy in advance based on the assumed magnitude and frequency of occurrence of the infringement of rights, the technology level available, and the cost to maintain accuracy, etc.";green
"If it is planned to use data provided by consumer users, they are expected to provide consumer users with information on the means and format of data provision in advance, taking into consideration the characteristics and usage of the AI.";yellow
"AI service providers, business users, and data providers are expected to pay attention to the risk that AI security might become vulnerable by learning inaccurate or inappropriate data. They are also expected to inform consumer users in advance of the existence of such risks.";green
"A risk of making learning (models) fail by mixing incorrectly labeled data in supervised-learning.";red
"AI service providers and business users are expected to comply with data format standards (with syntax and semantics) to promote collaboration among AIs and between AIs and other systems: Data format for AI input and output, and connection methods for collaboration";green
"AI service providers, business users, and data providers are expected to analyze possible risks with consideration for information from developers, while sharing the risks with the cooperating parties, organizing preventive measures and countermeasures for problems";green
"Risks of failure in verifying the judgment and the decision making of an AI (risk of failure to analyze the interactions between AI systems because the interactions become complicated).";red
"Risks that the influence of a small number of AIs become too strong (risks of enterprises and individuals suffering disadvantages because of judgements made by a few AI systems).";red
"In cases where AI is used in fields where AI may harm human life, body, or property, AI service providers and business users are expected to take into consideration so that AI will not harm them through actuators or other devices by taking the following measures as necessary, based on information from the developers, and with consideration of the nature, and conditions, etc. of the assumed damage.";green
"AI service providers and business users are expected to organize in advance the measures to be taken if an AI damages a human life, body, or property through actuators or other devices.";green
"Perform AI inspections, repairs, and AI software updates, and encourage consumer users to carry them out.";green
"Provide a fail-safe design, for example, by constructing a mechanism that can ensure the safety of entire systems even if an unexpected operation is caused by the AI.";green
"AI service providers and business users are expected to pay attention to the security of AI and take reasonable measures corresponding to the technology level at that time to ensure the confidentiality, integrity and availability (CIA) of AI systems.";green
"Initial actions (to be taken according to necessary procedures depending on the urgency of the affected systems or AI etc.): Recovery by rolling back the system or using an alternative system, System shutdown (by kill switch): If possible, Network disconnection: If possible, Content confirmation of security infringement, Report to the related parties";green
"AI service providers are expected, with regard to their AI services, to provide end users with services for security measures and to share past accident and incident information.";green
"Users and data providers should take into consideration that the utilization of AI systems or AI services will not infringe on the privacy of users or others.";yellow
"AI service providers and business users should respect the privacy of end users and third parties in the utilization of AI, based on the social context and reasonable expectations of people in its utilization.";green
"AI service providers, business users, and data providers should respect the privacy of end users and third parties in the collection, preprocessing, and provision etc. of personal data used for AI learning and in the provision of learning models generated through them.";green
"AI service providers, business users, and data providers are expected to take appropriate measures, including the prevention of unconsented data being made available to third parties, in their systems so that personal data is not provided under the judgement of AI to third parties without the consent of those persons.";green