text_extract;highlight_color
"Trustworthiness is the demonstrable likelihood that the system performs according to designed behavior under any set of conditions as evidenced by characteristics including, but not limited to, safety, security, privacy, reliability and resilience";green
"In computer security, a chain of trust is established by validating each component of hardware and software from the bottom up";yellow
"The EU AI Act establishes a set of horizontal mandatory requirements for trustworthy AI, which include a prohibition against a small number of AI uses that create 'unacceptable risk,' including AI uses that violate fundamental rights";green
"High-risk AI systems are required to undergo an ex ante conformity assessment";green
"The classification of high-risk AI systems is based on the intended purpose of the AI system, and only eight pre-listed areas are considered high-risk. These areas include: biometric identification and categorization of natural persons; management and operation of critical infrastructure; education and vocational training; employment, workers management, and access to self-employment; access to and enjoyment of essential private services and public services and benefits; law enforcement; migration, asylum, and border control management; and administration of justice and democratic processes";yellow
"The EU AI Act also contains requirements for 'high-risk' AI systems, including data and data governance, documentation and record keeping, transparency and provision of information to users, human oversight, robustness, accuracy, and security";green
"Certain AI systems that pose limited risks are subject to transparency requirements. For example, AI systems that interact with humans, that are used to detect emotions or determine association with social categories based on biometric data, or that generate or manipulate content are all subject to transparency obligations";green
"people will need to be informed if they are interacting with an AI system";green
"commitments related to environmental sustainability, accessibility for people with disabilities, stakeholders' participation in the design and development of AI systems, and diversity of development teams are all considered voluntary";yellow
"You should be protected from unsafe or ineffective systems. For example, systems should have ongoing monitoring and evaluation, and be removed from use if necessary";green
"You should not face discrimination by algorithms and systems should be used and designed in an equitable way. For example, designers should conduct proactive equity assessments and ensure the use of representative data and protection against proxies for demographic features";green
"You should be protected from abusive data practices via built-in protections and you should have agency over how data about you is used. For example, designers, developers, and deployers should seek permission about collection and use of your data where possible, and not use defaults that are privacy invasive";green
"Surveillance technologies should be subject to heightened oversight, including restrictions in high-stakes settings";green
"You should know that an automated system is being used and understand how and why it contributes to outcomes that impact you. For example, you should be given notice that AI systems are in use, the individual or organization responsible for the system, and explanations of outcomes in a clear, timely, and accessible way";green
"You should be able to opt out, where appropriate, and have access to a person who can quickly consider and remedy problems you encounter. For example, you should be able to choose a human alternative when possible";green
"The AI RMF defines trustworthy AI as being 'valid and reliable, safe, secure and resilient, accountable and transparent, explainable and interpretable, privacy-enhanced, and fair with harmful bias managed'";green
"The govern function is intended to help cultivate a culture of risk management; the map function is intended to help recognize context and identify risks; the measure function is intended to help assess, analyze, or track risks; and the manage function is intended to help prioritize and act upon identified risks";green
"The core of the AI RMF is composed of four functions: govern, map, measure, and manage";yellow
"The AI RMF is designed to be applied in an iterative manner and used throughout the AI lifecycle";green
"trustworthy AI as having three components that should be met throughout the system's lifecycle: 1. Trustworthy AI should be lawful, complying with all applicable laws and regulations; 2. ethical, ensuring adherence to ethical principles and values; and 3. robust, both from a technical and social perspective";green
"The approach is grounded in fundamental rights, including international human rights law and a framework of democracy and the rule of law";yellow
"independent auditing, technical standards, and federal regulation will all be critical";yellow
"The five principles are the following: 1. You should be protected from unsafe or ineffective systems. 2. You should not face discrimination by algorithms and systems should be used and designed in an equitable way. 3. You should be protected from abusive data practices via built-in protections and you should have agency over how data about you is used. 4. You should know that an automated system is being used and understand how and why it contributes to outcomes that impact you. 5. You should be able to opt out, where appropriate, and have access to a person who can quickly consider and remedy problems you encounter";green
