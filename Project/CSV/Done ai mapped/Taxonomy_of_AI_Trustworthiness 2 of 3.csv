page_text_first_proposal_second_proposal_third_proposal_labels_confidence_definition
15_This paper and the taxonomy of trustworthiness it introduces can ideally supplement use of the NIST AI RMF because it provides an approach for connecting what are currently three relatively disparate elements: the core framework, the AI lifecycle, and the characteristics of trustworthiness._GV.OC-01_GV.PO-01_GV.RM-01__Low_definition
16_The overall trustworthiness of an AI system is dependent upon the holistic consideration of all properties. For example, an AI system that is reliable and safe, but is not made transparent or explainable to users, is unlikely to be trusted._GV.RM-01; GV.RM-02_GV.OC-02__transparency_Medium_
16_There are also tensions between properties that can arise, for example between explainability and security._GV.RM-02_ID.RA-05___Low_definition
16_In some cases an organization will need to make tradeoffs between some of the properties, either due to resource constraints or conflicts between two or more properties. Which properties to prioritize will depend on the context of the particular organization, AI system, and use case._GV.RM-02_GV.RM-04_GV.OC-01__Medium_
17_The people best suited to address a particular property will vary depending on the organization and the type of system being developed. In general, we expect that multidisciplinary and diverse teams will be critical, and that many roles will have relevant input on how to effectively consider the properties._GV.RR-02_GV.RR-01___High_
17_We expect that in many cases, decisions about a particular property will not be made by a single person or team, but rather there will be chains of interactions among people with different roles who bring unique expertise._GV.RR-02_GV.RM-05___Medium_
17_It will also be critical that the teams exploring the trustworthiness of AI systems have the power to influence or implement necessary changes._GV.RR-01_GV.RR-03___High_
18_If risks and impact are deemed to be unacceptable, how will we ensure the AI system is adjusted or rejected?_ID.RA-06_GV.RM-04_ID.RA-05__High_
19_Rather than looking at a small number of final high-risk use cases to determine the relevancy of properties, we opted instead to focus on a set of questions that reveal more about the nature of the interaction between the system and people._ID.RA-05_GV.RM-06___Medium_
19_An AI system may change its degree of human engagement at some point during its lifecycle, and so any assessment of human engagement should be revisited at regular intervals._ID.RA-07_DE.CM-03___High_
20_Conducting a risk and impact assessment is still a critical process for any AI system, and should be done in addition to considering the degree to which an AI system engages with people._ID.RA-05_ID.RA-04_GV.RM-03__High_
22_Security-by-Design How will we build security into the AI system design, testing, deployment, and operation? How often will we provide security updates to the AI system?_PR.PS-01_PR.PS-06_PR.PS-02__High_
22_Availability How will we ensure that information for and about the AI system is available to authorized personnel when it is needed?_PR.AA-05_PR.DS-01___High_
22_Confidentiality How will we ensure that information is not made available or disclosed to unauthorized individuals, entities, or processes?_PR.DS-01_PR.AA-05_PR.DS-02_privacy_High_
22_Integrity How will we maintain and ensure the accuracy, completeness, and appropriateness of data, models, and procedures informing the AI system?_PR.DS-01_PR.DS-02_PR.DS-10_data protection_High_
22_High Quality AI System Configuration How will we assess the quality of the AI system design and configuration and ensure consistently high quality?_PR.PS-01_ID.AM-08___High_
22_High Quality Network Resources and Services How will we assess and ensure the quality of shared network resources and services, e.g., distributed dataset access?_PR.IR-01_PR.IR-03___High_
22_Trusted Dependencies on External Parties How will we identify, assess, and monitor our dependencies on external parties?_GV.SC-04_GV.SC-07___High_
22_Foresight and Scenario Planning How will we assess and navigate possible futures and the evolving risk landscape?_ID.RA-02_ID.RA-03_ID.RA-04__High_
23_Protection of Physical and Psychological Safety How will we ensure that the AI system will not cause physical or psychological harm or lead to a state in which human life, health, property, or the environment is endangered?_ID.RA-04_ID.RA-05_GV.RM-01__High_
23_Assurance / Management of Uncertainty If we do not know all of the elements required for the safe development and deployment of the AI system, how will we manage this uncertainty?_ID.RA-05_GV.RM-02___High_
23_Assurance / Management of Multi-Capability / Multi-Modal Systems If an AI system has multiple capabilities or works across multiple modalities, how will we document and manage this complexity?_ID.AM-08_PR.PS-01___High_
24_Alignment with Human Values How will we ensure that the AI system abides by desired human values and does not sacrifice human values to achieve its narrow goals?_GV.OC-02_GV.RM-01___Medium_
24_Governable How will we ensure an AI system is designed and engineered to achieve its goals while maintaining the ability to disengage or deactivate the system if necessary? How will we ensure an AI system would not have incentives to resist or deceive its operators?_PR.PS-01_PR.PS-04_ID.RA-01__High_
24_Diverse How will we ensure that gender, racial, age, ability, religious, cultural, disciplinary, and other relevant types of diversity are represented within the teams influencing AI development and use, throughout all stages of the AI lifecycle?_GV.RR-02_PR.AT-01___High_
24_Inclusive How will we ensure inclusivity of all relevant experts and communities in the design and development of the AI system?_GV.RR-02_GV.OC-02___High_
25_Equitable How will we navigate structural power dynamics and promote equity in the design and use of the AI system?_GV.OC-02_GV.RM-01___High_
25_Just How will we ensure justice in the design and use of the AI system?_GV.OC-02_GV.RM-01___High_
25_Mitigation of Systemic and Human Bias How will we assess and mitigate ways in which systemic and human bias may influence the design, development, and deployment of the AI system?_ID.RA-01_ID.RA-05_GV.OC-02__High_
26_Solidarity How will we ensure the design and use of the AI system respects the solidarity of groups and communities, such as workers, women, people with disabilities, ethnic minorities, children, or others?_GV.OC-02_GV.RM-01___High_
27_Privacy-by-Design How will privacy be built into the AI system design, testing, deployment, and operation? If data includes sensitive or personally identifiable information including biometrics, what extra precautions will be taken?_PR.DS-01_PR.DS-02_PR.AA-05_privacy_High_
27_Data Privacy or Protection Impact Assessment What is the impact of the AI system on privacy? When and how will we conduct a data privacy or data protection impact assessment?_ID.RA-04_ID.RA-05__privacy; data protection_High_
27_Effective Policy and Governance How will we analyze and follow or implement relevant or desired AI and data standards, policies, principles, and guidance?_GV.PO-01_GV.PO-02___High_
27_Adherence to the Rule of Law How will we analyze and ensure compliance with all relevant laws and regulations across every jurisdiction of use? How will we analyze liability considerations, and what precautions will be taken?_GV.OC-03_GV.PO-01___High_
28_Coordination (Public-Private; International) How will we identify and coordinate with relevant institutions, nationally and internationally?_GV.SC-02_RS.CO-02___High_
28_Effective Risk Assessments and Impact Assessments How will we assess, document, and communicate (on a regular basis) the expected, potential, and actual risks and impacts of the AI system on people, organizations, and society?_ID.RA-05_ID.RA-04_GV.RM-06__High_
28_Community Engagement How will we identify communities interested in, engaged in, or impacted by the AI system, and how will we encourage their participation throughout the AI lifecycle?_GV.OC-02_RS.CO-02___High_
28_Open How can we promote openness and transparency about our development and governance of AI technologies, internally and externally?_GV.RR-01_RS.CO-03__transparency_High_
29_Documentation How will we document the AI system's design, datasets, training, characteristics, capabilities, limitations, predictable failures, intended uses, etc?_ID.AM-08_PR.PS-04_RS.AN-06_transparency_High_
29_Internal Reporting / Culture of Safety How will we incentivize internal reporting of challenges or concerns, and promote a culture of safety among teams involved with the AI system and in general?_GV.RR-01_RS.CO-02___High_
29_Internal Reviews How will internal reviews be conducted to assess trustworthy AI practices?_GV.OV-03_ID.IM-01___High_
29_Responsible Use in Government, Education, Health, Finance, Workplace, Identification and Detection, and other High-stakes Settings How will we ensure responsible potential and actual uses in high-stakes settings?_GV.OC-01_ID.RA-05_GV.RM-01__High_
29_Responsible Use in Critical Infrastructure and Safety-Critical Systems How will we ensure responsible potential and actual uses for critical infrastructure and safety-critical systems, including assessing the potential for damaging effects from technical faults, defects, or attacks?_ID.RA-05_PR.IR-03_GV.SC-05__High_
29_Responsible Use in the Criminal Legal System and by Law Enforcement How will we ensure responsible potential and actual uses in the criminal legal system or by law enforcement?_GV.OC-03_ID.RA-05___High_
30_Responsible Use in Defense and National Security How will we promote peace and ensure responsible and controlled uses for defense, military, border control, and national security purposes, including for weapons systems?_GV.OC-03_ID.RA-05___High_
30_Verified Supply Chain How will we assess and verify the relevant components of the supply chain?_GV.SC-06_GV.SC-07___High_
30_Appropriate Assignment of Organizational Roles, Authorities, and Responsibilities How will we assign and document organizational roles, authorities, and responsibilities? How will we designate points of contact along the lifecycle?_GV.RR-02_GV.RR-01___High_
30_Effective Capabilities How will we obtain the necessary resources and knowledge to achieve our trustworthy AI objectives?_GV.RR-03_PR.AT-01___Medium_
30_Collaboration How will we enable multi-stakeholder collaboration?_GV.SC-02_RS.CO-02___High_
30_Supportive Governance and Organizational Structure How can our governance and organizational structure support trustworthy AI?_GV.RR-01_GV.PO-01___High_
31_Effective Hiring and Training How will we support the hiring and training of individuals who can carry out trustworthy AI objectives?_PR.AT-01_PR.AT-02___High_
31_Responsible Labor Practices and Rights How can we support labor rights in our use of AI? How will the supply chain of the AI system be monitored to evaluate working conditions?_GV.SC-07_GV.OC-03___High_
31_Leadership Commitment How will we ensure long-term commitment to trustworthy AI from organizational leadership?_GV.RR-01_GV.RR-03___High_
31_Supportive Organizational Culture How will our organizational culture support our trustworthy AI objectives?_GV.RR-01_PR.AT-01___Medium_
31_Procurement Standards How will we implement/ensure AI procurement standards that support trustworthy AI if we are procuring the AI system or providing it to others?_GV.SC-05_GV.SC-06___High_
31_Appropriate Relationships, Interdependencies, and Interconnections What relationships, interdependencies, and interconnections will be involved in the development and use of the AI system?_GV.SC-02_GV.OC-05___High_
31_Alignment with Organizational Vision, Mission, and Values How will we ensure the AI system is true to our vision, mission, and values?_GV.OC-01_GV.RR-01___High_
31_Socially Responsible How will our AI system and its use align with our social responsibility efforts?_GV.OC-02_GV.RM-01___High_
31_Supportive of Fair Competition How will we support fair competition among a variety of actors in the domain in which our AI system is applied?_GV.OC-02_GV.SC-02___High_
32_Supportive of Civil Rights How will we protect and promote civil rights throughout the AI lifecycle, including protection from unlawful discrimination?_GV.OC-03_GV.PO-01___High_
32_Supportive of Democratic Values and Processes How will we ensure the design and use of the AI system are consistent with democratic values such as freedom and equality?_GV.OC-02_GV.RM-01___High_
33_Protection of Human Autonomy and Freedom How will we ensure that the AI system respects the freedom and autonomy of individuals and does not intrude on people's self-determination?_GV.OC-02_GV.RM-01___High_
33_Protection of Human Dignity How will we ensure that the development and use of the AI system respect human dignity and treat people as having intrinsic worth, and not merely as objects?_GV.OC-02_GV.RM-01___High_
33_Protection of Human Rights How will we ensure the AI system does not threaten human rights? For example, how will we ensure the right to privacy?_GV.OC-03_GV.PO-01__privacy_High_
33_Supportive of Wellbeing How will we ensure the AI system supports individual, community, and societal wellbeing, including mental or emotional wellbeing?_GV.OC-02_GV.RM-01___High_
34_Reduction of Carbon Emissions How can we reduce the carbon emissions from the design and use of AI systems in general?_GV.OC-01_PR.IR-04___Medium_
34_Assessment of Economic, Social, Cultural, Political, and Global Implications How will we assess the economic implications of the AI system, including whether use of the system could impact jobs or reduce the need for human labor?_ID.RA-04_ID.RA-05_GV.OC-02__High_
