page_text_First proposal_Second proposal_Third proposal_labels_confidence_definitions
1_Business units own the challenge. Since the business units carry out the mission, they are primarily responsible for identifying business challenges that should be innovated through the use of technology generally, but specifically through adoption of AI. Each AI project should be directly linked to a business challenge with expected outcome and benefits identified early on.GV.RR-01; GV.RR-02_GV.OC-01_GV.RM-01__High
1_Investment. The level of investment in AI should match the level of value it adds in achieving mission and business goals. Therefore, mission or business executives should allocate funding for AI. Think about your mission and business objectives, and which tasks to support those objectives could be done better with the addition of AI techniques.GV.RR-03_GV.RM-01_GV.OC-01__High
1_Team structure. Embedding AI-focused work in the mission centers and with the customer ensures that AI is integrated into how the agency functions and achieves its mission and business goals. AI should not be approached in a silo, but rather integrated into the rest of the workforce and the agency's core workflows.GV.RR-02_ID.AM-05_GV.OC-01__High
2_Don't use AI for the sake of using AI; use AI where it will be an effective tool for dealing with the current and future state of the business and missions.GV.RM-01_GV.OC-01___High
2_Invest in AI tools, talent, and tradecraft within the business centers that are most able to use it. The mission owners who are best able to judge AI's value to their objectives make those decisions.GV.RR-03_GV.RM-01___High
2_Avoid centralizing AI practitioners and leaders in one unit. AI talent must be accountable to the business needs and therefore should exist across the organization.GV.RR-02_PR.AT-02___High
2_Avoid "data scientist" or "AI staff" for loan situations that remove accountability to the mission center or program office responsible for implementing the AI solution.GV.RR-02_GV.RR-01___High
3_Technical Tool Domain Examples: development environments, server space, code libraries, etc.ID.AM-02____Low_definition
3_AI practitioners will also need support and guidance in areas such as legal considerations, acquisition, and security to fully integrate an AI system into existing processes.PR.AT-02_GV.SC-02___Medium
3_Institutional resources: security review, legal review, acquisition support for buying licenses, etc., talent/HR support_ID.AM-02_GV.SC-01___Medium
4_The people managing the central AI resource should also be involved in AI talent recruitment, certification, training, and career path development for AI jobs and roles.PR.AT-01; PR.AT-02_GV.RR-04___High
4_Business units that have AI practitioners can then expect that AI talent will be of consistent quality and able to enhance mission and business effectiveness regardless of the customer's own technical understanding of AI.PR.AT-02_GV.RR-02___Medium
4_Embed AI professionals in the mission centers and program offices, but they should have access to a one-stop-shop for AI tools and resources in a central AI resource.GV.RR-02_ID.AM-02___High
4_The central AI technical resource provides technical and infrastructure support as well as access to legal, security, and acquisition support for AI professionals in the mission center and program office to succeed in AI adoption efforts.GV.SC-02_ID.AM-02___High
6_The IAT should address these types of issues: Data rights, Intellectual property provisions, End-user licensing agreements, Appropriations implications for different types of pricing, The extent that software or hardware must be integrated into the existing infrastructure, Security measures that must be complied with to start a pilot or scale a solution.GV.SC-05_GV.SC-01_PR.DS-01_data protection_High
6_Meeting with these individuals that make up the IAT at the beginning of your program's efforts will help establish the operating framework within the team as well as pain points that must be solved before moving into more involved phases of the project.GV.SC-02_GV.RM-05___High
6_Meeting with the IAT in the middle of planning will help validate the ideas being explored and ensure they are practical. Finally, meeting with everyone right before starting a solicitation or internal development effort in earnest will ensure that the entire organization is not only on the same page, but ready to react should a critical issue arise that has to be escalated.GV.SC-06_GV.OV-01___High
6_Given AI's emerging and rapidly evolving nature, new and unforeseen challenges may come up at any time. Build a process that allows IPTs to ask questions or clarify issues at any point in the process, like, for example, a legal concern.GV.RM-05_ID.RA-07___High
7_Ease of access. With access to a suite of tools already available, AI practitioners–or the vendors that business teams interact with–can easily experiment with datasets, create proofs of concept or even deploy at scale with ready to use AI tools without having to go through the process of individually procuring, installing and gaining security approvals individually.PR.AA-05_ID.AM-02___High
7_Cost and infrastructure optimization. A shared resource allows for optimization and automation of shared infrastructure, which can translate into significant cost savings. By sharing infrastructure across the organization, the central AI technical resource can coordinate and optimize infrastructure usage for model training, hosting, and deployment.ID.AM-08_PR.IR-04___High
7_Governance. Creating a central AI technical resource allows for greater insight into all of the AI initiatives underway in the organization. This makes it possible to create and enforce common governance policy and create a structure for monitoring AI projects.GV.PO-01_GV.OV-03___High
7_Expertise. Though the central technical resource DOES NOT provide data scientists to loan out to the rest of the organization, it is staffed by deeply technical experts who can aid in the selection of additional AI talent.PR.AT-02_GV.RR-04___Medium
8_Most likely, these early teams will need to supply their own ad hoc infrastructure, which will limit their effectiveness. Choose a use case that is so compelling—ideally to agency leadership—that the teams are still able to show great value to the mission/business center.GV.RM-01_ID.RA-06___Medium
10_The National Institute of Standards defines the essential building blocks of AI responsibility and trustworthiness to include accuracy, explainability and interpretability, privacy, reliability, robustness, safety, security, and importantly the mitigation of harmful bias._GV.OC-03____Low_definition
10_An essential (but not solely sufficient) practice that can help answer these important questions, and enable responsible and trustworthy AI is to ensure that diversity, equity, inclusion, and accessibility (DEIA) are prioritized and promoted throughout the design, development, implementation, iteration, and ongoing monitoring after deployment.GV.RR-01_GV.OC-02_PR.AT-02__High
10_Some of the worst negative impacts are due to harmful biases in AI system outcomes, including many cases where AI further entrenches inequality in both the private and public sectors. One of the key ways the outcomes of AI systems become biased is by not carefully curating, evaluating, and monitoring the underlying data and subsequent outcomes.ID.RA-01_DE.CM-09_ID.RA-04__High
11_To implement responsible AI practices, and prevent harms, including biased outcomes, AI systems must both be rigorously tested and continually monitored. Affected individuals and groups must be able to understand the decisions that are made by these systems.DE.CM-09_ID.RA-01__transparency_High
11_Because a broad set of topics such as security, privacy, and explainability are also important to the development of responsible AI, interdisciplinary and diverse teams are key to success. Interdisciplinary teams must include AI experts, other technical subject-matter experts, program-specific subject-matter experts, and of course the end-users.GV.RR-02_PR.AT-02_GV.OC-02_privacy; transparency_High
13_As discussed, a responsible and trustworthy AI practice must include interdisciplinary, diverse, and inclusive teams with different types of expertise (both technical and subject matter specific, including user or public-focused).GV.RR-02_PR.AT-02___High
13_To provide the AI team with the best tools for success, the principles of DEIA should be at the forefront of any technology project. Responsibility for ensuring responsible design decisions that result in equitable outcomes falls on all team members, from the practitioners to managers.GV.RR-01_PR.AT-01___High
13_How to handle missing values in the training data? It is well known that data sets used for AI often lack diverse representation or are overrepresented by certain demographics, which can lead to inequitable outcomes. One option is to filter the dataset to ensure it is more representative, but this could require disregarding some data which could reduce the overall dataset quality.ID.RA-04_PR.DS-01_ID.AM-07_data protection_Medium
13_Which metrics will be used to measure a model's performance? What an AI system uses to determine it actually is working is an essential decision.ID.IM-01_DE.CM-09___Medium
15_To drive this point home: A good starting point to responsibly implement AI is to ask questions, especially around key decision points. Ask them early; ask them often.GV.RM-06_ID.RA-04___High
15_Ask the same question over and over again. (Answers might change as the team learns.) Ask different people on the team to get a collection of answers.GV.RM-05_ID.IM-01___High
16_Why are you considering using an AI solution in the first place? Is it the best option to solve this particular problem? Have you evaluated alternative solutions? Will it actually solve the problem? What metrics are important to assess this hypothesis and how will you measure them? Will it equally benefit all users or just disproportionately help some, possibly at the cost to others?GV.OC-01_ID.RA-04_GV.RM-01__High
16_When something deviates from the intended output or behavior, who is responsible for noticing and correcting this? Is someone responsible for making sure that every step is not just done, but done correctly?GV.RR-02_DE.AE-02_RS.MA-02__High
16_The process starts with establishing clear roles and responsibilities for data and model management. At a minimum, an aberrant outcome can be linked to its training source.GV.RR-02_ID.AM-08_DE.AE-02__High
17_What are the possible negative impacts of these systems? How do we measure this harm and what could we do to mitigate that impact?ID.RA-04_ID.RA-06___High
17_Are there regular management reviews of changes made to the input, throughput, or output of the developed system?DE.CM-09_GV.OV-03___High
17_Are there clear roles and responsibilities for the management of the AI system?GV.RR-02_GV.RR-01___High
17_Are there automated system checks for issues such as model drift, anomalous behavior, or other potential changes?DE.CM-09_DE.AE-02___High
17_Are the systems auditable so that the drivers of incorrect or inequitable outcomes can be identified and fixed?DE.AE-02_ID.RA-01__transparency_High
17_Does the AI system provide clear notice of its use to impacted people, including what relevant factors are important to any decisions or determinations? Is there a mechanism for impacted people to contest, correct, or appeal or even opt out of the use of an AI system?GV.OC-02_RS.CO-02__transparency_High
17_Bias can enter an AI system in many ways. While, some of the most commonly discussed bias issues are about discriminatory opportunity loss, seen in employment, housing, healthcare, and many other fields, it's important to remember bias occurs in many forms._ID.RA-01____Low_definition
17_Though it may be impossible to completely eliminate all bias (and that may not even be the goal) an AI team must be able to evaluate what possible harms of their system could be and how bias might cause disparate negative impacts across different populations. To reduce this possibility, the team must evaluate for bias in datasets, the model, and the design choices throughout the product life cycle. It must also evaluate for bias in the outcomes the systems produce to ensure the output does not disproportionately affect certain users.ID.RA-04_DE.CM-09_ID.RA-01__High
19_This chapter is a first step in responsible and trustworthy AI implementation, but like the iteration and innovation occurring in AI, this will be an ongoing effort. Asking these types of questions will not solve all challenges, nor does answering them ensure compliance with any standards, guidelines, or additional principles for using AI responsibly.GV.RM-03_ID.IM-01___Medium