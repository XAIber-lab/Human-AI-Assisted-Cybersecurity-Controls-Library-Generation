page_text_First proposal_Second proposal_Third proposal_labels_confidence_definition
1_Companies that develop and operate AI systems should, under the leadership of top management, understand not only positive impacts but also negative impacts, including unintended risks, that AI systems may have. This information should be reported to the top management and shared among those in top managerial positions, and their understanding should be updated in a timely manner_GV.RR-01; GV.RR-02_ID.RA-05_GV.OV-01__High_
1_we investigated whether any incidents were reported in the past regarding AI systems whose functions or fields of application are the same or similar to those of the system that we are going to develop and operate, and even if there were no reports of such incidents, we examined whether there were reports anticipating specific possibilities of incidents_ID.RA-02; ID.RA-03_DE.AE-07_RS.AN-03__Medium_
1_we plan to perform in-depth impact analyses of individual AI systems through the gap analysis_ID.RA-04; ID.RA-05_GV.RM-06___Medium_
2_while recognizing that social acceptance of AI systems can differ from country/region to country/region, we also referred to the incident database listed in Column: Sharing Incidents later. In our analysis, we see that many incidents relate to the management of personal information, fairness, and security_ID.RA-02_RS.AN-03__data protection_Medium_definition
2_we have roughly classified incidents that have had a negative impact on society and potential negative impacts that some anticipate, in light of general frameworks in order to develop an overall picture about them_ID.RA-05_GV.RM-06___Medium_
2_analyses of positive and negative impacts of AI can be made more useful by combining information gleaned from our own experience with information from the experience of other companies in our industry, and in some cases, from the experience in other industries_ID.RA-02; ID.RA-03_GV.RM-03___High_
2_by continuing these analyses at a certain interval, we are able to look into revising our AI governance goals in a timely manner before an incident occurs_GV.OV-01; GV.OV-02_ID.IM-01___High_
2_CONTEXT chapter corresponds to conditions and risks analysis, presents a general framework from the perspective of the relationship between the OECD AI principles and industrial sectors, as well as from the perspectives of business function, potentially impacted stakeholders, and scope of impacts_GV.OC-01; GV.OC-02___Low_definition
4_Companies that develop and operate AI systems should, under the leadership of top management, understand the current state of social acceptance based on opinions of not only direct stakeholders, but potential stakeholders before full-scale provision of the AI systems. In addition, even after the full-scale operation, companies should obtain opinions of stakeholders again and update their perspectives in a timely manner_GV.OC-02_GV.OV-01_GV.RR-01__High_
4_we carried out questionnaire surveys and published their results on (1) the status of consumers' understanding of AI, (2) consumers' expectations for AI, their perceived challenges with respect to AI, and their intentions to use AI, (3) AI-provided services that consumers use (and the types of risks they are concerned about), and (4) how much they recognize and understand the risks associated with the AI services that they use_GV.OC-02_ID.RA-03_GV.RM-01_transparency_High_
5_we actively send personnel to seminars and conferences on AI ethics and quality that are organized by universities and industry organizations_PR.AT-01; PR.AT-02_GV.RR-04___Medium_
5_we invite experts who are familiar with social acceptance of AI and hold regular expert meetings_GV.OC-02_PR.AT-02___High_
5_we draw on the expert meetings not only to have them assess our AI management system and our operations, but also to deepen our understanding of the conditions in which we operate, such as general social acceptance of AI_GV.OV-03_ID.IM-01___High_
7_Companies that develop and operate AI systems should evaluate and re-evaluate their AI proficiency based on the extent of the company's experience in developing and operating AI systems_ID.IM-01_GV.OV-03___High_
11_effective way to address the issue of negative impacts that may result from AI system development and operation is in most cases to learn from past incidents_ID.RA-02_RS.AN-03_DE.AE-02__High_
11_The AI Incident Database (AIID) was released in November 2020. More than 1000 incidents are posted on AIID with their URL links, and a search app is also provided_ID.RA-02____Low_definition
11_Because AI systems are built inductively based on data sets and many of their negative impacts are unintentional, it is useful to understand past incidents in order to reduce the negative impacts_ID.RA-03; ID.RA-04_DE.AE-02__data protection_High_
15_Companies that develop and operate AI systems should evaluate and re-evaluate their AI proficiency based on the extent of the company's experience in developing and operating AI systems_ID.IM-01_GV.OV-03___High_
15_it becomes important to look at an index of AI proficiency (how much the company is ready for developing and operating AI systems), which makes it visible how much the company can respond to the negative impacts of AI_ID.RA-05_GV.RM-01___High_
15_we evaluate whether the magnitude of impacts that our company's AI systems may have on society and the scope of relevant stakeholders are proportionate to our company's level of AI proficiency_ID.RA-05_GV.OC-02___High_
19_Companies that develop and operate AI systems should identify a gap between AI governance goals and current state in the AI systems that they are developing and operating, and if any negative impacts are found upon evaluating the impacts resulting from the gap, determine whether or not the negative impacts would be acceptable, taking into account their severity, scope, and frequency of occurrence_ID.RA-04; ID.RA-05_GV.RM-06_ID.IM-01__High_
19_The technology officer defines perspectives for gap analysis from the Social Principles of Human-Centric AI and instructs development personnel to identify gaps for each perspective, evaluate impacts caused by the gaps, and report the results to the technology officer as soon as practically possible in all AI system development projects_ID.RA-05_GV.RR-02_GV.PO-01__High_
20_The committee is composed of individuals other than those engaged in development and operation projects of each AI systems, and their mission is to analyze gaps on a project basis between the current state and our company's AI policy_GV.RR-02_ID.RA-05___High_
20_in cases where it is clear that the negative impacts are minor, other modes of gap analysis operation may be allowed, for example, having AI management personnel present at project meetings carry out simple gap analysis instead of conducting a uniform and strict gap analysis_ID.RA-04_GV.RM-06___Medium_
20_create lists for gap analysis based on our AI policy, use the lists to identify gaps in AI system development and operation, and evaluate the impacts caused by the gaps_ID.RA-05_GV.PO-01___High_
20_We also select actual projects and have AI management personnel work alongside project personnel to refine the lists and make them standard process in the management system operation_GV.RR-02_ID.IM-01___High_
20_if there is any concern about the appropriateness of the report, the AI governance officer will communicate his/her concern to the officer overseeing the project and make some necessary adjustment_GV.RR-02_GV.OV-03___High_
20_The negative impacts of AI systems vary greatly depending on their application, scope, and mode of use_ID.RA-04____Low_definition
21_Some of the ethical issues of AI can be addressed through technical approaches, such as preparing sufficient data sets to obtain reasonable output, but this may not be enough in socially sensitive areas in some cases_PR.DS-01; PR.DS-02_ID.RA-05__data protection_Medium_
22_when developing or using AI systems in sensitive fields where we have no previous experience, we make sure that individual consultations are made instead of going through our regular process_GV.RR-02_ID.RA-05___High_
23_we compile and provide risk related information - information that we implement proper risk management, take measures to minimize negative impacts, and implement rigorous information security management - on our AI systems operations in a way that inexperienced consumers are able to understand, and also make a contact point easily accessible_GV.RM-05_RS.CO-02_GV.OC-02_transparency_High_
23_Since AI literacy is relatively high at our service recipients, we provide succinct explanations with technical terms about the possibility that certain gaps can be found in the AI system that we provide and measures we take to address the gaps_GV.OC-02_RS.CO-02___Medium_
24_we indicate in an easy-to-understand way that AI is used and clarify the advantages and disadvantages of using AI. We also let users know that we offer alternative services for AI system users who prefer not to use the AI mode_GV.OC-02_RS.CO-02__transparency_High_
24_have also established ongoing communication with consumers, using the Guidebook on Corporate Governance for Privacy in Digital Transformation (DX) ver 1.1 as a reference_GV.OC-02_GV.RM-05__data protection_Medium_
24_we make it clear in our agreement with our AI developer that we can have the developer provide us with the information that we will need to respond to inquiries from AI system users_GV.SC-05_RS.CO-02___High_
25_Companies that provide data should provide information on the data sets including data collection sources, collection policies, collection criteria, annotation criteria, and limitation on use to ensure that companies that develop AI systems are able to appropriately conduct gap analysis_PR.DS-01; PR.DS-02_ID.RA-05__data protection_High_
27_Companies that develop and operate AI systems should strategically improve AI literacy in order to properly operate their AI management system, considering outside learning materials as an option_PR.AT-01; PR.AT-02_GV.RR-04___High_
28_we use in-house learning materials with extensive coverage of case examples based on specific applications of our own AI systems instead of general-purpose third-party training materials_PR.AT-01; PR.AT-02_GV.RR-04___Medium_
28_recommendations given by a committee made up of invited external experts raised our management's interest in AI ethics, and we have since created an independent e-learning course solely on AI ethics which all employees are now required to take_PR.AT-01_GV.RR-01; GV.RR-04___High_