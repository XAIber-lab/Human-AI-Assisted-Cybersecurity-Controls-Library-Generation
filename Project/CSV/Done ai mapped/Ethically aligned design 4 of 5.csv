228_A city council might misallocate funds for policing across city neighborhoods because it relies on the output of an algorithm that directs attention to neighborhoods based on arrest rates rather than actual crime rates._ID.RA-05_GV.RM-06_ID.IM-01__Medium
228_In civil justice, A/IS applied in a search of documents to uncover relevant facts may fail to do so because an operator without sufficient competence in statistics may materially overestimate the accuracy of the system, thus ceasing vital fact-finding activities._PR.AT-02_GV.RR-02_PR.AT-01__High
228_In the money bail system, reliance on A/IS to reduce bias may instead perpetuate it. For example, if a judge does not understand whether an algorithm makes sufficient contextual distinctions between gradations of offenses, that judge would not able to probe the output of the A/IS and make a well-informed use of it._PR.AT-02_GV.RR-02_PR.AT-01__High
184_First, anticipating the process of evaluation during the implementation phase requires defining criteria and metrics for such evaluation, which in turn better allows the detection and mitigation of failures._ID.RA-05_ID.IM-01_GV.RM-06__High
184_Second, a systematic risk analysis and management approach can be useful for an application to privacy norms. This approach tries to anticipate potential points of failure, e.g., norm violations, and, where possible, develops some ways to reduce or remove the effects of failures._ID.RA-05_GV.RM-06___High
184_Third, because not all risks and failures are predictable, especially in complex human-machine interactions in social contexts, additional mitigation mechanisms must be made available._ID.RA-06_RS.MI-01___Medium
184_Fourth, once failures have occurred, responsible entities, e.g., corporate, government, science, and engineering, shall create a publicly accessible database with undesired outcomes caused by specific A/IS systems._RS.CO-03_DE.AE-06___High
181_In light of the multiple possible approaches to computationally implement norms, diverse research efforts should be pursued, especially collaborative research between scientists from different schools of thought and different disciplines._GV.SC-02_ID.IM-02___High
181_For example, some contributors to the multi-agent systems literature have integrated norms into their agent specifications, and even though these agents live in societal simulations and are too underspecified to be translated into individual A/IS such as robots, the emerging work can inform cognitive architectures of such A/IS that fully integrate norms._ID.IM-01_GV.SC-01___Low definition
185_Prevention and mitigation strategies must be adopted_ID.RA-06_RS.MI-01___High
183_Transparency as honest design—German designer Dieter Rams coined the term "honest design" to refer to design that "does not make a product more innovative, powerful or valuable than it really is"_GV.OC-02_PR.AT-01__transparency_Medium definition
182_Technical variables, such as traceability and verifiability, User-level variables such as reliability, understandable explanations, and responsiveness to feedback, and Community-level variables such as justified trust_PR.AT-02_GV.OC-02__transparency_High
184_Designers should identify a number of strict laws, that is, task- and community-specific norms that should never be violated, and the failsafe components should continuously monitor operations against possible violations of these laws._DE.CM-09_ID.RA-01___High
181_Relevant examples of these two are: (A) symbolic agents that have explicit representations of plans, actions, goals, etc.; and (B) machine learning systems that train subsymbolic mechanisms with acceptable ethical behavior._ID.AM-02_PR.PS-06___Medium definition
186_To evaluate a system's norm-conforming behavior, one must describe—and ideally, formally specify—criterion behaviors that reflect the previously identified norms, describe what the user expects the system to do, verify that the system really does this, and validate that the specification actually matches the criteria._ID.RA-01_DE.CM-09___High
229_Creators of A/IS for application in legal systems should provide clear and accessible guidance for the knowledge, skills, and experience required of the human operators of the A/IS if the systems are to achieve expected levels of effectiveness._PR.AT-02_GV.RR-02___High
181-182_Such traceability in turn calibrates a community's trust about whether A/IS are conforming to the norms and values relevant in their use contexts._DE.CM-09_ID.RA-01__transparency_High
182_Transparency must be open to appropriate public examination and oversight._GV.OV-03_RS.CO-03__transparency_High
236-237_Apportioning responsibility. An essential component of informed trust in a technological system is confidence that it is possible, if the need arises, to apportion responsibility among the human agents engaged along the path of its creation and application: from design through to development, procurement, deployment, operation, and, finally, validation of effectiveness._GV.RR-02_GV.SC-02___High definition
237_Unless there are mechanisms to hold the agents engaged in these steps accountable, it will be difficult or impossible to assess responsibility for the outcome of the system under any framework, whether a formal legal framework or a less formal normative framework._GV.RR-02_GV.OV-03___High
231_The human operator is an integral component of A/IS. Almost all current applications of A/IS in legal systems, like those in most other fields, require human mediation and likely will continue to do so for the near future. This human mediation, post design and post development, will take a number of forms, including decisions about (a) whether or not to use A/IS for a given purpose, (b) the data used to train the systems, (c) settings for system parameters to be used in generating results, (d) methods of validating results, (e) interpretation and application of the results._PR.AT-02_GV.RR-02___High definition