text_extract;highlight_color
"Take appropriate measures throughout the development of advanced AI systems, including prior to and throughout their deployment and placement on the market, to identify, evaluate, and mitigate risks across the AI lifecycle";green
"This includes employing diverse internal and independent external testing measures, through a combination of methods such as red-teaming, and implementing appropriate mitigation to address identified risks and vulnerabilities";green
"developers should seek to enable traceability, in relation to datasets, processes, and decisions made during system development";yellow
"Organizations should use, as and when appropriate commensurate to the level of risk, AI systems as intended and monitor for vulnerabilities, incidents, emerging risks and misuse after deployment, and take appropriate action to address these";green
"consider, for example, facilitating third-party and user discovery and reporting of issues and vulnerabilities after deployment";green
"Organizations are further encouraged to maintain appropriate documentation of reported incidents and to mitigate the identified risks and vulnerabilities, in collaboration with other stakeholders";green
"Mechanisms to report vulnerabilities, where appropriate, should be accessible to a diverse set of stakeholders";yellow
"Publicly report advanced AI systems' capabilities, limitations and domains of appropriate and inappropriate use, to support ensuring sufficient transparency, thereby contributing to increase accountability";green
"This should include publishing transparency reports containing meaningful information for all new significant releases of advanced AI systems";green
"Organizations should make the information in the transparency reports sufficiently clear and understandable to enable deployers and users as appropriate and relevant to interpret the model/system's output and to enable users to use it appropriately";green
"Work towards responsible information sharing and reporting of incidents among organizations developing advanced AI systems including with industry, governments, civil society, and academia";green
"This includes responsibly sharing information, as appropriate, including, but not limited to evaluation reports, information on security and safety risks, dangerous intended or unintended capabilities, and attempts by AI actors to circumvent safeguards across the AI lifecycle";green
"Develop, implement and disclose AI governance and risk management policies, grounded in a risk-based approach â€“ including privacy policies, and mitigation measures, in particular for organizations developing advanced AI systems";green
"This includes disclosing where appropriate privacy policies, including for personal data, user prompts and advanced AI system outputs";green
"Organizations are expected to establish and disclose their AI governance policies and organizational mechanisms to implement these policies in accordance with a risk-based approach";green
"Invest in and implement robust security controls, including physical security, cybersecurity and insider threat safeguards across the AI lifecycle";green
"These may include securing model weights and algorithms, servers, and datasets, such as through operational security measures for information security and appropriate cyber/physical access controls";green
"Develop and deploy reliable content authentication and provenance mechanisms, where technically feasible, such as watermarking or other techniques to enable users to identify AI-generated content";green
"This includes, where appropriate and technically feasible, content authentication such provenance mechanisms for content created with an organization's advanced AI system";yellow
"Organizations should also endeavor to develop tools or APIs to allow users to determine if particular content was created with their advanced AI system such as via watermarks";green
"Organizations are further encouraged to implement other mechanisms such as labeling or disclaimers to enable users, where possible and appropriate, to know when they are interacting with an AI system";green
"Prioritize research to mitigate societal, safety and security risks and prioritize investment in effective mitigation measures";green
"This includes conducting, collaborating on and investing in research that supports the advancement of AI safety, security and trust, and addressing key risks, as well as investing in developing appropriate mitigation tools";green
"Organizations should prioritize responsible stewardship of trustworthy and human-centric AI and also support digital literacy initiatives";yellow
"Advance the development of and, where appropriate, adoption of international technical standards";yellow
"This includes contributing to the development and, where appropriate, use of international technical standards and best practices, including for watermarking, and working with Standards Development Organizations";yellow
"Implement appropriate data input measures and protections for personal data and intellectual property";green
"Organizations are encouraged to take appropriate measures to manage data quality, including training data and data collection, to mitigate against harmful biases";green
"Appropriate transparency of training datasets should also be supported and organizations should comply with applicable legal frameworks";green
"Organizations should not develop or deploy advanced AI systems in a way that undermines democratic values, are particularly harmful to individuals or communities, facilitate terrorism, enable criminal misuse, or pose substantial risks to safety, security, and human rights, and are thus not acceptable";green
"While harnessing the opportunities of innovation, organizations should respect the rule of law, human rights, due process, diversity, fairness and non-discrimination, democracy, and human-centricity, in the design, development and deployment of advanced AI systems";green
"States must abide by their obligations under international human rights law to promote that human rights are fully respected and protected, while private sector activities should be in line with international frameworks such as the United Nations Guiding Principles on Business and Human Rights and the OECD Guidelines for Multinational Enterprises";green
"Identify and mitigate vulnerabilities, and, where appropriate, incidents and patterns of misuse, after deployment including placement on the market";green
"transparency reporting should be supported and informed by robust documentation processes";yellow
"This should include accountability and governance processes to evaluate and mitigate risks, where feasible throughout the AI lifecycle";green
"addressing key risks, as well as investing in developing appropriate mitigation tools";yellow
"We call on organizations in consultation with other relevant stakeholders to follow these actions, in line with a risk-based approach, while governments develop more enduring and/or detailed governance and regulatory approaches";yellow
"We also commit to develop proposals, in consultation with the OECD, GPAI and other stakeholders, to introduce monitoring tools and mechanisms to help organizations stay accountable for the implementation of these actions";yellow
"We encourage organizations to support the development of effective monitoring mechanisms, which we may explore to develop, by contributing best practices";yellow
