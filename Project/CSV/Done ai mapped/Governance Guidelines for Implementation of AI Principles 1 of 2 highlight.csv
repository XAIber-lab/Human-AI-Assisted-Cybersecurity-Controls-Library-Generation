text_extract;highlight_color
Companies that develop and operate AI systems should, under the leadership of top management, understand not only positive impacts but also negative impacts, including unintended risks, that AI systems may have. This information should be reported to the top management and shared among those in top managerial positions, and their understanding should be updated in a timely manner;green
we investigated whether any incidents were reported in the past regarding AI systems whose functions or fields of application are the same or similar to those of the system that we are going to develop and operate, and even if there were no reports of such incidents, we examined whether there were reports anticipating specific possibilities of incidents;yellow
we plan to perform in-depth impact analyses of individual AI systems through the gap analysis;yellow
while recognizing that social acceptance of AI systems can differ from country/region to country/region, we also referred to the incident database listed in Column: Sharing Incidents later. In our analysis, we see that many incidents relate to the management of personal information, fairness, and security;yellow
we have roughly classified incidents that have had a negative impact on society and potential negative impacts that some anticipate, in light of general frameworks in order to develop an overall picture about them;yellow
analyses of positive and negative impacts of AI can be made more useful by combining information gleaned from our own experience with information from the experience of other companies in our industry, and in some cases, from the experience in other industries;green
by continuing these analyses at a certain interval, we are able to look into revising our AI governance goals in a timely manner before an incident occurs;green
CONTEXT chapter corresponds to conditions and risks analysis, presents a general framework from the perspective of the relationship between the OECD AI principles and industrial sectors, as well as from the perspectives of business function, potentially impacted stakeholders, and scope of impacts;red
Companies that develop and operate AI systems should understand the current state of social acceptance based on opinions of not only direct stakeholders, but potential stakeholders before full-scale provision of the AI systems;green
we carried out questionnaire surveys and published their results on the status of consumers' understanding of AI, their expectations, perceived challenges, intentions to use AI, AI-provided services that consumers use, and how much they recognize and understand the risks;green
we actively send personnel to seminars and conferences on AI ethics and quality that are organized by universities and industry organizations;yellow
we invite experts who are familiar with social acceptance of AI and hold regular expert meetings;green
we draw on the expert meetings not only to have them assess our AI management system and our operations, but also to deepen our understanding of the conditions in which we operate, such as general social acceptance of AI;green
Companies that develop and operate AI systems should evaluate and re-evaluate their AI proficiency based on the extent of the company's experience in developing and operating AI systems;green
effective way to address the issue of negative impacts that may result from AI system development and operation is in most cases to learn from past incidents;green
The AI Incident Database (AIID) was released in November 2020. More than 1000 incidents are posted on AIID with their URL links, and a search app is also provided;red
Because AI systems are built inductively based on data sets and many of their negative impacts are unintentional, it is useful to understand past incidents in order to reduce the negative impacts;green
Companies that develop and operate AI systems should evaluate and re-evaluate their AI proficiency based on the extent of the company's experience in developing and operating AI systems;green
it becomes important to look at an index of AI proficiency (how much the company is ready for developing and operating AI systems), which makes it visible how much the company can respond to the negative impacts of AI;green
we evaluate whether the magnitude of impacts that our company's AI systems may have on society and the scope of relevant stakeholders are proportionate to our company's level of AI proficiency;green
Companies that develop and operate AI systems should identify a gap between AI governance goals and current state in the AI systems they are developing and operating, and if any negative impacts are found upon evaluating the impacts resulting from the gap, determine whether or not the negative impacts would be acceptable, taking into account their severity, scope, and frequency of occurrence;green
The technology officer defines perspectives for gap analysis from the Social Principles of Human-Centric AI and instructs development personnel to identify gaps for each perspective, evaluate impacts caused by the gaps, and report the results to the technology officer as soon as practically possible in all AI system development projects;green
The committee is composed of individuals other than those engaged in development and operation projects of each AI systems, and their mission is to analyze gaps on a project basis between the current state and our company's AI policy;green
in cases where it is clear that the negative impacts are minor, other modes of gap analysis operation may be allowed, for example, having AI management personnel present at project meetings carry out simple gap analysis instead of conducting a uniform and strict gap analysis;yellow
create lists for gap analysis based on our AI policy, use the lists to identify gaps in AI system development and operation, and evaluate the impacts caused by the gaps;green
We also select actual projects and have AI management personnel work alongside project personnel to refine the lists and make them standard process in the management system operation;green
if there is any concern about the appropriateness of the report, the AI governance officer will communicate his/her concern to the officer overseeing the project and make some necessary adjustment;green
The negative impacts of AI systems vary greatly depending on their application, scope, and mode of use;red
Some of the ethical issues of AI can be addressed through technical approaches, such as preparing sufficient data sets to obtain reasonable output, but this may not be enough in socially sensitive areas in some cases;yellow
when developing or using AI systems in sensitive fields where we have no previous experience, we make sure that individual consultations are made instead of going through our regular process;green
we compile and provide risk related information - information that we implement proper risk management, take measures to minimize negative impacts, and implement rigorous information security management - on our AI systems operations in a way that inexperienced consumers are able to understand, and also make a contact point easily accessible;green
Since AI literacy is relatively high at our service recipients, we provide succinct explanations with technical terms about the possibility that certain gaps can be found in the AI system that we provide and measures we take to address the gaps;yellow
we indicate in an easy-to-understand way that AI is used and clarify the advantages and disadvantages of using AI. We also let users know that we offer alternative services for AI system users who prefer not to use the AI mode;green
have also established ongoing communication with consumers, using the Guidebook on Corporate Governance for Privacy in Digital Transformation (DX) ver 1.1 as a reference;yellow
we make it clear in our agreement with our AI developer that we can have the developer provide us with the information that we will need to respond to inquiries from AI system users;green
Companies that provide data should provide information on the data sets including data collection sources, collection policies, collection criteria, annotation criteria, and limitation on use to ensure that companies that develop AI systems are able to appropriately conduct gap analysis;green
Companies that develop and operate AI systems should strategically improve AI literacy in order to properly operate their AI management system, considering outside learning materials as an option;green
we use in-house learning materials with extensive coverage of case examples based on specific applications of our own AI systems instead of general-purpose third-party training materials;yellow
recommendations given by a committee made up of invited external experts raised our management's interest in AI ethics, and we have since created an independent e-learning course solely on AI ethics which all employees are now required to take;green