15_The risk-management system should consist of a continuous, iterative process that is planned and run throughout the entire lifecycle of a high-risk AI system. That process should be aimed at identifying and mitigating the relevant risks of AI systems on health, safety and fundamental rights_GV.RM-01; GV.RM-02_ID.RA-05_GV.SC-01__High_

15_The risk-management system should be regularly reviewed and updated to ensure its continuing effectiveness, as well as justification and documentation of any significant decisions and actions taken subject to this Regulation. This process should ensure that the provider identifies risks or adverse impacts and implements mitigation measures for the known and reasonably foreseeable risks of AI systems_GV.OV-01; GV.OV-02_ID.RA-06_GV.PO-02__High_

15_The risk-management system should adopt the most appropriate risk-management measures in light of the state of the art in AI. When identifying the most appropriate risk-management measures, the provider should document and explain the choices made and, when relevant, involve experts and external stakeholders_GV.RM-06_GV.SC-01_ID.RA-06__High_

16_Requirements should apply to high-risk AI systems as regards risk management, the quality and relevance of data sets used, technical documentation and record-keeping, transparency and the provision of information to deployers, human oversight, and robustness, accuracy and cybersecurity_GV.PO-01_ID.AM-08_PR.DS-01_transparency_High_

17_High-quality data and access to high-quality data plays a vital role in providing structure and in ensuring the performance of many AI systems, especially when techniques involving the training of models are used_PR.DS-01_ID.AM-07_ID.RA-01_data protection_Medium_definition

17_Data sets for training, validation and testing require the implementation of appropriate data governance and management practices. Data sets for training, validation and testing, including the labels, should be relevant, sufficiently representative, and to the best extent possible free of errors_PR.DS-01; PR.DS-02_ID.AM-07_PR.PS-01_data protection_High_

19_The right to privacy and to protection of personal data must be guaranteed throughout the entire lifecycle of the AI system_PR.DS-01; PR.DS-02_GV.OC-03_PR.AA-05_privacy_High_

19_Measures taken by providers to ensure compliance with those principles may include not only anonymisation and encryption, but also the use of technology that permits algorithms to be brought to the data_PR.DS-01; PR.DS-02_PR.PS-01_ID.AM-08_privacy; data protection_High_

20_Having comprehensible information on how high-risk AI systems have been developed and how they perform throughout their lifetime is essential to enable traceability of those systems_ID.AM-08_PR.PS-04_GV.OV-03_transparency_High_

21_High-risk AI systems should be designed in a manner to enable deployers to understand how the AI system works, evaluate its functionality, and comprehend its strengths and limitations_ID.AM-08_PR.AT-01_GV.OC-02_transparency_High_

22_High-risk AI systems should be designed and developed in such a way that natural persons can oversee their functioning_PR.AT-01; PR.AT-02_GV.RR-02_ID.AM-08_transparency_High_

22_It is also essential to ensure that high-risk AI systems include mechanisms to guide and inform a natural person to whom human oversight has been assigned to make informed decisions_PR.AT-01; PR.AT-02_GV.RR-02_ID.AM-08_transparency_High_

24_Technical robustness is a key requirement for high-risk AI systems. They should be resilient in relation to harmful or otherwise undesirable behaviour_PR.IR-01; PR.IR-03_PR.PS-01_DE.CM-09__High_

24_Technical and organisational measures should be taken to ensure robustness of high-risk AI systems, for example by designing and developing appropriate technical solutions to prevent or minimize harmful behaviour_PR.IR-01; PR.IR-03_PR.PS-06_DE.CM-09__High_

24_Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties_PR.IR-01; PR.IR-03_DE.CM-09_PR.PS-04__High_

30_It is important to ensure that, under all circumstances, a person established in the Union can provide authorities with all the necessary information on the compliance of an AI system_GV.RR-02_GV.OC-03_RS.CO-02__Medium_

31_Operators could act in more than one role at the same time and should therefore fulfil cumulatively all relevant obligations associated with those roles_GV.RR-02_GV.PO-01___Medium_

33_Along the AI value chain multiple parties often supply AI systems, tools and services but also components or processes that are incorporated by the provider_GV.SC-01_ID.AM-04_GV.SC-02__Medium_definition

35_Deployers should in particular take appropriate technical and organisational measures to ensure they use high-risk AI systems in accordance with the instructions of use_PR.AT-01; PR.AT-02_GV.RR-02_ID.AM-08__High_

35_Furthermore, deployers should ensure that the persons assigned to implement the instructions for use and human oversight have the necessary competence_PR.AT-01; PR.AT-02_GV.RR-02_GV.RR-04__High_

37_Deployers are best placed to understand how the high-risk AI system will be used concretely and can therefore identify potential significant risks_ID.RA-03; ID.RA-04_GV.RM-05_DE.AE-04__Medium_

39_The aim of the fundamental rights impact assessment is for the deployer to identify the specific risks to the rights of individuals or groups of individuals likely to be affected_ID.RA-04; ID.RA-05_GV.OC-03_GV.RM-06__High_

40_The impact assessment should be performed prior to deploying the high-risk AI system, and should be updated when the deployer considers that any of the relevant factors have changed_ID.RA-04; ID.RA-05_GV.PO-02_ID.RA-07__High_

43_Technical documentation should be prepared and kept up to date by the general-purpose AI model provider_ID.AM-08_GV.PO-02_PR.PS-01__High_

47_Providers that place general-purpose AI models on the Union market should ensure compliance with the relevant obligations in this Regulation_GV.OC-03_GV.PO-01_GV.RR-01__High_

50_General-purpose AI models could pose systemic risks which include any actual or reasonably foreseeable negative effects in relation to major accidents, disruptions of critical sectors and serious consequences_ID.RA-03; ID.RA-04_GV.RM-06_DE.AE-04__High_definition

50_Systemic risks should be understood to increase with model capabilities and model reach, can arise along the entire lifecycle of the model, and are influenced by conditions of misuse, model reliability, model fairness and model security_ID.RA-03; ID.RA-04_GV.RM-06_DE.AE-04__High_definition