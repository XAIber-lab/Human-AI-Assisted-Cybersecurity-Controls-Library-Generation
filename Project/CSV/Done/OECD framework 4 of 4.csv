41;Standardisation of data formats facilitates interoperability and data re-use across applications and for accessibility, and can help ensure that data are findable, catalogued, searchable and re-usable. The use of standardised formats may improve an AI system's robustness and security by making it easier to address security vulnerabilities;medium, definition
41;Performing checks: For data quality and appropriateness.;high
41;Transparent information about the data and inputs used in the AI system: Providing interested stakeholders with access to meaningful information on the data and inputs used in the AI system.;high
41;Labelling data: Such as tagging data with informative data.;medium
41;Protecting personal data.;high
41;Documenting data and dataset characteristics.;high
41;Using tools or processes for trustworthy AI: Such as guidelines, governance frameworks, product development/lifecycle tools, risk management, sector-specific codes of conduct, process standards, technical validation approaches, technical documentation, technical standards, toolkits/toolboxes/software tools, educational material, change-management processes, and certification;high
43;It is important to note that AI models can be built to achieve a specific set of objectives but then used with different objectives, as in the case of transfer learning;low, definition
43;Is it clear what the objectives of the AI system are, i.e. is it possible to formalise the problem that the system is being asked to solve?;high
43;Does the AI system provide useful and meaningful information for understanding its performance and outputs/decisions?;high
43;Can all of the AI system's outputs – both intermediary and final – for achieving a given goal be explained?;high
43;Can the determinant data or knowledge that an AI system uses to make decisions be identified?;high
43;Do two similar-looking cases verifiably result in similar outcomes, i.e. can the consistency and integrity of AI system outcomes be verified?;high
43;Do safety metrics exist that can evaluate the safety of an AI system for a given use case?;high
43;How does the entity deploying the AI system test for safety during development?;high
43;What measures has the entity deploying the AI system taken to do an adversarial evaluation – that is, explore the AI system through the lens of being a "bad actor" and trying to break it?;high
43;Does the AI system change significantly if it is trained with variations of the data available?;high
43;Are there measures in place to validate and verify the AI system's outcomes?;high
43;What measures are in place to facilitate traceability in the AI system, including in relation to datasets, processes and decisions made during the AI system lifecycle?;high
47;Model evolution and model drift (where a model degrades because of changes in data, input or output) are directly relevant to safety, security and robustness as well as accountability and liability;medium, definition
47;There may be a trade-off between the adaptive nature of an AI system (i.e. whether the model evolves in the field based on input from its environment) and the quality of its outcomes. This trade-off may be more acute with real-time data, as more conflicting data may arrive faster, creating a further risk of compromising the quality of the outcomes;medium, definition
48;Understanding how an AI system's model was developed and/or maintained is a key consideration for assigning roles and responsibilities throughout a risk-management process. It is also relevant to assessing the system's robustness, security and safety as well as accountability;high
48;Model verification and validation involves data scientists, data/model/systems engineers and governance experts;medium, definition
48;Verification and validation to execute and tune models, including metrics to authorise the system for broader deployment;high
48;Federated learning helps to address critical issues like privacy, data security and data access rights by building models without sharing data;medium, definition
49;When it comes to testing to assess performance across various dimensions and considerations, characteristics of the team of AI system developers – such as gender, country, cultural background – have been shown to impact the way AI systems are built, as developers can incorporate unconscious biases;medium
49;Make stakeholders aware of their interactions with AI systems, including in the workplace;high
49;Enable those affected by an AI system to understand and challenge the outcome and how it was produced by the AI model;high
50;For policy purposes, understanding the purpose of an AI system is important for identifying the necessary level of human oversight, the explainability needed, and the extent of testing required;medium
50;Model-building and interpretation involve the creation or selection of models/algorithms, their calibration and/or training and inferencing (use). It also involves verification and validation, whereby models are executed and tuned (maximising performance) with tests to assess performance across various dimensions and considerations;medium, definition