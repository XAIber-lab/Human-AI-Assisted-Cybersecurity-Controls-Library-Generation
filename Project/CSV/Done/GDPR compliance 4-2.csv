Page of the document;Text
31;"The GDPR established in Article 32 that both the controller and the processor shall apply suitable technical and organisational measures to guarantee a suitable security level with regard to the data subjects' rights and freedoms. Such measures shall be adapted taking into account the costs of the implementation, the nature, the scope, the context and the purposes of the processing, as well as the variable risks of probability and severity. There is no standard solution for all processings and much less for those including an AI component. The solution must be assessed through a risk analysis that must be related to the risks for the rights and freedoms of the data subjects from the point of view of data protection."
35;"The validation of the processing including an AI component must be performed under conditions reflecting the real context where the processing is expected to be deployed"
35;"The validation process requires a periodic review, taking into account that such context or the processing itself could change and evolve."
35;"The tests of the AI component guarantee that the design and development results comply with the requirements of the component. The scope of the validation of the processing extends even further. It should garantee that the resulting products and services meet the requirements regarding a specific application or envisaged use"
38;"For each phase of a processing, regardless of whether the phase includes an AI component or not, a different extent of the total personal data regarding the same data subject needs to be processed. In general terms, it is not necessary to access the full extent of the available personal data in every phase. Therefore, data minimisation strategies used for every phase of the processing should differ, and they should likewise differ in each of the phases of the life cycle of the AI-based solution: the training phase, the inference phase or the model evolution phase. It should be taken into account the limitations established by the legal basis itself."
40;"The existence of log files or activity records, the performance of audits (be they automated or manual) and the certification of the process are inherent to the "accountability" strategies or proactive responsibility strategies, but they also arise out of the legal requirements that are specifically established in the sectorial regulation."
40;"The log files shall be necessary to support the audit processes and the security mechanisms, with regard to data protection, said log files shall provide evidence in order to:

Establish who and under what circumstances accesses the personal data that may be included within the model.
Provide traceability with regard to the update of the inference models, the communications of the user API with the model and the detection of abuse or intrusion attempts.
Provide traceability to enable governance in data disclosure among all intervening parties in the AI-based solution with regard to the obligations arising out of Recital 66 of the GDPR.
Provide a follow-up of the quality parameters of the inference when the AI is used for decision-making or in assistance processes to the decision-making."

32;"Data controllers adopting this type of solutions and systems must provide precise information and specific training to their personnel on the limitations of the AI system."
32;"Whenever the processing is a tool that helps in decision-making, it is necessary to adopt measures to manage the risk that the humans behave like a mere link to the inferences made by the AI solution. Such measures include information on the operator (as indicated above), training and behaviour audits."
32;"In the event that the solutions are released by a third party, the latter must provide sufficient information to the controller so that the controller may manage such risks as well as information on the best way to proceed in this regard."