page;text
6;"generative technologies also introduce new risks and potential user harms. These risks include issues of copyright and intellectual property, the circumvention or reverse-engineering of prompts through attacks, the production of hateful, toxic, or profane language, the disclosure of sensitive or personal information, the production of malicious source code, and a lack of representation of minority groups due to underrepresentation in the training data"
7;"Test & monitor for user harms. Identify relevant user harms (e.g. bias, toxic content, misinformation) and include mechanisms that test and monitor for them"
7;"Expose or limit emergent behaviors. Determine whether generative capabilities beyond the intended use case should be surfaced to the user or restricted"
7;"Identify & resolve value tensions. Consider and balance different values across people involved in the creation, adoption, and usage of the AI system"
7;"Use a human-centered approach. Design for the user by understanding their needs and pain points, and not for the technology or its capabilities"
7;"Teach effective use. Help the user learn how to effectively use the AI system by providing explanations of features and examples through in-context mechanisms and documentation"
7;"Support co-editing of generated outputs. Allow both the user and the AI system to improve generated outputs"
7;"Calibrate trust using explanations. Be clear and upfront about how well the AI system performs different tasks by explaining its capabilities and limitations"
7;"Use friction to avoid overreliance. Encourage the user to review and think critically about outputs by designing mechanisms that slow them down at key decision-making points"
7;"Make uncertainty visible. Caution the user that outputs may not align with their expectations and identify detectable uncertainties or flaws"
7;"Evaluate outputs using domain-specific metrics. Help the user identify outputs that satisfy measurable quality criteria"
7;"Provide feedback mechanisms. Collect user feedback to improve the training of the AI system"
8;"Enable curation & annotation. Design user-driven or automated mechanisms for organizing, labeling, filtering, and/or sorting outputs"
8;"Draw attention to differences or variations across outputs. Help the user identify how outputs generated from the same prompt differ from each other"
8;"Understand the user's mental model. Build upon the user's existing mental models and evaluate how they think about your application: its capabilities, limitations, and how to work with it effectively"
8;"Teach the AI system about the user. Capture the user's expectations, behaviors, and preferences to improve the AI system's interactions with them"