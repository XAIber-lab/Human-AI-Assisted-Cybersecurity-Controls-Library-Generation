Page;Extract
5;"Ensuring transparency and explainability during development and due process rights in application"
5;"Many elements of the rule of law and democratic societies rely on access to information. Transparency facilitates public discourse, evidence-based policymaking, regulatory oversight, judicial review, and journalistic scrutiny."
5;"In the case of AI-powered biometric technologies, understanding how AI systems work and how algorithms arrive at their decision promotes public trust in the responsible use of such technologies and ensures democratic norms during development and application."
5;"However, private companies often keep crucial information about the inner workings of AI systems under wraps. This makes it difficult to understand exactly how biometric information is processed and where errors in biometric data analysis may originate."
5;"While we might not know how an AI system produces unintended results, we can know what was intended for the system in the first place. Requiring the transparency of training data and procedure, documentation detailing performance characteristics, and iterations of algorithms, for example, sheds light on the explainability of AI systems."
6;"Develop audit trail requirements and documentation of AI-powered biometric systems that cover all steps of the AI development process, which could include model architecture, training data, records of exhibited bias and previous predictions, etc."
6;"Require private companies to provide a right to explanation of decisions made by automated or AI systems."
6;"Implement executive and legislative actions to mandate developers of AI systems to provide access for auditing via independent regulatory agencies, such as the Federal Trade Commission (FTC), or third-party organizations."
7;"Third parties like researchers, civil society groups, community organizations, and regulators also need access to transparency and explainability information used internally by an organization, so they can fully understand and assess the design and deployment of AI-powered biometric technologies."
8;"Other parts of internal accountability regimes, however, are not technical. Companies developing AI tools need not only internal ethical guidelines (e.g., policies on transparency and explainability) but also human involvement in accountability structures, such as "rank-and-file employee representation on the board of directors, external ethics advisory boards, and the implementation of independent monitoring and transparency efforts.""
8;"Implement executive and legislative actions to allow third-party auditor access to AI data and source code, as well as other transparency and explainability information, for the purposes of external researcher, civil society, and regulator assessments."