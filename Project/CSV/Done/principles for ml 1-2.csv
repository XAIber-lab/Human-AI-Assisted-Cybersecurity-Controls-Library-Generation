Page;Text
9;It will never be possible to assure complete security against adversaries, whose techniques are always evolving. The field of adversarial ML and AI is immature: new attack techniques appear regularly and there are significant limitations to existing defence methods. It's therefore important to ensure that you understand what your ML model may look like in different scenarios and the potential impact on your wider system.
9;Exploring these scenarios will help system designers decide whether additional mitigations are required to prevent undesirable behaviour if the ML model is attacked.
10;Create system models for worst-case scenarios and modelling the effects of integrity attacks.
10;Use the CIA (confidentiality, integrity, availability) triad and known ML vulnerabilities (as outlined in MITRE ATLAS) to explore further.
10;An effective way of capturing and sharing the necessary ML model information may be to treat it as a component in the system. Documenting inputs and outputs and highlighting limitations (such as uncertainties and value bounds) can be an effective way to do this.
10;The NCSC has guidance on understanding system-driven risk management.
8;Technical team members working on model development should be familiar with a range of attacks on ML systems. Some of these attacks are highlighted in this Microsoft blog on Failure Modes in Machine Learning and in the MITRE ATLAS framework. ATLAS is a knowledge base of adversary tactics, techniques and case studies for ML systems based on real-world observation, demonstrations from ML red teams and security groups, and the state of the possible from academic research.
8;As research in this field is fast moving, you should make sure that practitioners receive the right support to keep up to date with the latest attacks and vulnerabilities for ML techniques, or any other common vulnerabilities and exposures on applicable assets (such as models and datasets) or relevant software. A method capturing ML-related objective is cyber exercising.
8;Each application's development lifecycle will be different and it's important to integrate security reviews appropriately. For example, if you take an agile approach to development, consider integrating security reviews into each sprint.
8;If teams are aware of and accountable for security-related responsibilities through the lifecycle, it encourages a positive security culture. Depending on your specific development process, automated security testing may be an option, although it's still important to have a security-centred culture.
8;See below for guidance on incorporating security-focused activities throughout the development lifecycle. (Although it's important to tailor advice and implementation to your own requirements.)
8;NCSC guidance on secure development and deployment
8;OWASP Securing the SDLC
10;Consider how the design of your wider system can be used to limit the impact if the confidentiality, integrity or availability of the ML component (eg, model) is compromised. This may be baked in natively to the wider system design (including humans in the loop), or may require you to make design decisions based on ML component's limitations and your risk appetite.
10;The limitations of ML components can often be mitigated with non-ML components to restrict the model's effect on the wider system. But this may restrict the effectiveness of the ML component, which may cap its advantages to the system. It's important that both ML expertise and wider system/domain expertise are used in the design, and that people understand the limits of your ML components.
6;ML practitioner: 2.1 Consider your system's vulnerability to known ML threats, 2.2 Consider digital and physical supply chains risk, 2.5 Document the creation, operation and lifecycle management of assets, 2.6 Ensure your model capacity is proportionate to your requirements
6;Senior decision maker: 2.2 and 2.3 Consider digital and physical supply chains risk, 2.4 Secure your infrastructure
6;IT security professional: 2.1 Consider the vulnerability of your system to known ML threats, 2.2 and 2.3 Consider digital and physical supply chains risk, 2.4 Secure your infrastructure, 2.5 Document the creation, operation and lifecycle management of assets
6;ML practitioner: 4.1 Understand what continual learning is and the potential risks of using it, 4.2 Track and test continual learning models
6;Senior decision maker: 4.1 Understand what continual learning is and the potential risks of using it
6;ML practitioner: 5.1 Decommission your assets appropriately, 5.2 Collate lessons learned and share
6;Senior decision maker: 5.2 Collate lessons learned and share
6;IT security professional: 5.1 Decommission your assets appropriately, 5.2 Collate lessons learned and share
7;Ensuring that your ML practitioners, data scientists and software developers are familiar with the inherent vulnerabilities and failure modes in ML workflows and algorithms. They should follow best practices to reasonably mitigate the threats associated with them.
7;Security is considered a key part of your ML project and integrated into your workflows. Your team members at all levels understand this.
8;Enable and encourage a positive security culture and accountability by ensuring team members have the relevant security knowledge. Support this by providing training on the threats that are unique to ML components, where knowledge gaps are identified.
10;Ensure your design team and operational end users have experience across the range of disciplines or domains required for the system design process.
10;Encourage a cross-discipline culture that recognises the need to work collaboratively during the design process. Put in place processes and procedures to share knowledge and experience where disciplines meet and overlap. This is particularly important when highlighting the limitations of the ML components with the wider system designers. Ensure ML experts work collaboratively with system designers and formalise methods of exchanging information.