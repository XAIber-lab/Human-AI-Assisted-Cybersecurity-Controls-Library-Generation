Page of document;Text
41;The developers of the AI component whenever they are using ML-based solutions should implement other registers for the purposes of documenting and meeting the principle of accountability to allow a traceability of the origin of the training data and the validation of such data, as well as records of analysis performed on the validity of such data and the results thereof.
42;As establishes by the principle of accountability, the guarantees established to manage the risk must be documented and collect enough information to enable a satisfactory and verifiable accreditation of the actions taken. Such documentation must enable the traceability of the decisions and verifications made pursuant to the minimisation principles referred above. In summary, not only the processing needs to be audited, but the processing must be auditable throughout its life cycle, including upon withdrawal thereof.
42;More precisely, it is necessary to perform an audit to establish compliance with GDPR, as well as to verify the validity of the processing that is based on AI solutions. In order to be effective, the auditing process must be carried out under the same conditions as in a real operation context, more precisely, in order to assess:
42;• The existence of a documented process of analysis, development and/or implementation including, as the case may be, the relevant traceability evidence.
42;• The existence or absence of personal data, profiling or automated decisions on the data subjects without a human intervention, as well as the analysis of the efficiency of the anonymisation and the pseudonymisation methods.
42;• Analysis on the existence and legitimisation of the processing of special categories of data, more precisely with regard to inferred information.
42;• The legal grounds for the processing and identification of responsibilities.
42;• More precisely, when the legal grounds of the processing is the legitimate interest, an assessment of the balance between the different interests and impacts on the rights and freedoms with regard to the guarantees adopted.
43;• The information and the effectiveness of the implemented transparency mechanisms.
43;• The application of the principle of accountability and risk management for the rights and liberties of the data subjects and, more precisely, if the obligation or the need to carry out PIAs has been assessed and, if such was the case, the results of such PIAs.
43;• With regard to the above, the application of data protection measures by default and by design, inter alia:
43;o The prior analysis of the need to process personal data, in terms of quantity and extent, in the several phases pursuant to minimisation criteria.
43;o The analysis of the accuracy, fidelity, quality and biases of the data used or gathered for the development or the operation of the AI component, as well as the data sanitation methods used with regard to the data.
43;o The verification and performance of tests and validation of the precision, the accuracy, the convergence, the consistence, predictability and any other metrics on the eligibility of the algorithms used, profiling and inferences. Furthermore, the verification that such parameters meet the requirements needed for the processing.
43;• The suitability of the security measures in order to avoid privacy risks.
43;• The training and education of the data controller personnel involved in the development and operation of the AI component. In this last case, a special attention to the accurate interpretation of the inferences.
43;• The obligation, necessity and, as the case may be, the qualification of the DPO.
43;• The addition of mechanisms that guarantee the fulfilment of the rights of the data subjects, more precisely, the ex officio erasure of personal data, with a great attention to minors' rights.
43;• The fulfilment of the limitations on automated decisions without a human intervention, the assessment, as the case may be, of the quality of the human intervention and the supervisory mechanisms adopted. More precisely, when the legal grounds are the explicit consent, the identification of the guarantes adopted in order to verify that such a consent is free given.
43;• The application of some of the guarantees established in Chapter V of the GDPR in the event that international data transfers exist.
43;• In general terms, the fulfilment of the requirements and obligations of the GDPR and, more precisely, those stated in this document.
43;As previously established, the AI-based solution shall be integrated within a specific processing, with specific characteristics and a certain operational context. An audit of the isolated AI-based solution, without taking into account the context or the background, shall be incomplete and shall offer partial and unrealistic results.
43;A critical aspect of the audit is to guarantee that the AI-based solution is being used for the purpose for which it was designed, with special attention to its use by the operators of the system. Furthermore, when it is a component that has been acquired from a third party, the other collateral processing that could be performed by such component needs to assessed as well as whether legal or regulatory consequences that may arise out of such use.
43;The use of solutions or real-time automated audit tools is advisable in systems with automated decision-making in order to ensure that the output is consistent and precise, as well as in order to allow that erroneous decisions be aborted or cancelled before irreversible consequences arise.
44;The guarantees appearing in Chapter V of the GDPR "Transfers of personal data to third countries or international organisations" need to be applied to such transfers. It is especially important to establish mechanisms in order to allow the contracts signed in this context of international transfers to be managed smoothly, ensuring at the same time that the client, as data controller, has enough information on the contractors or prospect contractors and keeps the power to adopt decisions. When international transfers exist, data subjects must be informed pursuant to the terms in Articles 13 and 14 of the GDPR and such international transfers must be included within the records of processing activities.
41;If the data controller uses third party data sets for training an AI component, it must act with due diligence for verifying that the original data source is legitimate, including the purchase or service agreement, or the corresponding contractual clauses that claim evidences and commitments of such legitimacy
41;The controller shall be aware of the obligations and the limits established in the sectorial regulation, for such legal bases do not allow for the processing of personal data contained in the log file for different purposes such as the assessment of the performance or the evolution of the AI system. Therefore, the controller must ensure that guarantees are implemented to avoid access to and use of such record for purposes for which no legal grounds are available.