"Page of the document;text"
"1-2;AI literacy is essential for all personnel in order for them to quickly assess, describe, and respond to fast-moving, viral and dangerous threats such as disinformation and deepfakes."
"2;AI tools are now utilized in national security and to help protect against data breaches and cyberattacks."
"2;The CDAO includes five ethical principles of responsible, equitable, traceable, reliable, and governable as part of its responsible AI toolkit."
"2-3;Fostering an organizational culture that recognizes the sociotechnical nature of AI challenges. This must be communicated from the outset, and there must be a recognition of the practices, skill sets and thoughtfulness that need to be put into models and their management to monitor performance."
"3;Detailing ethics practices throughout the AI lifecycle, corresponding to business (or mission) goals, data preparation and modeling, evaluation and deployment."
"3;Providing interpretable AI model metadata (for example, as factsheets) specifying accountable persons, performance benchmarks (compared to human), data and methods used, audit records (date and by whom), and audit purpose and results."
"3;Establishing a center of excellence to give diverse, multidisciplinary teams a community for applied training to identify potential disparate impact."
"3;Using auditing tools to reflect the bias exhibited in models. If the reflection aligns with the values of the organization, transparency surrounding the chosen data and methods is key. If the reflection does not align with organizational values, then this is a signal that something must change."
"3;Measuring fairness and making equity standards actionable by providing functional and non-functional requirements for varying levels of service."
"4;Always make clear to users when they are interfacing with an AI system."
"4;Provide content grounding for AI models. Empower domain experts to curate and maintain trusted sources of data used to train models. Model output is based on the data it was trained on."
"4;Capture key metadata to render AI models transparent and keep track of model inventory. Make sure that this metadata is interpretable and that the right information is exposed to the appropriate personnel."
"4;Make this metadata easily findable by people (ultimately at the source of output)."
"4;Include human-in-the-loop as AI should augment and assist humans. This allows humans to provide feedback as AI systems operate."
"4;Create processes and frameworks to assess disparate impact and safety risks well before the model is deployed or procured. Designate accountable people to mitigate these risks."
"5;Establishing communities that constantly reaffirm why fair, reliable outputs are essential."
"5;Building reliability testing rationales around the guidelines and standards for data used in model training."
"5;Limit user access to model development, but gather diverse perspectives at the onset of a project to mitigate introducing bias."
"5;Perform privacy and security checks along the entire AI lifecycle."
"5;Include measures of accuracy in regularly scheduled audits. Be unequivocally forthright about how model performance compares to a human being. If the model fails to provide an accurate result, detail who is accountable for that model and what recourse users have."
"5;AI model investment does not stop at deployment. Dedicate resources to ensure models continue to behave as desired and expected. Assess and mitigate risk throughout the AI lifecycle, not just after deployment."
"5;Designating an accountable party who has a funded mandate to do the work of governance. They must have power."
"5;Invest in communication, community-building and education. Leverage tools such as watsonx.governance to monitor AI systems."
"5;Capture and manage AI model inventory as described above."
"5;Deploy cybersecurity measures across all models."
"6;IBM leads global efforts to shape the future of responsible AI and ethical AI metrics, standards, and best practices"