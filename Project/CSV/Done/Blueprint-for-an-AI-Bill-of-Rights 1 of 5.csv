page;extract;confidence_level
5;"Systems should undergo pre-deployment testing, risk identification and mitigation, and ongoing monitoring that demonstrate they are safe and effective based on their intended use, mitigation of unsafe outcomes including those beyond the intended use, and adherence to domain-specific standards";high
5;"You should be protected from inappropriate or irrelevant data use in the design, development, and deployment of automated systems, and from the compounded harm of its reuse";medium
5;"Independent evaluation and reporting that confirms that the system is safe and effective, including reporting of steps taken to mitigate potential harms, should be performed and the results made public whenever possible";high
5;"Designers, developers, and deployers of automated systems should take proactive and continuous measures to protect individuals and communities from algorithmic discrimination and to use and design systems in an equitable way";high
5;"This protection should include proactive equity assessments as part of the system design, use of representative data and protection against proxies for demographic features, ensuring accessibility for people with disabilities in design and development, pre-deployment and ongoing disparity testing and mitigation, and clear organizational oversight";high
6;"You should be protected from abusive data practices via built-in protections and you should have agency over how data about you is used";medium
6;"You should be protected from violations of privacy through design choices that ensure such protections are included by default, including ensuring that data collection conforms to reasonable expectations and that only data strictly necessary for the specific context is collected";high
6;"Designers, developers, and deployers of automated systems should seek your permission and respect your decisions regarding collection, use, access, transfer, and deletion of your data in appropriate ways and to the greatest extent possible";high
6;"Systems should not employ user experience and design decisions that obfuscate user choice or burden users with defaults that are privacy invasive";high
6;"Consent should only be used to justify collection of data in cases where it can be appropriately and meaningfully given";medium
6;"Any consent requests should be brief, be understandable in plain language, and give you agency over data collection and the specific context of use";high
6;"Enhanced protections and restrictions for data and inferences related to sensitive domains, including health, work, education, criminal justice, and finance, and for data pertaining to youth should put you first";medium
6;"You and your communities should be free from unchecked surveillance; surveillance technologies should be subject to heightened oversight that includes at least pre-deployment assessment of their potential harms and scope limits to protect privacy and civil liberties";high
6;"You should know that an automated system is being used and understand how and why it contributes to outcomes that impact you";high
6;"Designers, developers, and deployers of automated systems should provide generally accessible plain language documentation including clear descriptions of the overall system functioning and the role automation plays, notice that such systems are in use, the individual or organization responsible for the system, and explanations of outcomes that are clear, timely, and accessible";high
7;"You should be able to opt out, where appropriate, and have access to a person who can quickly consider and remedy problems you encounter";high
7;"You should have access to timely human consideration and remedy by a fallback and escalation process if an automated system fails, it produces an error, or you would like to appeal or contest its impacts on you";high
7;"Human consideration and fallback should be accessible, equitable, effective, maintained, accompanied by appropriate operator training, and should not impose an unreasonable burden on the public";high
7;"Automated systems with an intended use within sensitive domains, including, but not limited to, criminal justice, employment, education, and health, should additionally be tailored to the purpose, provide meaningful access for oversight, include training for any people interacting with the system, and incorporate human consideration for adverse or high-risk decisions";high
8;"Civil rights, civil liberties, and privacy, including freedom of speech, voting, and protections from discrimination, excessive punishment, unlawful surveillance, and violations of privacy and other freedoms in both public and private sector contexts";medium;definition
8;"Equal opportunities, including equitable access to education, housing, credit, employment, and other programs";low;definition
8;"Access to critical resources or services, such as healthcare, financial services, safety, social services, non-deceptive information about goods and services, and government benefits";low;definition
8;"The measures taken to realize the vision set forward in this framework should be proportionate with the extent and nature of the harm, or risk of harm, to people's rights, opportunities, and access";high
9;"Civil rights laws protect the American people against discrimination";low;definition
10;"Throughout this framework the term 'algorithmic discrimination' takes this meaning (and not a technical understanding of discrimination as distinguishing between items)";low;definition