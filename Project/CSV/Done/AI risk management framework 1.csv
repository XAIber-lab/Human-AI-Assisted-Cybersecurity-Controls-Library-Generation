

Actions, recommendations, best practices, etc. related to secure design, development, deployment, operation, configuration, and maintenance:

page 8;"Organizations need to establish and maintain the appropriate accountability mechanisms, roles and responsibilities, culture, and incentive structures for risk management to be effective."
page 8;"Effective risk management is realized through organizational commitment at senior levels and may require cultural change within an organization or industry."
page 9;"Ideally, risk management efforts start with the Plan and Design function in the application context and are performed throughout the AI system lifecycle."

Actions, recommendations, best practices, etc. related to safe and secure use, development, and provision of an AI system:

page 13;"Deployment of AI systems which are inaccurate, unreliable, or poorly generalized to data and settings beyond their training creates and increases negative AI risks and reduces trustworthiness."
page 14;"Employing safety considerations during the lifecycle and starting as early as possible with planning and design can prevent failures or conditions that can render a system dangerous."
page 14;"Other practical approaches for AI safety often relate to rigorous simulation and in-domain testing, real-time monitoring, and the ability to shut down, modify, or have human intervention into systems that deviate from intended or expected functionality."

Actions, recommendations, best practices, etc. related to defending, protecting, and monitoring the AI system, and handling logs:

page 15;"AI systems that can maintain confidentiality, integrity, and availability through protection mechanisms that prevent unauthorized access and use may be said to be secure."
page 15;"Guidelines in the NIST Cybersecurity Framework and Risk Management Framework are among those which are applicable here."

Actions, recommendations, best practices, etc. related to maintaining user safety and protecting their privacy:

page 14;"AI systems should "not under defined conditions, lead to a state in which human life, health, property, or the environment is endangered" (Source: ISO/IEC TS 5723:2022)."
page 14;"Safe operation of AI systems is improved through: responsible design, development, and deployment practices; clear information to deployers on responsible use of the system; responsible decision-making by deployers and end users; and explanations and documentation of risks based on empirical evidence of incidents."

Actions, recommendations, best practices, etc. related to user and stakeholder rights, allowing them to exercise their rights, and what they should be communicated:

page 15;"Transparency reflects the extent to which information about an AI system and its outputs is available to individuals interacting with such a system – regardless of whether they are even aware that they are doing so."
page 15;"Meaningful transparency provides access to appropriate levels of information based on the stage of the AI lifecycle and tailored to the role or knowledge of AI actors or individuals interacting with or using the AI system."

Actions, recommendations, best practices, etc. related to law, legislation, regulations, standardization, and rules compliance:

page 7;"The Framework is intended to be flexible and to augment existing risk practices which should align with applicable laws, regulations, and norms. Organizations should follow existing regulations and guidelines for risk criteria, tolerance, and response established by organizational, domain, discipline, sector, or professional requirements."

Actions, recommendations, best practices, etc. related to risk assessment, management, evaluation, response, mitigation, vulnerabilities identification, and threat identification:

page 6;"Risk tolerance refers to the organization's or AI actor's (see Appendix A) readiness to bear the risk in order to achieve its objectives. Risk tolerance can be influenced by legal or regulatory requirements (Adapted from: ISO GUIDE 73)."
page 7;"When applying the AI RMF, risks which the organization determines to be highest for the AI systems within a given context of use call for the most urgent prioritization and most thorough risk management process."
page 7;"In cases where an AI system presents unacceptable negative risk levels – such as where significant negative impacts are imminent, severe harms are actually occurring, or catastrophic risks are present – development and deployment should cease in a safe manner until risks can be sufficiently managed."

Actions, recommendations, best practices, etc. related to evaluation, validation, and testing of AI systems, networks, and components:

page 9;"Performed regularly, TEVV tasks can provide insights relative to technical, societal, legal, and ethical standards or norms, and can assist with anticipating impacts and assessing and tracking emergent risks."
page 9;"As a regular process within an AI lifecycle, TEVV allows for both mid-course remediation and post-hoc risk management."
page 13;"Validity and reliability for deployed AI systems are often assessed by ongoing testing or monitoring that confirms a system is performing as intended."

Actions, recommendations, best practices, etc. related to data protection, classification, storage, and data validation:

page 8;"Examples of overlapping risks include: privacy concerns related to the use of underlying data to train AI systems; the energy and environmental implications associated with resource-heavy computing demands; security concerns related to the confidentiality, integrity, and availability of the system and its training and output data; and general security of the underlying software and hardware for AI systems."