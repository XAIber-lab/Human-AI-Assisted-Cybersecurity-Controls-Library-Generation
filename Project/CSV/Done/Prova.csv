Category,Page,Text
Secure design/development/deployment/operation/configuration/maintenance,20,"Data and data governance: High-risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation, and testing datasets that meet a set of quality criteria"
Secure design/development/deployment/operation/configuration/maintenance,20,"Record-keeping: High-risk AI systems shall be designed and developed with capabilities enabling the automatic recording of events ('logs') while the high-risk AI systems is operating. Those logging capabilities shall conform to recognised standards or common specifications."
Secure design/development/deployment/operation/configuration/maintenance,20,"Transparency and provision of information to users: High-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable users to interpret the system's output and use it appropriately."
Secure design/development/deployment/operation/configuration/maintenance,20,"Human oversight: High-risk AI systems shall be designed and developed in such a way, including with appropriate humanâ€“machine interface tools, that they can be effectively overseen by natural persons during the period in which the AI system is in use."
Secure design/development/deployment/operation/configuration/maintenance,20-21,"Risk management system: An assessment through internal checks for 'stand-alone' high-risk AI systems would require a full, effective and properly documented ex ante compliance with all requirements of the regulation and compliance with robust quality and risk management systems and post-market monitoring. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems."
Secure design/development/deployment/operation/configuration/maintenance,21,"Quality management system: Providers of high-risk AI systems shall put a quality management system in place that ensures compliance with this Regulation. The provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system."
Safe and secure use/development/provision of AI systems,21,"Robustness: AI systems should be resilient against risks connected to the limitations of the system (e.g. errors, faults, inconsistencies, unexpected situations) as well as against malicious actions that may compromise the security of the AI system and result in harmful or otherwise undesirable behaviour."
Safe and secure use/development/provision of AI systems,22,"The technical solutions to address AI specific vulnerabilities shall include, where appropriate, measures to prevent and control for attacks trying to manipulate the training dataset ('data poisoning'), inputs designed to cause the model to make a mistake ('adversarial examples'), or model flaws."
Defending/protecting/monitoring AI systems and handling logs,20,"Record-keeping: High-risk AI systems shall be designed and developed with capabilities enabling the automatic recording of events ('logs') while the high-risk AI systems is operating. Those logging capabilities shall conform to recognised standards or common specifications."
Defending/protecting/monitoring AI systems and handling logs,22,"High-risk AI systems shall be resilient as regards attempts by unauthorised third parties to alter their use or performance by exploiting the system vulnerabilities."
User safety and privacy protection,22,"High-risk AI systems are to be accompanied by instructions for use, specifying, among other things, the 'the level of accuracy, robustness and cybersecurity referred to in Article 15 against which the high-risk AI system has been tested and validated and which can be expected, and any known and foreseeable circumstances that may have an impact on that expected level of accuracy, robustness and cybersecurity'."
User rights and communication,20,"Transparency and provision of information to users: High-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable users to interpret the system's output and use it appropriately."
Law/legislation/regulations/standardization/rules compliance,21,"Conformity assessment: AI systems that create a high risk to the health and safety or fundamental rights of natural persons: in line with a risk-based approach, these high-risk AI systems are permitted on the European market subject to compliance with certain mandatory requirements and an ex-ante conformity assessment."
Law/legislation/regulations/standardization/rules compliance,25,"Ensure regulatory coherence between the draft AI Act and legislation on cybersecurity. In particular, Article 42 of the draft AI Act sets out a presumption of conformity with cybersecurity requirements for high-risk AI systems that have been certified or for which a statement of conformity has been issued under a cybersecurity scheme pursuant to Regulation (EU) 2019/881 (the Cybersecurity Act)"
Risk assessment/management/evaluation/response/mitigation/threat identification,20-21,"Risk management system: An assessment through internal checks for 'stand-alone' high-risk AI systems would require a full, effective and properly documented ex ante compliance with all requirements of the regulation and compliance with robust quality and risk management systems and post-market monitoring. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems."
Risk assessment/management/evaluation/response/mitigation/threat identification,21,"ISO/IEC 31000 is a framework for risk analysis and the management of risk analysis systems. At a more detailed level, tools for vulnerability analysis (e.g. ETSI TS 102 165-1) may apply, as well as runtime analysis tools. Many development environments will perform both static and dynamic tests on software that allow risks in the codebase to be identified. The suite of measures should operate in concert."
Evaluation/validation/testing of AI systems,22,"High-risk AI systems are to be accompanied by instructions for use, specifying, among other things, the 'the level of accuracy, robustness and cybersecurity referred to in Article 15 against which the high-risk AI system has been tested and validated and which can be expected, and any known and foreseeable circumstances that may have an impact on that expected level of accuracy, robustness and cybersecurity'."
Data protection/classification/storage/validation,20,"Data and data governance: High-risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation, and testing datasets that meet a set of quality criteria"
Data protection/classification/storage/validation,20,"The requirements here address data quality, which is key to secure data feeds, processing and outputs. Data quality can be reinforced by the use of tools that verify the source of data and the integrity of data (i.e. to prove that data have not been manipulated between source and sink), and by limiting access to data."