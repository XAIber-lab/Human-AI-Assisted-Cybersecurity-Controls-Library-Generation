Page of the document;text
21;"Protecting data is a wider issue and the advice and regulations reflect this. Best practice is likely to include encrypting data at rest and in transit, keeping keys as secure as possible, implementing multi-factor authentication and, where necessary, in two person controls."
22;"It's therefore crucial that system owners implement a framework for monitoring and recording changes to an asset and its metadata throughout its life. Good documentation and monitoring strengthens your ability to respond when a dataset or model has been compromised, for example, through poisoning."
22;"Version control allows changes to be tracked and rolled back, and for metadata to be generated for confidence checking. Tracking changes between versions enables scrutiny between releases and updates and allows developers to understand and mitigate attacks or accidents."
22;"This has an overlap with preventing 'data leakage', where data used to train a model can be accidentally reused in validation."
22;"Collecting data in a machine-readable format has several advantages. One is that a digital catalogue for datasets and models can be created, allowing users to filter and search depending on requirements. Machine-readable data can also be consumed by other programs that can be used as security or monitoring solutions throughout the operational stage of the lifecycle. This can help implement tracking model behaviour, monitoring and logging user queries as outlined in principle 3.2 - Deployment: design for security."
22;"Good dataset documentation enables more trustworthy sharing of datasets. Hashing and digital signing of a dataset can ensure that recipients of a shared dataset can verify the authenticity of its contents."
23;"You know the intended use of the dataset, including where it can and can't be used."
23;"You know who is authorised to access your data."
23;"You know when your data needs to be deleted."
23;"You are aware of any biases in your data."
23;"You have considered what metadata should be captured, and for what purpose."
23;"You 'version-control' your dataset throughout its lifecycle, and can roll back datasets or models easily to help with root cause analysis."
23;"If a model is compromised model, you can roll back to a known safe state."
23;"You know what data you hold and where it is stored."
23;"If you are distributing your dataset or model, the recipients can verify the authenticity of the contents using attached metadata and confirm it hasn't been tampered with."
23;"You are monitoring key metrics that can be tracked across the data lifecycle."
24;"Track dataset information and updates in a consistent format that is readable by humans and that can be easily processed or parsed by a computer (eg, json, csv). This metadata should be paired with the dataset throughout its lifecycle and include updates to the dataset made throughout operation, via continual learning, as discussed in section 4 - In operation: continual/online learning."
24;"Track model information in a consistent format that is readable by humans and that can be easily processed or parsed by a computer (eg, json, csv). The model's metadata should be paired with it throughout its lifecycle and include updates to the model made throughout operation, via continual learning, as discussed in section 4 - In operation: continual/online learning."
24;"Empower your people with accountability for assets. Accountability can be for the creation of an asset and/or the maintenance of it."
24;"Ensure your development team follows good development operations management. Operations management is important for security because it covers policy compliance, configuration and management of development tools (eg, version-control software). This management should continue throughout the lifecycle."
25;"'Model capacity' describes how complicated a pattern or relationship is that a model can express, and is dictated by the architecture choice (for example, a neural network versus a decision tree) and, in some model types, the stipulated size of the model (i.e. its number of tuneable parameters). For a given model to perform well, it's important that its capacity fits the dataset size and variety. A model with capacity that is too low for a task won't generalise well and perform poorly. This can create security vulnerabilities especially around edge cases, lowering the entry barrier to to 'trick' your system. In contrast, a model with a capacity that is too high for the dataset also creates security vulnerabilities, such as increasing the proportion of feature space in which the model behaves unreliably (if the training data does not adequately cover the feature space) or even giving adversaries extra capacity in which to hide malware."
25;"To validate your model for security or robustness, it's important to understand (and be able to explain) your model's behaviour. This allows you to: • detect anomalous behaviour • better predict how the model will react to out of distribution (OoD) inputs (ie inputs that don't appear in its training data) • understand when you may require downstream rules or controls to constrain the output or effects of your model • build trust in the user base"
26;"The complexity of your model and size/quality of your dataset is justified for meeting your performance requirements."
26;"You understand the potential trade-off between interpretability and predictive power and the effects this can have on security."
26;"You can assess that your model capacity will be appropriate for the size and quality of your dataset."
27;"Test a range of model types on your data and assess their performance. This will help you make an informed decision about which model is best for your application, but also which performs best on security aspects."
27;"Assess the performance of a range of architecture types (where performance is likely to include robustness), using a bottom-up approach to selecting your model architecture. Start with classical ML and highly interpretable techniques where possible, rather than diving into the latest deep learning models."
27;"When you understand the performance of a range of architecture types, assess the trade-off between meeting performance requirements and the security and how explainable each architecture type is."
27;"Once you have narrowed down your model architecture type selection to the best performing ones, the next phase is to tune hyperparameters (and iterate). The aim of this stage is to ensure your model's capacity matches your requirements and dataset."
27;"Discuss with experienced practitioners in your team or research area where others have overcome similar problems to yours. This knowledge will speed up development time, allowing more time for fine tuning the model parameters to ensure a good fit between your model and training data."
27;"If your team has little direct knowledge or experience of the problem you're working on, a useful place to start may be to consider which models are not appropriate for this solution."
28;"Review the size and quality of your dataset against your requirements. The metrics you use to evaluate it will depend on your specific application, although there are many rules of thumb that can be applied here. The data scientists and practitioners should select which are most appropriate for your application."
28;"Common metrics for evaluating a dataset's quality include completeness, timeliness, validity, consistency, integrity and balance between classes."
28;"Where data is insufficient, several approaches may help. They include gathering more data, using transfer learning, augmentation of existing data and synthetic data generation. Selecting an algorithm that runs well on limited data may also prove useful."
28;"Attackers may exploit out of distribution (OoD) areas of the feature space for attacks. Where complex models are required, consider implementing OoD detection on inference inputs. Depending how your developer implements this, it could double up as detection mechanism for some adversarial attacks."
28-29;"Firstly, consider whether the use of more complex model (eg, a neural network) is justified for your use case. In many applications, particularly those using structured data, classical ML methods may achieve sufficient performance whilst being more interpretable and potentially subject to a smaller range of attacks. If a complex model is required, there are a range of techniques highlighted in research and academia for reducing the size of a complex model (often a neural network). Many fall under the umbrella technique of 'pruning'. Pruning occurs after you have a trained model and involves removing unnecessary neurons or weights. Pruning can have a detrimental impact on performance and should be used when other more pragmatic techniques have fallen short. When required, consider regularly pruning and simplifying your model during the development and testing process, rather than doing a final test pre- deployment."
29;"Where you have identified a requirement for your model to be pruned, how to best implement pruning for your model and application. Many techniques show promising signs in a laboratory environment but are relatively untested in deployment. Each defensive method has its own advantages and disadvantages (often a drop in performance). Some key metrics to evaluate when pruning are: • a model's accuracy before and after • a model's robustness before and after • a model's size before and after • computation time"
30;"Once your model is in operation, it may be vulnerable to a range of different attacks. These include: • evasion attacks, designed to make a model misclassify specific examples • extraction attacks, when an attacker uses repeated querying to build a copy of the model • inversion attacks, when an attacker aims to identify or reconstruct data on which the model was trained"
30;"Protecting information about your model will help strengthen the barrier to entry against an attacker."
30;"Knowledge of your model can enable prospective attackers to create better performing attacks against it. The range of this knowledge can be described on a scale between 'transparent box', when an attacker has complete information about a model's architecture, weights and biases, through to 'opaque box' when an attacker has no prior knowledge, except for the ability to query the model and view its decision. This knowledge may be derived directly via access to the model, or inferred via knowledge of the pipeline. For example, reconnaissance of pre-processing steps, such as the shape of input data, gives an attacker information that can be used to help move closer to a transparent box attack."
30;"If a model is used in more than one place (such as over a range of products), an attacker who gains access to one instance could then create an attack that is effective against all instances of that model. This is especially important when deploying a model in uncontrolled environments, when attackers are likely to have free access to hardware, for example, in a product that is mass produced and sold directly to consumers."