"Page of document;Text"
44;Commercialization, for entities and consumers in general, of processing including solutions based on disruptive technologies, such as technologies based on AI components, requests for the implementation of quality and security guarantees like in every other product.
44;The availability or novelty of a technology is not reason enough to commercialise products that do not meet a certain level of quality of service, especially when such requirements are laid down by regulation.
44;Researchers and the AI-based industry need guidelines to help them to get compliance and legal certainty in their projects, products and services.
44;With regard to the protection of personal data, compliance with the provisions in the GDPR requests a certain level of maturity in the AI solutions that makes it possible to objectively assess the compliance of the processing and the implementation of guarantees and measures to manage the risks.
45;The use of transparency, risk management strategies and audit and certification mechanisms will allow for compliance with the provisions in the GDPR but this will also enhance trust by users in AI-based products and services and open a new market within this sector: privacy engineers, data scientist, auditors, certification schemes, authorised professionals, etc.
45;AI-applications may be a useful tool to implement guarantees to ensure data protection.
41;The developers of the AI component whenever they are using ML-based solutions should implement other registers for the purposes of documenting and meeting the principle of accountability to allow a traceability of the origin of the training data and the validation of such data, as well as records of analysis performed on the validity of such data and the results thereof.
42;As establishes by the principle of accountability, the guarantees established to manage the risk must be documented and collect enough information to enable a satisfactory and verifiable accreditation of the actions taken. Such documentation must enable the traceability of the decisions and verifications made pursuant to the minimisation principles referred above. In summary, not only the processing needs to be audited, but the processing must be auditable throughout its life cycle, including upon withdrawal thereof.
42;More precisely, it is necessary to perform an audit to establish compliance with GDPR, as well as to verify the validity of the processing that is based on AI solutions. In order to be effective, the auditing process must be carried out under the same conditions as in a real operation context, more precisely, in order to assess:
42;• The existence of a documented process of analysis, development and/or implementation including, as the case may be, the relevant traceability evidence.
42;• The existence or absence of personal data, profiling or automated decisions on the data subjects without a human intervention, as well as the analysis of the efficiency of the anonymisation and the pseudonymisation methods.
42;• Analysis on the existence and legitimisation of the processing of special categories of data, more precisely with regard to inferred information.
42;• The legal grounds for the processing and identification of responsibilities.
42;• More precisely, when the legal grounds of the processing is the legitimate interest, an assessment of the balance between the different interests and impacts on the rights and freedoms with regard to the guarantees adopted.
43;• The information and the effectiveness of the implemented transparency mechanisms.
43;• The application of the principle of accountability and risk management for the rights and liberties of the data subjects and, more precisely, if the obligation or the need to carry out PIAs has been assessed and, if such was the case, the results of such PIAs.
43;• With regard to the above, the application of data protection measures by default and by design, inter alia:
43;o The prior analysis of the need to process personal data, in terms of quantity and extent, in the several phases pursuant to minimisation criteria.
43;o The analysis of the accuracy, fidelity, quality and biases of the data used or gathered for the development or the operation of the AI component, as well as the data sanitation methods used with regard to the data.
43;o The verification and performance of tests and validation of the precision, the accuracy, the convergence, the consistence, predictability and any other metrics on the eligibility of the algorithms used, profiling and inferences. Furthermore, the verification that such parameters meet the requirements needed for the processing.
43;• The suitability of the security measures in order to avoid privacy risks.
43;• The training and education of the data controller personnel involved in the development and operation of the AI component. In this last case, a special attention to the accurate interpretation of the inferences.
43;• The obligation, necessity and, as the case may be, the qualification of the DPO.
43;• The addition of mechanisms that guarantee the fulfilment of the rights of the data subjects, more precisely, the ex officio erasure of personal data, with a great attention to minors' rights.
43;• The fulfilment of the limitations on automated decisions without a human intervention, the assessment, as the case may be, of the quality of the human intervention and the supervisory mechanisms adopted. More precisely, when the legal grounds are the explicit consent, the identification of the guarantes adopted in order to verify that such a consent is free given.
43;• The application of some of the guarantees established in Chapter V of the GDPR in the event that international data transfers exist.
43;• In general terms, the fulfilment of the requirements and obligations of the GDPR and, more precisely, those stated in this document.
43;As previously established, the AI-based solution shall be integrated within a specific processing, with specific characteristics and a certain operational context. An audit of the isolated AI-based solution, without taking into account the context or the background, shall be incomplete and shall offer partial and unrealistic results.
43;A critical aspect of the audit is to guarantee that the AI-based solution is being used for the purpose for which it was designed, with special attention to its use by the operators of the system. Furthermore, when it is a component that has been acquired from a third party, the other collateral processing that could be performed by such component needs to assessed as well as whether legal or regulatory consequences that may arise out of such use.
43;The use of solutions or real-time automated audit tools is advisable in systems with automated decision-making in order to ensure that the output is consistent and precise, as well as in order to allow that erroneous decisions be aborted or cancelled before irreversible consequences arise.
44;The guarantees appearing in Chapter V of the GDPR "Transfers of personal data to third countries or international organisations" need to be applied to such transfers. It is especially important to establish mechanisms in order to allow the contracts signed in this context of international transfers to be managed smoothly, ensuring at the same time that the client, as data controller, has enough information on the contractors or prospect contractors and keeps the power to adopt decisions. When international transfers exist, data subjects must be informed pursuant to the terms in Articles 13 and 14 of the GDPR and such international transfers must be included within the records of processing activities.
45;Finally, it must be highlighted that one of the main problems of AI-based solutions is not the AI itself, but rather the way in which the AI technology and the new psychological biases arising out of its use are going to be used by individuals. More precisely, careful attention needs to be paid so as not to assign responsibilities to unsupervised AI components without adopting a rational, critical and discerning position. The delegation of decision-making on machines is not something new; it has already been used with determinist algorithms, but the bias of assigning a kind of authority or reputability to a result just inferred by an AI-based solution may increase the risks arising out of such a delegation of responsibility.