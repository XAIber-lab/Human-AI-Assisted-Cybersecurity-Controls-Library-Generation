Page;Text
13;The AIDA would require that appropriate measures be put in place to identify, assess, and mitigate risks of harm or biased output prior to a high-impact system being made available for use
13;Human Oversight means that high-impact AI systems must be designed and developed in such a way as to enable people managing the operations of the system to exercise meaningful oversight. This includes a level of interpretability appropriate to the context
13;Monitoring, through measurement and assessment of high-impact AI systems and their output, is critical in supporting effective human oversight
14;Transparency means providing the public with appropriate information about how high-impact AI systems are being used. The information provided should be sufficient to allow the public to understand the capabilities, limitations, and potential impacts of the systems
14;Fairness and Equity means building high-impact AI systems with an awareness of the potential for discriminatory outcomes. Appropriate actions must be taken to mitigate discriminatory outcomes for individuals and groups
15;Safety means that high-impact AI systems must be proactively assessed to identify harms that could result from use of the system, including through reasonably foreseeable misuse. Measures must be taken to mitigate the risk of harm
15;Accountability means that organizations must put in place governance mechanisms needed to ensure compliance with all legal obligations of high-impact AI systems in the context in which they will be used
16;Validity means a high-impact AI system performs consistently with intended objectives. Robustness means a high-impact AI system is stable and resilient in a variety of circumstances
17;Businesses who design or develop a high-impact AI system would be expected to take measures to identify and address risks with regards to harm and bias, document appropriate use and limitations, and adjust the measures as needed
17;Businesses who make a high-impact AI system available for use would be expected to consider potential uses when deployed and take measures to ensure users are aware of any restrictions on how the system is meant to be used and understand its limitations
17;Businesses who manage the operations of an AI system would be expected to use AI systems as indicated, assess and mitigate risk, and ensure ongoing monitoring of the system
18;Performing an initial assessment of potential risks associated with the use of an AI system in the context and deciding whether the use of AI is appropriate
18;Assessing and addressing potential biases introduced by the dataset selection
18;Assessing the level of interpretability needed and making design decisions accordingly
19;Documenting datasets and models used
19;Performing evaluation and validation, including retraining as needed
19;Building in mechanisms for human oversight and monitoring
19;Documenting appropriate use(s) and limitations
19;Keeping documentation regarding how the requirements for design and development have been met
19;Providing appropriate documentation to users regarding datasets used, limitations, and appropriate uses
19;Performing a risk assessment regarding the way the system has been made available
19;Logging and monitoring the output of the system as appropriate in the context
19;Ensuring adequate monitoring and human oversight
19;Intervening as needed based on operational parameters
20;In the initial years after it comes into force, the focus of AIDA would be on education, establishing guidelines, and helping businesses to come into compliance through voluntary means