Actions, recommendations, and guidelines for secure design, development, deployment, operation, configuration, and maintenance of systems and AI:

Page 2; "Safeguarding fairness and rights to nondiscrimination"
Page 2; "Ensuring transparency and explainability during development and due process rights in application"
Page 2; "Embedding accountability measures into system design"
Page 7; "Require private companies to conduct stakeholder consultations with civil societies and seek out their guidance during the development of AI technologies to augment human capabilities and ensure the inclusion of diverse developers of AI systems, representative datasets, and nondiscriminatory practices."

Measures for safe and secure use, development, and provision of systems and AI:

Page 2; "Ensuring AI-powered biometric systems are developed and deployed in a manner that supports fundamental democratic values with respect to the rule of law, basic civil liberties, and universal human rights"
Page 5; "Identify fairness considerations and approaches up-front, and involve multi-stakeholders, such as experts in the relevant domain and across disciplines, in the conversation."
Page 5; "Develop testing and monitoring mechanisms to detect and mitigate fairness-related harms."

Actions to defend, protect, and monitor systems and AI, including log handling:

Page 6; "Develop audit trail requirements and documentation of AI-powered biometric systems that cover all steps of the AI development process, which could include model architecture, training data, records of exhibited bias and previous predictions, etc."
Page 6; "Implement executive and legislative actions to mandate developers of AI systems to provide access for auditing via independent regulatory agencies, such as the Federal Trade Commission (FTC), or third-party organizations."

Measures to keep users safe and protect their privacy:

Page 2; "Safeguarding fairness and rights to nondiscrimination"
Page 6; "Require private companies to provide a right to explanation of decisions made by automated or AI systems."

Recommendations regarding user and stakeholder rights, communication, and enabling rights exercise:

Page 6; "Require private companies to provide a right to explanation of decisions made by automated or AI systems."
Page 7; "Mandate federal and local governments to consult representatives from community and civil society organizations when developing rules and regulations related to AI."

Actions related to legal compliance, regulations, and contextual considerations:

Page 5; "Explore a legally viable path for algorithmic fairness under current constitutional doctrines."
Page 8; "Implement executive and legislative actions to allow third-party auditor access to AI data and source code, as well as other transparency and explainability information, for the purposes of external researcher, civil society, and regulator assessments."

Guidelines for data protection, classification, storage, and validation:

Page 6; "Develop audit trail requirements and documentation of AI-powered biometric systems that cover all steps of the AI development process, which could include model architecture, training data, records of exhibited bias and previous predictions, etc."

Practices for risk assessment, management, mitigation, and threat identification:

Page 5; "Develop testing and monitoring mechanisms to detect and mitigate fairness-related harms."
Page 6; "Implement bias and safety bug-bounty programs, allowing individuals to report algorithmic bias or security vulnerabilities to an organization and receive rewards or compensation, for AI systems to increase incentives for broader scrutiny of AI systems."

Methods for control, evaluation, verification, validation, and testing of systems and AI throughout their lifecycle:

Page 5; "Develop testing and monitoring mechanisms to detect and mitigate fairness-related harms."
Page 6; "Implement executive and legislative actions to mandate developers of AI systems to provide access for auditing via independent regulatory agencies, such as the Federal Trade Commission (FTC), or third-party organizations."

Recommendations for data access control:

Page 8; "Implement executive and legislative actions to allow third-party auditor access to AI data and source code, as well as other transparency and explainability information, for the purposes of external researcher, civil society, and regulator assessments."

Guidelines for asset management, security, and authentication:

No specific information found.

Recommendations regarding roles, rights, and responsibilities of developers, deployers, providers, and other AI actors:

Page 7; "Require private companies to conduct stakeholder consultations with civil societies and seek out their guidance during the development of AI technologies to augment human capabilities and ensure the inclusion of diverse developers of AI systems, representative datasets, and nondiscriminatory practices."
Page 8; "Consider best practices that could be recommended to industry for embedding accountability mechanisms to test the outcome or results of its AI systems."