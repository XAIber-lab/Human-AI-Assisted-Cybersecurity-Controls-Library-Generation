Page;Text
11;"Minimise an adversary's knowledge"
11;"Understand that attackers can gather information to strengthen attacks."
11;"When deciding whether to release information, consider the balance between the motivation for sharing (marketing, publication or improving security practices) while protecting core system, development and model details. This balance requires understanding the implications on your system vulnerability of releasing information."
12;"Develop a process or framework to review information intended for public release and assess the risk it could pose to your system. Seek views from a range of backgrounds (for example ML practitioners, security, software developers, non-technical subject matter experts) to build up a comprehensive picture of the potential impact."
12;"Make sure that all staff (not just staff in technical roles) involved in releasing information to the public are trained on the potential impact of releasing the material. Make them aware of the required processes for releasing different types of material, for example marketing material, privacy policies or contributions to academic literature or open source software."
13;"Design for security (vulnerabilities)"
13;"When drafting system requirements, consider the vulnerability of your proposed system against the inherent AI/ML threats and continue to review throughout the lifecycle."
13;"Identifying specific vulnerabilities in your intended workflows or algorithms at the requirements stage helps you plan your defences at the start of a project. By supporting security by design, you prevent the need to mitigate vulnerabilities in an operational system and the work and disruption that comes with that."
13;"It's good practice to review decisions throughout the development process, with a formal security review before a model or system is released into production. The use of (automated) tools can make this process easier and more effective."
14;"Establish the risk appetite or the security targets in your requirements and set up development processes to ensure you're on track to meet them."
14;"Once you have established security requirements, consider using automated tools to quantify and automatically test your model's security performance against known vulnerabilities and attack techniques. Running automated tests throughout the model's development cycle will help practitioners meet the required security goals."
14;"Red teaming can be an effective way to highlight vulnerabilities in your systems. Applying a red teaming or pen-testing mindset (without necessarily undergoing full red teaming or pen testing) can be useful to identify vulnerabilities in your system. This will be useful to inform security requirements and drive design decisions."
15;"Follow principle 1.1 and train your developers to understand the inherent vulnerabilities to ML algorithms and workflows."
15;"Ensure your team are familiar with appropriate defensive techniques and risk mitigation strategies."
15;"Secure your supply chain"
15;"Obtain your data and models from a trusted source."
16;"Implement good validation and verification (V&V) processes for creating and acquiring dataset"
16;"Once data is obtained, it must be stored securely and transmitted to and from your training environment securely"
16;"You understand that your data and its labels determine the logic of the model."
16;"You understand your data supply chain and have sufficient validation and verification (V&V) processes in place to ensure data can be trusted."
16;"You understand that the risk of supply chain contamination heightens when you purchase and use models that don't have a transparent creation method."
16;"You understand the risk posed by insider threats and human error, if labelling manually."
16;"You understand the key information about the model you are using."
16;"When you are procuring assets, consider the security of the supply chain. This also applies when using auto labelling/labelling aid software."
16;"Follow the NCSC's supply chain security guidance, which advises understanding your suppliers and their security posture, and ensuring they are aware of your security expectations."
16;"Follow advice in the ETSI AI Data Supply Chain Security paper."
17;"Implement and apply a robust validation and verification process to assess the quality and integrity of both internally created and externally acquired datasets."
17;"Consider applying security-specific data augmentation alongside standard data augmentation. This is often referred to as 'adversarial training'."
17;"Create guidance and train labellers on their roles and responsibilities. This will help minimise unintentional mislabelling â€“ especially important for nuanced labelling, such as spatial data (object detection bounding boxes)."
17;"Reduce the risk of insider attacks on datasets by making sure the level of vetting for your labellers is appropriate for the severity of impact that mislabelling could have. This would be different, for example, for an autonomous vehicle and in a research environment."
18;"Secure your infrastructure (development environment)"
18;"Baseline security by protecting your training and development environment, applying trust controls to anything and anyone that enters."
18;"The security of the environment in which your model is developed and trained is critical. At the training stage of the lifecycle, valuable assets (eg, training data) come together with external inputs (eg, software or open-source pre-trained models). This creates a high-value target with multiple possible attack vectors. Damage or exploitation at this stage could enable attacks that propagate throughout your application's lifecycle."
18;"Like your data, the infrastructure that makes up your training environment needs to be sourced through a trusted supply chain, whether that involves locally owned servers, public cloud services or local training on an embedded device."
18;"Developers should understand that initiating development in a less secure research and development (R&D) environment could create attack vectors that could be exploited in production."
18;"Securing development infrastructure is likely to involve assessing multiple components and settings. It's important to secure the operating system, ensuring you're updated to the latest version, and limiting access to the environment to only those with a legitimate need. Access to and modification of components should be logged and monitored."
19;"Source assets (including digital ones) appropriately from trusted supply chains This includes pre-trained parent models for transfer learning."
19;"Source software to build and train models (eg, third-party Python libraries), data warehouses, MLOps software and experimentation or testing platforms from trusted supply chains."
19;"Verify any third-party inputs (including pre-trained models) are from sources you trust."
19;"Use secure software development practices."
19;"Monitor CVEs associated with your development software and library dependencies. The level of monitoring should be proportionate to your security requirements."
19;"Ensure access to your training environment is appropriately secured while following the principle of least privilege for user access."
19;"Secure your firmware/operating system"
19;"Implement access logging and monitoring in your development environment."
19;"Ensure your team have an appropriate level of awareness of cyber vulnerabilities and best practices to mitigate them."
20;"Secure your infrastructure (digital assets)"
20;"Protect digital assets at rest and in transit"
20;"Once you have your data and have acquired or generated your model, you need to protect them. These digital assets represent a significant investment of resources and intellectual property, making them an attractive target for theft, and their manipulation can significantly affect a system's operation. Knowledge of a model's training data or architecture can also enhance an adversary's ability to craft an effective attack."
20;"You know what data you hold and where it's stored."
20;"You understand what data you are transmitting, between which devices or to whom."
20;"You understand the impact of theft or loss of integrity to this data, including legal and reputational impacts."
20;"You consider datasets, models and other artefacts to be crucial assets that need to be protected for security as well as other purposes (eg, data protection)."
20;"You have followed appropriate advice and guidance on how to secure digital assets, including limiting access to those with a legitimate need, and logging and monitoring any access and modification."