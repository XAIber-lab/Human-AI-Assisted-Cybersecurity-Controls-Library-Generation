1_Notified bodies shall have documented procedures in place ensuring that their personnel, committees, subsidiaries, subcontractors and any associated body or personnel of external bodies maintain, in accordance with Article 78, the confidentiality of the information which comes into their possession during the performance of conformity assessment activities_GV.RR-02_PR.DS-01_PR.AA-05_data protection_High_
1_Notified bodies shall have procedures for the performance of activities which take due account of the size of a provider, the sector in which it operates, its structure, and the degree of complexity of the AI system concerned_GV.OC-02_GV.PO-01_GV.SC-01__Medium_
1_Notified bodies shall take out appropriate liability insurance for their conformity assessment activities, unless liability is assumed by the Member State in which they are established_GV.OC-03_GV.RR-03___High_
1_Notified bodies shall be capable of carrying out all their tasks under this Regulation with the highest degree of professional integrity and the requisite competence in the specific field, whether those tasks are carried out by notified bodies themselves or on their behalf and under their responsibility_GV.RR-01_GV.RR-02___Medium_
2_Notified bodies shall have sufficient internal competences to be able effectively to evaluate the tasks conducted by external parties on their behalf_GV.RR-02_PR.AT-02___High_
2_The notified body shall have permanent availability of sufficient administrative, technical, legal and scientific personnel who possess experience and knowledge relating to the relevant types of AI systems, data and data computing_GV.RR-03_PR.AT-02___High_definition
2_Notified bodies shall participate in coordination activities as referred to in Article 38. They shall also take part directly, or be represented in, European standardisation organisations, or ensure that they are aware and up to date in respect of relevant standards_GV.SC-02_ID.IM-01___Medium_
4_Notified bodies shall make available and submit upon request all relevant documentation, including the providers' documentation, to the notifying authority referred to in Article 28 to allow that authority to conduct its assessment, designation, notification and monitoring activities_RS.CO-03_GV.OC-03___High_
6_In the event of the restriction, suspension or withdrawal of a designation, the notifying authority shall take appropriate steps to ensure that the files of the notified body concerned are kept, and to make them available to notifying authorities in other Member States and to market surveillance authorities at their request_PR.DS-11_RS.CO-03___High_
7_In the event of the restriction, suspension or withdrawal of a designation, the notifying authority shall assess the impact on the certificates issued by the notified body_ID.RA-04_ID.RA-05___Medium_
7_In the event of the restriction, suspension or withdrawal of a designation, the notifying authority shall submit a report on its findings to the Commission and the other Member States within three months of having notified the changes to the designation_RS.CO-02_RS.CO-03___High_
7_In the event of the restriction, suspension or withdrawal of a designation, the notifying authority shall require the notified body to suspend or withdraw, within a reasonable period of time determined by the authority, any certificates which were unduly issued_GV.OV-03_RS.MI-02___High_
7_In the event of the restriction, suspension or withdrawal of a designation, the notifying authority shall provide the national competent authorities of the Member State in which the provider has its registered place of business with all relevant information about the certificates of which it has required the suspension or withdrawal_RS.CO-02_RS.CO-03___High_
32_Providers shall ensure that AI systems intended to interact directly with natural persons are designed and developed in such a way that the natural persons concerned are informed that they are interacting with an AI system_GV.OC-02_PR.AT-01__transparency_High_
33_Providers of AI systems, including general-purpose AI systems, generating synthetic audio, image, video or text content, shall ensure that the outputs of the AI system are marked in a machine-readable format and detectable as artificially generated or manipulated_PR.DS-01_PR.DS-02__transparency_High_
33_Providers shall ensure their technical solutions are effective, interoperable, robust and reliable as far as this is technically feasible, taking into account the specificities and limitations of various types of content, the costs of implementation and the generally acknowledged state of the art_PR.PS-01_PR.IR-03___Medium_
33_Deployers of an emotion recognition system or a biometric categorisation system shall inform the natural persons exposed thereto of the operation of the system_GV.OC-02___transparency_High_
34_Deployers of an AI system that generates or manipulates image, audio or video content constituting a deep fake, shall disclose that the content has been artificially generated or manipulated_GV.OC-02_PR.AT-01__transparency_High_
35_The information referred to in paragraphs 1 to 4 shall be provided to the natural persons concerned in a clear and distinguishable manner at the latest at the time of the first interaction or exposure_GV.OC-02_PR.AT-01__transparency_High_
40_High-risk AI systems or general-purpose AI models which are in conformity with harmonised standards or parts thereof the references of which have been published in the Official Journal of the European Union shall be presumed to be in conformity with the requirements set out in Section 2_GV.PO-01_GV.SC-01___Medium_definition
45_Providers of general-purpose AI models shall draw up and keep up-to-date the technical documentation of the model, including its training and testing process and the results of its evaluation_ID.AM-08_PR.PS-06___High_
45_Providers shall assess and mitigate possible systemic risks at Union level, including their sources, that may stem from the development, the placing on the market, or the use of general-purpose AI models with systemic risk_ID.RA-05_GV.RM-06___High_
46_Providers shall keep track of, document, and report, without undue delay, to the AI Office and, as appropriate, to national competent authorities, relevant information about serious incidents and possible corrective measures to address them_RS.CO-02_RS.CO-03___High_
46_Providers shall ensure an adequate level of cybersecurity protection for the general-purpose AI model with systemic risk and the physical infrastructure of the model_PR.PS-01_PR.IR-01___High_
47_The AI Office shall encourage and facilitate the drawing up of codes of practice at Union level in order to contribute to the proper application of this Regulation_GV.PO-01_GV.SC-01___Medium_
48_The measures, procedures and modalities for the assessment and management of the systemic risks at Union level, including the documentation thereof, which shall be proportionate to the risks, take into consideration their severity and probability and take into account the specific challenges of tackling those risks in light of the possible ways in which such risks may emerge and materialise along the AI value chain_ID.RA-05_GV.RM-06___High_
49_The AI Office and the Board shall aim to ensure that participants to the codes of practice report regularly to the AI Office on the implementation of the commitments and the measures taken and their outcomes_GV.OV-03_ID.IM-01___Medium_