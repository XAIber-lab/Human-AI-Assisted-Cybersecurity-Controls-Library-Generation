page_text_First proposal_Second proposal_Third proposal_labels_confidence_definitions

3_Users should make efforts to utilize AI systems or AI services in a proper scope and manner, under the proper assignment of roles between humans and AI systems, or among users._GV.RR-02; GV.RR-01_GV.OC-02__transparency_Medium_

4_AI service providers are expected to provide AI software updates and AI inspections/repairs, etc. services to improve AI functions and mitigate risks in their utilization. In particular, if it is assumed that the update affects other linked AI systems, AI service providers are expected to provide information on these risks._ID.IM-03_PR.PS-02_ID.RA-06__High_

4_Depending on the nature and usage mode of AI systems or AI services to be provided, AI service providers are expected to confirm the reliability of users in advance in cases where the use of an AI is likely to harm human lives, bodies, or property. Furthermore, after an AI service is provided, there may be a necessity for recording and saving input and output logs on the service in order to make sure that no end users misuse or make malicious use of the AI service or AI system._PR.PS-04; DE.CM-03_ID.RA-04_RS.AN-07__High_

4_It is desirable to provide corresponding information before using AI._GV.OC-02_RS.CO-02___Low_

4_If the information cannot be provided in advance, with consideration for assumed risks based on the nature and usage mode of AI, it is desirable to have a system in place to respond to feedback from consumer users._GV.RM-05_RS.CO-03___Medium_

5_The necessity for human intervention is considered according to the field and application of the AI in accordance with the following example criteria. [Example perspective considered as criteria for the necessity of human intervention]: Nature of end users rights, benefits and intention affected by AI's decision, Reliability of AI's decision (compared with that of human decisions), Allowable time necessary for human decisions, Expected ability of users making decisions, Necessity for protecting target for decision_GV.RR-02_ID.RA-05_GV.OC-02__High_

6_If it is considered appropriate for consumer users to give final approval to an AI's decision, they are recommended to acquire the necessary skills and knowledge to make appropriate decisions._PR.AT-01_GV.RR-02___Medium_

7_AI service providers, business users and data providers are expected to cooperate with related stakeholders and to work on preventive or remedial measures (including information sharing, stopping and starting of AI, elucidation of causes, and measures to prevent recurrence, etc.) in accordance with the nature, and conditions, etc. of accidents that have occurred or may occur in the future_RS.CO-03_ID.RA-06_GV.SC-02__High_

10_AI service providers, business users, and data providers are expected to pay attention to the quality of data (e.g. data accuracy and integrity) used for learning or other AI methods, with consideration for the characteristics of the AI to be used and its usage._PR.DS-01; PR.DS-02_ID.RA-09__data protection_High_

10_Exclude the data which humans cannot understand or identify from those for learning, Actively adopt the data for learning if it is easily misrecognized by machines (learner), Be careful not to cause an error when annotating (labeling) (especially for supervised learning)._ID.RA-01_PR.DS-01_ID.IM-02_data protection_High_

10_Create a data set while being conscious of the data format used (input) at the utilization phase, Acquire and store logs on how pre-processing is performed (the provenance of data pre-processing)._PR.DS-01_ID.AM-07_RS.AN-07_data protection_High_

11_It is assumed that the accuracy of an AI's judgment can become impaired or decline afterwards. Therefore, AI service providers, business users, and data providers are expected to define reference levels concerning accuracy in advance based on the assumed magnitude and frequency of occurrence of the infringement of rights, the technology level available, and the cost to maintain accuracy, etc._ID.RA-05_GV.RM-02_ID.IM-01__High_

11_If it is planned to use data provided by consumer users, they are expected to provide consumer users with information on the means and format of data provision in advance, taking into consideration the characteristics and usage of the AI._GV.OC-02_PR.DS-01__data protection_Medium_

12_AI service providers, business users, and data providers are expected to pay attention to the risk that AI security might become vulnerable by learning inaccurate or inappropriate data. They are also expected to inform consumer users in advance of the existence of such risks._ID.RA-01_GV.RM-05_ID.RA-03__High_

12_A risk of making learning (models) fail by mixing incorrectly labeled data in supervised-learning._ID.RA-01___data protection_Low_definition

14_AI service providers and business users are expected to comply with data format standards (with syntax and semantics) to promote collaboration among AIs and between AIs and other systems: Data format for AI input and output, and connection methods for collaboration_ID.AM-08_PR.DS-02_GV.SC-01__High_

15_AI service providers, business users, and data providers are expected to analyze possible risks with consideration for information from developers, while sharing the risks with the cooperating parties, organizing preventive measures and countermeasures for problems_ID.RA-05; ID.RA-06_GV.RM-05_RS.CO-03__High_

15_Risks of failure in verifying the judgment and the decision making of an AI (risk of failure to analyze the interactions between AI systems because the interactions become complicated)._ID.RA-01___Low_definition

15_Risks that the influence of a small number of AIs become too strong (risks of enterprises and individuals suffering disadvantages because of judgements made by a few AI systems)._ID.RA-04___Low_definition

17_In cases where AI is used in fields where AI may harm human life, body, or property, AI service providers and business users are expected to take into consideration so that AI will not harm them through actuators or other devices by taking the following measures as necessary, based on information from the developers, and with consideration of the nature, and conditions, etc. of the assumed damage._ID.RA-05_GV.RR-01_PR.IR-03__High_

17_AI service providers and business users are expected to organize in advance the measures to be taken if an AI damages a human life, body, or property through actuators or other devices._ID.IM-04_RS.MA-01_GV.RM-04__High_

17_Perform AI inspections, repairs, and AI software updates, and encourage consumer users to carry them out._PR.PS-02; PR.PS-03_ID.IM-02___High_

17_Provide a fail-safe design, for example, by constructing a mechanism that can ensure the safety of entire systems even if an unexpected operation is caused by the AI._PR.IR-03_ID.RA-01___High_

21_AI service providers and business users are expected to pay attention to the security of AI and take reasonable measures corresponding to the technology level at that time to ensure the confidentiality, integrity and availability (CIA) of AI systems._PR.DS-01; PR.DS-02_GV.PO-01___High_

21_Initial actions (to be taken according to necessary procedures depending on the urgency of the affected systems or AI etc.): Recovery by rolling back the system or using an alternative system, System shutdown (by kill switch): If possible, Network disconnection: If possible, Content confirmation of security infringement, Report to the related parties_RS.MI-01; RS.MI-02_RC.RP-01_RS.CO-02__High_

22_AI service providers are expected, with regard to their AI services, to provide end users with services for security measures and to share past accident and incident information._RS.CO-03_GV.SC-09_DE.AE-06_transparency_High_

24_Users and data providers should take into consideration that the utilization of AI systems or AI services will not infringe on the privacy of users or others._PR.DS-01_GV.OC-03__privacy_Medium_

26_AI service providers and business users should respect the privacy of end users and third parties in the utilization of AI, based on the social context and reasonable expectations of people in its utilization._PR.DS-01; PR.DS-02_GV.OC-03__privacy_High_

27_AI service providers, business users, and data providers should respect the privacy of end users and third parties in the collection, preprocessing, and provision etc. of personal data used for AI learning and in the provision of learning models generated through them._PR.DS-01_GV.OC-03_ID.AM-07_privacy_High_

27_AI service providers, business users, and data providers are expected to take appropriate measures, including the prevention of unconsented data being made available to third parties, in their systems so that personal data is not provided under the judgement of AI to third parties without the consent of those persons._PR.DS-01; PR.DS-02_PR.AA-05_GV.OC-03_privacy_High_