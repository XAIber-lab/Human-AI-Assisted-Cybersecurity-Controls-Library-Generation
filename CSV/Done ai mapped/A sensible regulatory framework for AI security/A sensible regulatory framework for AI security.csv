page_text_First proposal_Second proposal_Third proposal_labels_confidence
3_"Improved machine perception that for certain tasks can exceed human cognitive visual performance, Optimization and planning engines that leverage reinforcement learning to exceed human performance in complex games, Generative algorithms that can create text, audio, and images that in many cases are indistinguishable from those created by humans without targeted analysis"_ID.AM-02_PR.PS-01_DE.CM-09_definition_low
4_"Tools are emerging to identify and protect against new and existing threats. For example, MITRE works closely with industry and government to capture such threats and document associated adversary tactics, techniques, and procedures in the MITRE Adversarial Threat Landscape for Artificial-Intelligence Systems (ATLAS) framework"_ID.RA-02; ID.RA-03_RS.CO-03_DE.AE-07__medium
4_"MITRE defines AI assurance as a lifecycle process that provides justified confidence in an AI system's ability to operate effectively with acceptable levels of risk to its stakeholders"_GV.RM-01; GV.RM-02_GV.OC-02_ID.RA-05_definition_high
4_"The risks that need to be managed within acceptable levels may be associated with or stem from a variety of factors depending on the use context, including but not limited to AI system safety, security, equity, reliability, interpretability, robustness, privacy, and governability"_ID.RA-05_GV.RM-02_GV.OC-03_privacy_high
4_"The National Institute of Standards and Technology's (NIST) AI Risk Management Framework (RMF) is a good example of an approach that incorporates trustworthiness considerations into AI design, development, use, and evaluation of AI system components"_GV.RM-01; GV.RM-06_ID.IM-01_GV.OC-03__medium
7_"Industry regulators should promote trusted information sharing mechanisms to support regulatory analysis"_RS.CO-03_GV.RM-05_ID.RA-02__high
7_"Any AI regulation should require AI components to satisfy software assurance requirements as well as AI-specific assurance requirements that can be developed based on validated AI assurance frameworks"_GV.PO-01_GV.SC-05_ID.RA-09__high
8_"Regulated industries should develop a NIST AI RMF response plan; if they deem the NIST AI RMF insufficient, they should identify alternative AI assurance approaches"_GV.PO-01; GV.PO-02_GV.RM-01_GV.OC-03__high
8_"Any AI regulation should account for and mitigate risks stemming from component interactions"_ID.RA-01; ID.RA-04_GV.SC-07_PR.PS-01__high
8_"Any AI regulation should account for use context and favor existing domain-specific regulations"_GV.OC-03_GV.PO-01_GV.RM-01__high
8_"Any AI regulation should require 'assurance cases' to be developed before deployment"_ID.RA-06_GV.SC-06_PR.PS-06__high
8_"An assurance case is a documented body of evidence that provides a compelling argument that the system satisfies certain critical assurance properties in specific contexts"_ID.RA-05_GV.RM-06_GV.OC-01_definition_medium
8_"Industry regulators should conduct continuous regulatory analysis of individual use cases"_DE.CM-09_ID.IM-03_GV.OV-03__high
9_"AI regulation should require system auditability in order to hold individuals who misuse AI to cause harm accountable"_PR.PS-04_RS.AN-06_GV.RR-02_transparency_high
9_"Legal frameworks that may be developed as part of AI regulation to hold individuals accountable for causing harm with AI should focus on regulatory approaches commensurate with the scale of the risk"_GV.RR-02_ID.RA-05_GV.PO-01__high
9_"AI regulation should provide appropriate levels of transparency into AI applications to an objective third party and/or the public for detection and mitigation of intentional AI misuse"_GV.OC-02_RS.CO-02_DE.CM-03_transparency_high
9_"We recommend an assessment of federal government critical infrastructure plans focused on identifying and strengthening recommendations for safety-critical cyber-physical systems particularly vulnerable to increased threats due to the scale and speed AI enables"_ID.RA-05; ID.RA-06_GV.SC-07_PR.IR-03__medium
10_"Federal government critical infrastructure plans should address increased risk due to AI-enabled scale and speed and consider countering risk with automated red teaming"_ID.IM-02_DE.CM-09_ID.RA-06__high
11_"Increase federal funding to create common vocabulary and frameworks for AI alignment, and use those to guide future research"_GV.RM-06_ID.IM-01_GV.PO-02__medium
11_"Regulation and legal frameworks should differentiate between appropriate research with risk mitigations and bad actors, and hold all appropriately accountable for harms"_GV.RR-02_ID.RA-05_RS.MA-03__high
4_"Building on ATLAS and in partnership with Microsoft, MITRE released tools to perform red team testing of converged AI-cyber systems as Arsenal"_ID.IM-02_DE.CM-09_ID.RA-01_definition_low