page_text_First proposal_Second proposal_Third proposal_labels_confidence_definitions
31_In the case of profiling by using AI in fields that might have a significant influence on individual's rights or interests, AI service providers and business users are expected to carefully consider all disadvantages that may occur to the target individuals_GV.RM-06; ID.RA-05_ID.RA-04_GV.OC-02_High_
31_Incorrect decisions are made by providing profiling results that are different from the facts_ID.RA-01_DE.AE-02_RS.AN-03_Medium_definition
31_An adverse decision can be made on the target individual if a part of his/her profiling results is the same as the characteristics of a particular group and an unfavorable decision is made on the group_ID.RA-04; ID.RA-05__GV.RM-06_Medium_
31_As a result of profiling, a treatment that impairs the rights and interests of target individuals or groups can occur, which may promote unfair discrimination against individuals or groups_ID.RA-05_GV.OC-03_ID.RA-04_Medium_
31_Negative decisions can be made in the process of predicting (extrapolating) an uncertain future based on profiling results_ID.RA-04_ID.RA-05_GV.RM-06_Medium_
32_AI service providers, business users, and data providers should pay attention to the possibility of bias inherent in the judgements of AI systems or AI services, and take into consideration that individuals and groups will not be unfairly discriminated against by their judgments_GV.RM-01; GV.RM-02_ID.RA-05_GV.OC-02_High_
34_Take into consideration that AI can be biased due to the failure to ensure representativeness for the data even if the AI learning algorithm is designed to prevent an unfair judgment_ID.RA-05; ID.RA-04_GV.RM-06_ID.IM-01_High_
34_Take into consideration that AI can be biased as a result of using data embedding social bias even if sensitive information is not embedded into the data_ID.RA-04; ID.RA-05_GV.RM-06_ID.IM-01_High_
34_Take into consideration that the learning data may be affected by the bias of the person who labels (intentionally or unintentionally) because the label for the learning data is often created and granted manually during the preprocessing phase_ID.RA-01; ID.RA-04_GV.RM-06_PR.AT-02_High_
34_Respect personal privacy embedded in data in the case of collecting enormous amounts of data, including personal data, to satisfy the representativeness of the data_PR.DS-01; PR.DS-02_GV.OC-03_PR.DS-10_High_privacy
39_AI service providers and business users are expected to record and preserve logs, including those on inputs/outputs, to ensure the verifiability of inputs/outputs from an AI_PR.PS-04_DE.CM-09_RS.AN-06_High_
39_The purpose of log recording and preservation (whether the purpose is to identify the causes of accidents or to prevent recurrences in fields that may harm humans' lives, bodies, property, etc.)_ID.IM-04_RS.AN-06_DE.AE-02_High_
39_Frequency of log acquisition and recording_PR.PS-04_DE.CM-01__Medium_
39_Log accuracy_PR.PS-04_DE.CM-09__Medium_
39_Log retention period_PR.PS-04_ID.IM-04__Medium_
39_Log protection (Ensuring security, and integrity, etc.)_PR.PS-04; PR.DS-01_PR.DS-02__High_
39_Capacity of storage location_PR.IR-04_PR.PS-04__Medium_
39_Log time recording_PR.PS-04_DE.CM-09__Medium_
39_Scope of log to be disclosed_PR.PS-04_RS.CO-03__Medium_
40_AI service providers and business users are expected to ensure the explainability of the judgment results by AI for the purpose of ensuring the trust of users and to present evidence of AI behavior with consideration of the social context in case of utilizing AI in a field that has a significant impact on individual's rights and interests_GV.OC-02; GV.RR-01_RS.CO-03_GV.RM-05_High_transparency
40_Adopt an interpretable model of AI software with high readability in advance_ID.RA-09_PR.PS-06__High_
40_Adopt technical methods that can explain a black-box model_ID.RA-09_PR.PS-06__High_transparency
40_A global explanation method that replaces the model with an interpretable model, such as a model that makes the AI's prediction and recognition process readable_ID.RA-09_PR.PS-06__High_definition; transparency
40_A local explanation method that presents the basis of prediction for specific input, such as the presentation of key features or the presentation of important learning data and its expression in natural language_ID.RA-09_PR.PS-06__High_definition; transparency
40_Manage when, where, and for what purpose data used for AI learning is collected (data provenance)_ID.AM-07_PR.DS-01_ID.RA-09_High_data protection
40_Analyze AI judgment trends based on combinations of multiple AI input and output (for example, observe changes in output when the input pattern is changed little by little)_DE.AE-02; DE.AE-03_ID.RA-04__High_
40_With consideration of the needs and opinions of consumer users, clarify parts in which an explanation is lacking, and collaborate with developers to find out what kind of explanation is necessary_GV.OC-02_GV.SC-02_RS.CO-03_High_
42_Users should make efforts to fulfill their accountability to stakeholders_GV.RR-01_GV.RR-02__High_
43_Based on the nature and purpose of the AI to be used, they are expected to provide and further explain information on the characteristics of the AI system, and communicate with various stakeholders according to their knowledge and capability_GV.OC-02; GV.RM-05_RS.CO-03_GV.RR-01_High_
44_AI service providers and business users are expected to create, publish and disseminate AI usage policies_GV.PO-01_GV.PO-02__High_
44_To create and publish an AI usage policy so that consumer users and third parties are aware of the use of AI when the judgment of an AI could directly affect them, and to provide notifications to them when asked_GV.PO-01; GV.PO-02_RS.CO-02__High_
44_Use of AI (if specific functions or technologies can be identified, their names and contents)_ID.AM-02_GV.OC-04__Medium_
44_Scope and method of AI utilization_GV.OC-04_ID.AM-02__Medium_
44_Risks associated with AI utilization_ID.RA-04; ID.RA-05_GV.RM-06__High_
44_Consultation counter_GV.OC-02_RS.CO-02__Low_
44_They are expected to publish or notify them not only before use of an AI is started but after its behavior changes or use of it is terminated (especially when assumed risks are changed due to a change in the AI's behavior)_GV.PO-02_ID.RA-07_RS.CO-02_High_
55_Ensure safety across the entire system (Fail-safe)_PR.IR-03_PR.PS-01__High_
55_Take reasonable measures corresponding to the current technology level to prevent system hacking_PR.PS-05_PR.IR-01_PR.PS-06_High_
55_Share information about measures to be taken when infringement occurs_RS.CO-02; RS.CO-03_ID.RA-02__High_
55_Share conditions on switching control from AI to human_GV.RR-02_PR.AA-05__High_
55_Provide updates (information) for systems with AI_PR.PS-02_RS.CO-02__High_
55_Ensure explainability, and fulfill accountability, when accident occurs_RS.CO-02; RS.CO-03_GV.RR-01_RS.AN-03_High_transparency
55_Negotiate and coordinate among autonomous vehicles, and support data format / protocol_GV.SC-02_PR.AA-04__High_
55_Address risks that a problem in one AI system spreads to the entire system_ID.RA-05; ID.RA-04_PR.IR-03_GV.SC-07_High_