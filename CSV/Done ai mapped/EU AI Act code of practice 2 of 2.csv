1_"Autonomy, scalability, adaptability to learn new tasks"_ID.RA-05_ID.RA-04_ID.RA-03_none_Low_definition
1_"Dangerous model propensities"_ID.RA-03_ID.RA-04_ID.RA-05_none_Low_definition
1_"Model characteristics beyond capabilities that may cause systemic risk"_ID.RA-05_ID.RA-03_GV.RM-06_none_Medium_definition
1_"Misalignment with human intent and/or values"_ID.RA-03_ID.RA-05_GV.RM-02_none_Low_definition
1_"Tendency to deceive"_ID.RA-03_ID.RA-04_GV.RM-02_none_Low_definition
1_"Bias"_ID.RA-03_ID.RA-04_GV.RM-02_none_Low_definition
1_"Confabulation"_ID.RA-03_ID.RA-04_GV.RM-02_none_Low_definition
1_"Lack of reliability and security"_PR.DS-01; PR.DS-02_ID.RA-03_ID.RA-04_none_Low_definition
1_"'Goal-pursuing', resistance to goal modification, and 'power-seeking'"_ID.RA-03_ID.RA-04_GV.RM-02_none_Low_definition
1_"'Colluding' with other AI models/systems to do so"_ID.RA-03_ID.RA-04_GV.RM-02_none_Low_definition
1_"Potential to remove guardrails"_PR.AA-05_ID.RA-03_PR.AA-01_none_Medium
1_"Access to tools (including other models)"_PR.AA-01_PR.AA-05_ID.AM-02_none_Medium
1_"Modalities (including novel and combined modalities)"_ID.AM-02_ID.RA-03_ID.RA-04_none_Low_definition
1_"Human oversight"_GV.OV-01_GV.OV-02_GV.OV-03_none_High
1_"Model exfiltration (e.g. model leakage/theft)"_PR.DS-01; PR.DS-02_PR.AA-05_PR.AA-01_none_Medium_definition
1_"Number of business users and number of end-users"_ID.AM-01_ID.AM-02_GV.OC-02_none_Low_definition
1_"Offence-defence balance, including the number, capacity, and willingness of bad actors to misuse the model"_ID.RA-03_ID.RA-04_ID.RA-05_none_Medium_definition
1_"Societal vulnerability or adaptation"_ID.RA-05_GV.OC-02_GV.RM-02_none_Low_definition
1_"Lack of explainability or transparency"_GV.OC-03_ID.RA-06_ID.RA-08_transparency_Medium_definition
1_"Technology readiness (i.e. how mature a technology is within a given application context)"_ID.RA-09_ID.RA-04_ID.RA-05_none_Medium_definition
1_"Feedback loops in the use of data, model, and inferences"_ID.RA-04_ID.RA-05_DE.AE-02_none_Medium_definition
2_"perform model evaluation in accordance with standardised protocols and tools reflecting the state of the art, including conducting and documenting adversarial testing of the model with a view to identifying and mitigating systemic risks"_ID.RA-01_ID.RA-04_ID.RA-05_none_High
2_"assess and mitigate possible systemic risks at Union level, including their sources, that may stem from the development, the placing on the market, or the use of general-purpose AI models with systemic risk"_ID.RA-05_ID.RA-06_GV.RM-03_none_High
2_"keep track of, document, and report, without undue delay, to the AI Office and, as appropriate, to national competent authorities, relevant information about serious incidents and possible corrective measures to address them"_RS.CO-02_RS.CO-03_DE.AE-06_none_High
2_"ensure an adequate level of cybersecurity protection for the general-purpose AI model with systemic risk and the physical infrastructure of the model"_PR.DS-01; PR.DS-02_PR.PS-01_PR.IR-01_none_High
2_"a tier of severity at which the level of risk would be considered intolerable absent appropriate safeguards"_ID.RA-05_GV.RM-02_GV.RM-06_none_High
3_"providers of general-purpose AI models with systemic risk should continuously assess and mitigate systemic risks, taking appropriate measures along the entire model's lifecycle, cooperating with relevant actors along the AI value chain, and ensuring their risk management is future-proof by regularly updating their practices in light of improving and emerging capabilities"_ID.RA-05_ID.RA-06_GV.SC-03_none_High
3_"detailed risk assessment, mitigations, and documentation are particularly important where the general-purpose AI model with systemic risk is more likely to (i) present substantial systemic risk, (ii) has uncertain capabilities and impacts, or (iii) where the provider lacks relevant expertise"_ID.RA-05_ID.RA-04_ID.RA-06_none_High
3_"there is less need for more comprehensive measures where there is good reason to believe that a new general-purpose AI model will exhibit the same high-impact capabilities as exhibited by general-purpose AI models with systemic risk that have already been safely deployed, without significant systemic risks materialising and where the implementation of appropriate mitigations has been sufficient"_ID.RA-05_ID.RA-04_GV.RM-02_none_High
3_"proportionality to size and capacity of providers"_GV.RM-01_GV.RM-02_GV.RR-03_none_Medium
3_"to account for differences in available resources between providers of different size and capacity, and recognising the principle of proportionality, simplified ways of compliance for SMEs and startups will be provided where appropriate"_GV.RM-01_GV.RM-02_GV.RR-03_none_High
3_"there are a wide range of organisations that have significant expertise and are well placed to assist with the assessment and mitigation of systemic risks"_GV.SC-02_ID.RA-06_PR.AT-02_none_Medium_definition
3_"they encourage each other to 'share the load', for example by sharing evaluations, best practices or infrastructure, or – where appropriate – by working with qualified third-party providers, potentially facilitated by industry organisations"_GV.SC-02_RS.CO-03_ID.IM-02_none_High
3_"The Signatories commit to adopting, implementing, and making available a Safety and Security Framework (SSF), which shall detail the risk management policies they adhere to in order to proactively assess and proportionately mitigate systemic risks from their general-purpose AI models with systemic risks"_GV.PO-01_GV.RM-01_ID.RA-06_none_High
4_"As part of their SSF, Signatories commit to continuously and thoroughly identifying systemic risks that may stem from the general-purpose AI model with systemic risk"_ID.RA-03_ID.RA-04_ID.RA-05_none_High
4_"Signatories will determine and specify the systemic risks that are particularly relevant to the proposed development, placing on the market, or use of the general-purpose AI model with systemic risk"_ID.RA-03_ID.RA-04_ID.RA-05_none_High
4_"Signatories will use robust risk analysis methodologies to identify the pathways by which the development and deployment of their general-purpose AI model with systemic risk could produce the systemic risks identified, as well as the probability of such risks materialising through those pathways"_ID.RA-04_ID.RA-05_GV.RM-06_none_High
4_"For their general-purpose AI models with systemic risk, Signatories will identify and map potentially dangerous model capabilities, propensities, and other sources of risk that may enable the pathways to systemic risks identified, and provide systemic risk indicators for each of these elements"_ID.RA-03_ID.RA-04_ID.RA-05_none_High
4_"For their general-purpose AI models with systemic risk, Signatories will categorise the identified dangerous model capabilities, dangerous model propensities, and other sources of risk into tiers of severity"_ID.RA-05_GV.RM-06_ID.RA-06_none_High
5_"Signatories will include in their SSF best effort estimates of timelines for when they expect to develop a model that triggers the systemic risk indicators"_ID.RA-04_GV.RM-06_ID.RA-05_none_High
5_"Where applicable to their general-purpose AI models with systemic risk, Signatories will collect model-agnostic evidence of the systemic risks presented by their model, using a wide range of methods that may include literature reviews, competitor and open-source project analysis, forecasting of general trends, and participatory methods involving civil society, academia, and other relevant stakeholders"_ID.RA-02_ID.RA-03_ID.RA-04_none_High
5_"Signatories will ensure best-in-class evaluations are run to adequately assess the capabilities and limitations of their general-purpose AI models with systemic risks"_ID.RA-04_ID.RA-05_ID.RA-06_none_High
5_"like all evidence collection in this section, this may be done in collaboration with – or outsourced to – qualified third parties"_GV.SC-02_PR.AT-02_ID.IM-02_none_High
6_"Signatories will ensure the execution of evaluations with high scientific rigour. Additional rigour shall be achieved through the validation of key results by qualified third parties, especially for high tiers of severity of systemic risks"_ID.RA-04_ID.RA-05_GV.SC-02_none_High
6_"Signatories will ensure that evaluations are being run with a best-in-class level of capability elicitation (e.g. fine-tuning, prompt engineering, scaffolding, compute and engineering budgets) to fully elicit the capabilities of a model and minimise the risk of under-estimating capabilities"_ID.RA-04_ID.RA-05_ID.RA-06_none_High
6_"Signatories will ensure that evaluations can assess the capabilities and limitations of a general-purpose AI model with systemic risk, both in an AI system representative of future AI systems in which the model is intended to and reasonably foreseeably will be used"_ID.RA-04_ID.RA-05_ID.RA-06_none_High
6_"Signatories will ensure that evaluations match the planned usage context of a model with all its variety, where applicable, to show generalisation"_ID.RA-04_ID.RA-05_ID.RA-06_none_High
6_"Signatories will ensure that significant amounts of exploratory work are done on their general-purpose models with systemic risk, such as open-ended red teaming by qualified third parties"_ID.RA-04_ID.RA-05_GV.SC-02_none_High
6_"This means that they will not restrict themselves only to evidence collection for risks or capabilities they have already identified, but also strive to identify new risks and emerging capabilities through these methods"_ID.RA-03_ID.RA-04_ID.RA-05_none_High
7_"Signatories will strive to make best-in-class safety evaluations, tooling, and accompanying best practices widely accessible to relevant actors in the AI ecosystem"_RS.CO-03_ID.IM-02_GV.SC-02_none_High
7_"When Signatories share evaluation results with the AI Office or the public, they will do so in a transparent and easily comparable format. They shall transparently report uncertainty of any empirical results and limitations of the methods used"_RS.CO-03_ID.RA-06_GV.OC-03_transparency_High
7_"Signatories commit to continuously assess risks and collect evidence during the full lifecycle of the development and deployment of general-purpose AI models with systemic risk"_ID.RA-03_ID.RA-04_ID.RA-05_none_High
7_"In specifically identified cases, Signatories may limit the sharing of information to protect commercially sensitive information, public security, proliferation risks, and the validity of future evaluations"_GV.PO-01_GV.OC-03_RS.CO-03_none_High
8_"Before starting a training run for a general-purpose AI model with systemic risk, Signatories will make updates to the SSF as necessary and ensure evaluators (internal and external) are ready for Evidence Collection"_ID.RA-04_GV.PO-02_PR.AT-02_none_High
8_"Signatories will collect evidence at regular milestones, updating an in-progress Safety and Security Report (SSR) as commensurate with the risks"_ID.RA-04_ID.RA-05_GV.PO-02_none_High
8_"During the deployment of any general-purpose AI model with systemic risk, Signatories will update the model's SSR by revisiting their risk assessment, especially by re-running relevant evaluations at least every six months"_ID.RA-04_ID.RA-05_GV.PO-02_none_High
8_"Signatories will conduct post-deployment monitoring for systemic risks. They will establish mechanisms to continuously gather and include relevant post-deployment information in risk assessment"_DE.CM-09_DE.AE-02_ID.RA-05_none_High
9_"Signatories will detail in their SSF the security mitigations they will implement to mitigate systemic risk from the possession of (a) the unreleased weights of a general-purpose AI model with systemic risk, and (b) related unreleased assets and information necessary to train or use such unreleased models"_PR.DS-01; PR.DS-02_PR.AA-05_GV.PO-01_none_High
9_"These security mitigations should furthermore be proportional to systemic risk indicators or tiers of severity, and could entail (a) protection of weights and assets at-rest, in-motion, and in-use, including at the hardware-level as appropriate (b) access control, monitoring, and hardened interfaces to weights and assets, (c) assurance through ongoing security red-teaming and accredited security reviews, and (d) screening for insider threats"_PR.DS-01; PR.DS-02_PR.AA-05_DE.CM-03_none_High
9_"protect commercially sensitive information, public security, proliferation risks, and the validity of future evaluations"_PR.DS-01; PR.DS-02_PR.AA-05_GV.PO-01_none_High
10_"Signatories will detail in their SSF their process for assessing the continued adequacy of their mapping from systemic risk indictors or tiers of severity to safety and security mitigations"_GV.PO-02_ID.RA-05_ID.RA-06_none_High
10_"Signatories will ensure an SSR has sufficient scientific detail to allow for the independent assessment of the methods used to generate the results, evidence, and analysis"_ID.RA-06_GV.OC-03_RS.CO-03_transparency_High
10_"while protecting intellectual property rights and confidential business information where appropriate