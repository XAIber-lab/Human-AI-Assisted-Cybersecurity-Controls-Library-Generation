1_As part of their reporting obligations under Article 34(4) of Regulation (EU) 2019/1020, the market surveillance authorities shall report annually to the Commission and relevant national competition authorities any information identified in the course of market surveillance activities that may be of potential interest for the application of Union law on competition rules._ID.RA-02; RS.CO-03_GV.RR-02_GV.OC-03_privacy_medium
1_They shall also annually report to the Commission about the use of prohibited practices that occurred during that year and about the measures taken._RS.CO-02_RS.CO-03_GV.OC-03__high
1_For high-risk AI systems related to products covered by the Union harmonisation legislation listed in Section A of Annex I, the market surveillance authority for the purposes of this Regulation shall be the authority responsible for market surveillance activities designated under those legal acts._GV.RR-02_ID.AM-02_GV.OC-03__medium definition
2_Without prejudice to the powers of market surveillance authorities under Article 14 of Regulation (EU) 2019/1020, for the purpose of ensuring the effective enforcement of this Regulation, market surveillance authorities may exercise the powers referred to in Article 14(4), points (d) and (j), of that Regulation remotely, as appropriate._GV.RR-02_GV.OC-03_PR.AA-01__high
2_Where the market surveillance authority of a Member State has sufficient reason to consider an AI system to present a risk as referred to in paragraph 1 of this Article, it shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation._ID.RA-01; ID.RA-04_DE.AE-02_ID.RA-05__high
2_Particular attention shall be given to AI systems presenting a risk to vulnerable groups._ID.RA-05_GV.OC-02_ID.RA-04__high
2_Where risks to fundamental rights are identified, the market surveillance authority shall also inform and fully cooperate with the relevant national public authorities or bodies referred to in Article 77(1)._RS.CO-02_ID.RA-06_RS.CO-03__high
4_The operator shall ensure that all appropriate corrective action is taken in respect of all the AI systems concerned that it has made available on the Union market._RS.MI-01; RS.MI-02_ID.RA-06_PR.IR-03__high
7_Market surveillance authorities shall have competences and powers to ensure that testing in real world conditions is in accordance with this Regulation._GV.RR-02_ID.RA-09_PR.PS-06__high
7_Where a market surveillance authority has been informed by the prospective provider, the provider or any third party of a serious incident or has other grounds for considering that the conditions set out in Articles 60 and 61 are not met, it may take either of the following decisions on its territory, as appropriate: (a) to suspend or terminate the testing in real world conditions._RS.MI-01_RS.MA-04_DE.AE-08__high
8_Market surveillance authorities and the Commission shall be able to propose joint activities, including joint investigations, to be conducted by either market surveillance authorities or market surveillance authorities jointly with the Commission, that have the aim of promoting compliance, identifying non-compliance, raising awareness or providing guidance in relation to this Regulation with respect to specific categories of high-risk AI systems._ID.IM-02_PR.AT-01; PR.AT-02_ID.RA-01__high
11_Market surveillance authorities and the Commission shall be able to propose joint activities, including joint investigations, to be conducted by either market surveillance authorities or market surveillance authorities jointly with the Commission, that have the aim of promoting compliance, identifying non-compliance, raising awareness or providing guidance in relation to this Regulation with respect to specific categories of high-risk AI systems that are found to present a serious risk across two or more Member States._ID.IM-02_PR.AT-01; PR.AT-02_ID.RA-01__high
12_Without prejudice to the powers provided for under Regulation (EU) 2019/1020, and where relevant and limited to what is necessary to fulfil their tasks, the market surveillance authorities shall be granted full access by providers to the documentation as well as the training, validation and testing data sets used for the development of high-risk AI systems, including, where appropriate and subject to security safeguards, through application programming interfaces (API) or other relevant technical means and tools enabling remote access._PR.DS-01; PR.DS-02_ID.AM-07_PR.AA-05_data protection_high
13_Market surveillance authorities shall be granted access to the source code of the high-risk AI system upon a reasoned request and only when both of the following conditions are fulfilled: (a) access to source code is necessary to assess the conformity of a high-risk AI system with the requirements set out in Chapter III, Section 2; and, (b) testing or auditing procedures and verifications based on the data and documentation provided by the provider have been exhausted or proved insufficient._ID.AM-02_PR.AA-05_PR.DS-01_transparency_high
14_Any information or documentation obtained by market surveillance authorities shall be treated in accordance with the confidentiality obligations set out in Article 78._PR.DS-01_GV.PO-01_PR.DS-02_data protection_high
14_Where the market surveillance authority considers that the non-compliance is not restricted to its national territory, it shall inform the Commission and the other Member States without undue delay of the results of the evaluation and of the actions which it has required the operator to take._RS.CO-02; RS.CO-03_DE.AE-04_ID.RA-06__high
15_The notification referred to in paragraph 5 shall include all available details, in particular the information necessary for the identification of the non-compliant AI system, the origin of the AI system and the supply chain, the nature of the non-compliance alleged and the risk involved, the nature and duration of the national measures taken and the arguments put forward by the relevant operator._RS.CO-03_ID.AM-02_DE.AE-04__high
20_Any affected person subject to a decision which is taken by the deployer on the basis of the output from a high-risk AI system listed in Annex III, with the exception of systems listed under point 2 thereof, and which produces legal effects or similarly significantly affects that person in a way that they consider to have an adverse impact on their health, safety or fundamental rights shall have the right to obtain from the deployer clear and meaningful explanations of the role of the AI system in the decision-making procedure and the main elements of the decision taken._GV.OC-03_PR.AT-01_RS.CO-02_transparency_high
20_Where, having performed an evaluation under Article 79, after consulting the relevant national public authority referred to in Article 77(1), the market surveillance authority of a Member State finds that although a high-risk AI system complies with this Regulation, it nevertheless presents a risk to the health or safety of persons, to fundamental rights, or to other aspects of public interest protection, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk._ID.RA-05_ID.RA-06_RS.MI-01__high
22_Where, in the course of that evaluation, the market surveillance authority finds that the AI system concerned is high-risk, it shall without undue delay require the relevant provider to take all necessary actions to bring the AI system into compliance with the requirements and obligations laid down in this Regulation._ID.RA-06_RS.MI-01_GV.RR-02__high
30_For the purpose of carrying out evaluations of the general-purpose AI model, the Commission may request access to the general-purpose AI model concerned through APIs or further appropriate technical means and tools, including source code._ID.AM-02_PR.AA-05_ID.RA-01_transparency_high
32_Prior to requesting access to the general-purpose AI model concerned, the AI Office may initiate a structured dialogue with the provider of the general-purpose AI model to gather more information on the internal testing of the model, internal safeguards for preventing systemic risks, and other internal procedures and measures the provider has taken to mitigate such risks._ID.IM-02_ID.RA-01_GV.SC-07__high
34_The AI Office and the Member States shall encourage and facilitate the drawing up of codes of conduct, including related governance mechanisms, intended to foster the voluntary application to AI systems, other than high-risk AI systems, of some or all of the requirements set out in Chapter III, Section 2 taking into account the available technical solutions and industry best practices allowing for the application of such requirements._GV.PO-01_PR.AT-01_GV.RR-01__medium
35_The AI Office and the Member States shall facilitate the drawing up of codes of conduct concerning the voluntary application, including by deployers, of specific requirements to all AI systems, on the basis of clear objectives and key performance indicators to measure the achievement of those objectives, including elements such as, but not limited to: (a) applicable elements provided for in Union ethical guidelines for trustworthy AI; (b) assessing and minimising the impact of AI systems on environmental sustainability, including as regards energy-efficient programming and techniques for the efficient design, training and use of AI; (c) promoting AI literacy, in particular that of persons dealing with the development, operation and use of AI; (d) facilitating an inclusive and diverse design of AI systems, including through the establishment of inclusive and diverse development teams and the promotion of stakeholders' participation in that process._GV.PO-01_PR.AT-01; PR.AT-02_GV.RR-01__high
35_assessing and preventing the negative impact of AI systems on vulnerable persons or groups of vulnerable persons, including as regards accessibility for persons with a disability, as well as on gender equality._ID.RA-05_GV.OC-02_ID.RA-04__high
43_When deciding whether to impose an administrative fine and when deciding on the amount of the administrative fine in each individual case, all relevant circumstances of the specific situation shall be taken into account and, as appropriate, regard shall be given to the following: (a) the nature, gravity and duration of the infringement and of its consequences, taking into account the purpose of the AI system, as well as, where appropriate, the number of affected persons and the level of damage suffered by them._DE.AE-04_ID.RA-05_RS.AN-08__high
43_When deciding whether to impose an administrative fine and when deciding on the amount of the administrative fine in each individual case, all relevant circumstances of the specific situation shall be taken into account and, as appropriate, regard shall be given to: (b) whether administrative fines have already been applied by other market surveillance authorities to the same operator for the same infringement._DE.AE-03_ID.RA-07_RS.AN-03__medium
44_(e) any other aggravating or mitigating factor applicable to the circumstances of the case, such as financial benefits gained, or losses avoided, directly or indirectly, from the infringement; (f) the degree of cooperation with the national competent authorities, in order to remedy the infringement and mitigate the possible adverse effects of the infringement; (g) the degree of responsibility of the operator taking into account the technical and organisational measures implemented by it; (h) the manner in which the infringement became known to the national competent authorities, in particular whether, and if so to what extent, the operator notified the infringement; (i) the intentional or negligent character of the infringement; (j) any action taken by the operator to mitigate the harm suffered by the affected persons._ID.RA-04; ID.RA-05_DE.AE-02_RS.AN-03__high