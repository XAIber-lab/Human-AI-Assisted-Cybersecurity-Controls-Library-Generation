54_ISO/IEC 23894:2022, Information Technology – Artificial Intelligence – Guidance on risk management: Guidelines for the risk management of the development and use of AI systems. This standard is also being developed under the direction of a German editor._GV.RM-01_GV.RM-06_ID.RA-05__High (definition)
54_ISO/IEC 42001, Information Technology – Artificial Intelligence – Management System: Certifiable management standard for AI that contains requirements and organizations for the responsible development and use of AI systems._GV.PO-01_GV.RR-01_GV.RR-02__High (definition)
54_ISO/IEC 42005, Information Technology – Artificial Intelligence – AI System impact assessment: Impact assessment for the use of AI systems_ID.RA-04_ID.RA-05___High (definition)
54_Requirements and certification bodies: Requirements and certification bodies_GV.OC-03____Low (definition)
72_Privacy ethical design underpins all systems with the principle of individual privacy. In doing so, it goes beyond the concept of privacy per se and assigns it a clear ethical dimension, taking into account not only direct influences but also indirect influences on the needs of the user. This promotes a basic trust in new technologies and thus increases market acceptance._GV.PO-01_PR.DS-01_GV.OC-02_privacy_High
74_The ethical re-evaluation of AI systems is based on their core values. These core values must be identified beforehand in the development process by the company as part of a stakeholder process._GV.RR-01_GV.OC-02___High
76_Those responsible for an AI system must examine not only the individual requirements, but the system as a whole. Only in this way can they assess the interactions of individual components or decisions and the potentially resulting conflicts of objectives, especially in complex systems._ID.AM-08_GV.RM-03___High
77_Those responsible for AI systems can promote and justify the value-based development and operation of the systems through ethical reflection. This apparent value base is a key factor in AI systems gaining social acceptance._GV.RR-01_GV.OC-02___Medium
79_In order to also be able to evaluate artificial intelligence systems in their ethical dimension during their use and, if necessary, to model decision bases, the use of a quality backward chain is recommended. This acquires field data as part of the deployment, which enables a judgement to be made about ethical decisions made by the system._DE.CM-09_DE.AE-02_ID.IM-01__High
80_The AI system must respect human self-determination. It should be possible to gradate the degree to which defined values are implemented via AI depending on the use case, combined with justifying documentation for this decision._GV.OC-03_GV.PO-01__transparency_High
81_Only a deeper consideration of the security/safety of AI-based technologies and applications can enable their comprehensive use in industry and society._ID.RA-05_PR.PS-01___Medium
82_For high-risk AI applications, for example, the proposed AI Act requires sufficient relevance as well as representativeness, accuracy, and completeness with respect to the intended application._ID.RA-05_GV.OC-03___High
82_Verification and validation: Testing of the AI system with respect to requirements and the fulfilment of project objectives._ID.IM-02_ID.RA-01___High
82_Operation and monitoring: The system is commissioned and monitored during operation._DE.CM-09_PR.PS-04___High
83_Support includes the provision of resources, the determination of necessary competencies, ensuring necessary mindfulness, communication and documentation._GV.RR-03_PR.AT-01___Medium
83_Operation is the operational implementation of management requirements._GV.PO-01____Low
83_Performance evaluation comprises monitoring, analysis and evaluation, internal auditing and management review._GV.OV-03_DE.CM-09___High
84_Testing and auditing processes will also gain importance for (learning and continual learning) NLP systems._ID.IM-02_DE.CM-09___Medium
87_For high-risk applications in particular, however, it is necessary to prove that performance is not in fact unacceptably impaired by anonymization, for example._ID.RA-04_PR.DS-01__data protection_High
87_In particular, processing high-resolution data often requires significant amounts of corresponding high-resolution annotations as a training basis. This is accompanied not only by considerable financial outlay, but also by the challenge of ensuring the quality of an appropriate dataset for specific applications._ID.AM-07_PR.DS-01__data protection_High
90_Documentation requirements and intervals for mandatory re-evaluations are to be standardized._GV.PO-02_ID.IM-01___High
91_In order to enable all parties to act transparently in the interest of trustworthy AI development, it is necessary to further develop the purpose limitation of data._PR.DS-01_GV.OC-03__transparency_High
92_Methods must be developed to assess the extent to which given image features are still trustworthy according to the state of the art (and can therefore be used for authentication) and at what point corresponding features can be manipulated._ID.RA-01_PR.DS-01___High
92_Better transparency and clarity with regard to the different levels of criticality (also beyond the classification in the planned AI Act and the associated requirements) should be created and anchored in corresponding standards._GV.OC-03_ID.RA-05__transparency_High
95_Metrics should be explored to assess what type of personal information may be latent in a given ML model and how to mitigate corresponding potential for misuse._PR.DS-01_ID.RA-01__privacy_High
96_Targeted research should be conducted and funded with the goal of enabling the development of high-performance AI/ML methods for image data while complying with data protection constraints, and quantifying the extent to which this is possible._PR.DS-01_ID.RA-04__data protection_High