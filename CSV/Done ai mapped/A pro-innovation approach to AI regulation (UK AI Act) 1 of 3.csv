page_text_first proposal_second proposal_third proposal_labels_confidence_definitions
1_Discriminatory outcomes that result from the use of AI may contravene the protections set out in the Equality Act 2010. AI systems are also required by data protection law to process personal data fairly. However, AI can increase the risk of unfair bias or discrimination across a range of indicators or characteristics. This could undermine public trust in AI._GV.OC-03_ID.RA-03_GV.PO-01_data protection_Medium_definition
1_Product safety laws ensure that goods manufactured and placed on the market in the UK are safe. Product-specific legislation may apply to some products that include integrated AI. However, safety risks specific to AI technologies should be monitored closely. As the capability and adoption of AI increases, it may pose new and substantial risks that are unaddressed by existing rules._ID.RA-01; ID.RA-05_GV.OC-03_ID.RA-03__High_
14_AI systems should function in a robust, secure and safe way throughout the AI life cycle, and risks should be continually identified, assessed and managed._ID.RA-05; GV.RM-06_PR.PS-01__security_High_
14_Regulators may need to introduce measures for regulated entities to ensure that AI systems are technically secure and function reliably as intended throughout their entire life cycle._PR.PS-06; ID.AM-08_PR.PS-01___High_
14_System developers should be aware of the specific security threats that could apply at different stages of the AI life cycle and embed resilience to these threats into their systems._PR.AT-02_ID.RA-01_PR.PS-06__High_
15_An appropriate level of transparency and explainability will mean that regulators have sufficient information about AI systems and their associated inputs and outputs to give meaningful effect to the other principles._GV.OC-02; GV.RR-02_RS.CO-03__transparency_Medium_
15_Parties directly affected by the use of an AI system should also be able to access sufficient information about AI systems to be able to enforce their rights._GV.OC-02_RS.CO-02__transparency_High_
16_AI systems should not undermine the legal rights of individuals or organisations, discriminate unfairly against individuals or create unfair market outcomes._GV.OC-03_GV.PO-01___High_
17_Governance measures should be in place to ensure effective oversight of the supply and use of AI systems, with clear lines of accountability established across the AI life cycle._GV.RR-01; GV.RR-02_GV.PO-01___High_
17_AI life cycle actors should take steps to consider, incorporate and adhere to the principles and introduce measures necessary for the effective implementation of the principles at all stages of the AI life cycle._GV.RR-02_ID.IM-01_PR.AT-01__High_
17_Regulator guidance on this principle should reflect that "accountability" refers to the expectation that organisations or individuals will adopt appropriate measures to ensure the proper functioning, throughout their life cycle, of the AI systems that they research, design, develop, train, operate, deploy, or otherwise use._GV.RR-01; GV.RR-02____Medium_definition
18_Assurance techniques like impact assessments can help to identify potential risks early in the development life cycle, enabling their mitigation through appropriate safeguards and governance mechanisms._ID.RA-05; ID.RA-06_GV.RM-06___High_
18_Regulatory guidance should also reflect the responsibilities such life cycle actors have for demonstrating proper accountability and governance (for example, by providing documentation on key decisions throughout the AI system life cycle, conducting impact assessments or allowing audits where appropriate)._GV.RR-02_ID.RA-06_GV.OV-03__High_
18_Where appropriate, users, impacted third parties and actors in the AI life cycle should be able to contest an AI decision or outcome that is harmful or creates material risk of harm._GV.OC-02_RS.CO-02___High_
18_Regulators will be expected to clarify existing routes to contestability and redress, and implement proportionate measures to ensure that the outcomes of AI use are contestable where appropriate._GV.OC-03; GV.PO-01_RS.CO-02___High_
18_We would also expect regulators to encourage and guide regulated entities to make clear routes (including informal channels) easily available and accessible, so affected parties can contest harmful AI outcomes or decisions as needed._GV.OC-02_RS.CO-02_RS.CO-03_transparency_High_