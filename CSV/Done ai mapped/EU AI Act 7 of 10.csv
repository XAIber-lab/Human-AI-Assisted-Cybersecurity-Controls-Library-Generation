page_text_First proposal_Second proposal_Third proposal_labels_confidence_definitions
3_AI regulatory sandboxes established under paragraph 1 shall provide for a controlled environment that fosters innovation and facilitates the development, training, testing and validation of innovative AI systems for a limited time before their being placed on the market or put into service pursuant to a specific sandbox plan agreed between the providers or prospective providers and the competent authority_GV.PO-01_GV.OC-01_GV.RM-01__High_
3_Competent authorities shall provide, as appropriate, guidance, supervision and support within the AI regulatory sandbox with a view to identifying risks, in particular to fundamental rights, health and safety, testing, mitigation measures, and their effectiveness in relation to the obligations and requirements of this Regulation and, where relevant, other Union and national law supervised within the sandbox_GV.RR-02_ID.RA-05_RS.MI-01__High_
3_Competent authorities shall provide providers and prospective providers participating in the AI regulatory sandbox with guidance on regulatory expectations and how to fulfil the requirements and obligations set out in this Regulation_GV.OC-03_GV.PO-01___Medium_
6_Any serious incident identified in the course of the testing in real world conditions shall result in an adequate mitigation. National competent authorities shall have the power to temporarily or permanently suspend the testing process, or the participation in the sandbox if no effective mitigation is possible, and shall inform the AI Office of such decision_RS.MI-01; RS.MI-02_DE.AE-04_RS.CO-02__High_
14_there are effective monitoring mechanisms to identify if any high risks to the rights and freedoms of the data subjects, as referred to in Article 35 of Regulation (EU) 2016/679 and in Article 39 of Regulation (EU) 2018/1725, may arise during the sandbox experimentation, as well as response mechanisms to promptly mitigate those risks and, where necessary, stop the processing_DE.CM-03_ID.RA-05_RS.MI-01_privacy_High_
14_any personal data to be processed in the context of the sandbox are in a functionally separate, isolated and protected data processing environment under the control of the prospective provider and only authorised persons have access to those data_PR.DS-01_PR.AA-05__data protection_High_
15_providers can further share the originally collected data only in accordance with Union data protection law; any personal data created in the sandbox cannot be shared outside the sandbox_PR.DS-02_GV.OC-03__data protection_High_
15_any personal data processed in the context of the sandbox are protected by means of appropriate technical and organisational measures and deleted once the participation in the sandbox has terminated or the personal data has reached the end of its retention period_PR.DS-01; PR.DS-02_PR.PS-01__data protection_High_
15_the logs of the processing of personal data in the context of the sandbox are kept for the duration of the participation in the sandbox, unless provided otherwise by Union or national law_PR.PS-04_ID.AM-07__data protection_Medium_
15_a complete and detailed description of the process and rationale behind the training, testing and validation of the AI system is kept together with the testing results as part of the technical documentation referred to in Annex IV_ID.IM-02_PR.PS-04__transparency_High_
20_The subjects of testing in real world conditions who are persons belonging to vulnerable groups due to their age or disability, are appropriately protected_PR.DS-01_GV.OC-02___High_
20_where a provider or prospective provider organises the testing in real world conditions in cooperation with one or more deployers or prospective deployers, the latter have been informed of all aspects of the testing that are relevant to their decision to participate, and given the relevant instructions for use of the AI system_GV.SC-02_RS.CO-03___High_
21_the testing in real world conditions is effectively overseen by the provider or prospective provider, as well as by deployers or prospective deployers through persons who are suitably qualified in the relevant field and have the necessary capacity, training and authority to perform their tasks_PR.AT-02_GV.RR-02___High_
21_the predictions, recommendations or decisions of the AI system can be effectively reversed and disregarded_PR.IR-03_RS.MI-01___High_
21_Any subjects of the testing in real world conditions, or their legally designated representative, as appropriate, may, without any resulting detriment and without having to provide any justification, withdraw from the testing at any time by revoking their informed consent and may request the immediate and permanent deletion of their personal data_PR.DS-01_PR.AA-05__data protection_High_
22_Any serious incident identified in the course of the testing in real world conditions shall be reported to the national market surveillance authority in accordance with Article 73. The provider or prospective provider shall adopt immediate mitigation measures or, failing that, shall suspend the testing in real world conditions until such mitigation takes place, or otherwise terminate it_RS.CO-02_RS.MI-01_DE.AE-08__High_
41_Member States shall ensure that their national competent authorities are provided with adequate technical, financial and human resources to fulfil their tasks effectively under this Regulation. In particular, the national competent authorities shall have a sufficient number of personnel permanently available whose competences and expertise shall include an in-depth understanding of AI technologies, data and data computing, personal data protection, cybersecurity, fundamental rights, health and safety risks and knowledge of existing standards and legal requirements_GV.RR-03_PR.AT-02___High_
45_The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by deployers or which may be collected through other sources on the performance of high-risk AI systems throughout their lifetime, and which allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Chapter III, Section 2_DE.CM-09_ID.AM-08___High_
47_For high-risk AI systems covered by the Union harmonisation legislation listed in Section A of Annex I, where a post-market monitoring system and plan are already established under that legislation, in order to ensure consistency, avoid duplications and minimise additional burdens, providers shall have a choice of integrating, as appropriate, the necessary elements described in paragraphs 1, 2 and 3 using the template referred in paragraph 3 into systems and plans already existing under that legislation, provided that it achieves an equivalent level of protection_GV.PO-02_ID.IM-01___Medium_
48_Following the reporting of a serious incident pursuant to paragraph 1, the provider shall, without delay, perform the necessary investigations in relation to the serious incident and the AI system concerned. This shall include a risk assessment of the incident, and corrective action_RS.AN-03_ID.RA-05_DE.AE-04__High_
48_The provider shall cooperate with the competent authorities, and where relevant with the notified body concerned, during the investigations referred to in the first subparagraph, and shall not perform any investigation which involves altering the AI system concerned in a way which may affect any subsequent evaluation of the causes of the incident, prior to informing the competent authorities of such action_RS.AN-06_RS.AN-07___High_
50_National competent authorities shall ensure that their representatives on the Board: have the relevant competences and powers in their Member State so as to contribute actively to the achievement of the Board's tasks_GV.RR-02____Medium, definition_
50_Each Member State shall establish or designate as national competent authorities at least one notifying authority and at least one market surveillance authority for the purposes of this Regulation. Those national competent authorities shall exercise their powers independently, impartially and without bias so as to safeguard the objectivity of their activities and tasks, and to ensure the application and implementation of this Regulation_GV.RR-01_GV.RR-02___Medium, definition