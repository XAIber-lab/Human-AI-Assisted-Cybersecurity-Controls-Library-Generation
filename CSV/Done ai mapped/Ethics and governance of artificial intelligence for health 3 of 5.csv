page_text_First proposal_Second proposal_Third proposal_labels_confidence_definitions
1_While physicians must be able to trust an algorithm, they should not ignore their own expertise and judgement and simply rubber-stamp the recommendation of a machine_GV.RR-02_PR.AT-02_GV.OC-02__High_
1_Assignation of accountability is even more complex when a decision is made to use an AI technology throughout a health-care system, as the developer, the institution and the physician may all have played a role in the medical harm, yet none is fully to blame. In such situations, accountability may rest not with the provider or the developer of the technology but with the government agency or institution that selected, validated and deployed it_GV.RR-01; GV.RR-02_GV.OV-03_GV.SC-02_transparency_High_
1_Decision-making has not yet been "fully transferred" from humans to machines in health care. While AI is used only to augment human decision-making in the practice of public health and medicine, epistemic authority has, in some circumstances, been displaced, whereby AI systems are displacing humans from the centre of knowledge production_GV.OC-01_GV.RR-02___Medium_definition
1_Furthermore, there are signs of full delegation of routine medical functions to AI. Delegation of clinical judgement introduces concern about whether full delegation is legal, as laws increasingly recognize the right of individuals not to be subject to solely automated decisions when such decisions would have a significant effect_GV.OC-03_GV.RR-02___Medium_
1_Use of AI systems to make specific, well-defined decisions may be entirely justified if there is compelling clinical evidence that the system performs the task better than a human_ID.RA-09_GV.OV-03___Medium_
2_The challenge of humanâ€“computer interactions has been addressed by validating systems, providing appropriate education for users and validating the systems continuously_PR.AT-01; PR.AT-02_ID.RA-09_ID.IM-02__High_
2_It may, however, be ethically challenging for doctors to rely on the judgement of AI, as they have to accept decisions based on black-box algorithms. The widely held convention is that many algorithms are black boxes that make inferences and decisions that are not understood even by their developers_GV.OC-02_PR.AT-02___Medium_definition
2_AI should therefore be transparent and explainable, which is listed as a core guiding principle_GV.PO-01_GV.OC-03__transparency_High_
2_Clinicians require other types of information, even if they do not understand exactly how an algorithm functions, including the data on which it was trained, how and who built the AI model and the variables underlying the AI model_PR.AT-02_ID.AM-02_GV.SC-02__High_
2_Some argue that, if a trade-off must be made between even greater transparency (and explainability) and accuracy, transparency should be preferred_GV.PO-01_GV.OC-03__transparency_High_
3_Although providing individuals with more opportunities to share data and to obtain autonomous health advice could improve their agency and self-care, it could also generate anxiety and fatigue_ID.RA-04_GV.OC-02__data protection_Low_
3_Most patients have insufficient knowledge about how and why AI technologies make certain decisions, and the technologies themselves may not be sufficiently transparent, even if a patient is well informed_PR.AT-01_GV.OC-02__transparency_Medium_
3_Hospitals and health-care providers are unlikely to inform patients that AI was used as a part of decision-making to guide, validate or overrule a provider_GV.OC-02_GV.RR-02___Low_definition
4_Physicians should be frank with patients from the onset and inform them of the use of AI rather than hiding the technology. They should try their best to explain to their patients the purpose of using AI, how it functions and whether it is explainable. They should describe what data are collected, how they are used and shared with third parties and the safeguards for protection of patients' privacy. Physicians should also be transparent about any weaknesses of the AI technology, such as any biases, data breaches or privacy concerns_GV.RR-02_PR.AT-01_GV.OC-02_transparency; privacy_High_
5_Loss of control could be construed as surrendering not just to a technology but also to companies that exert power over the development, deployment and use of AI for health care_GV.OC-05_GV.SC-02___Low_definition
5_Companies, unlike health systems or governments, may, however, ignore the needs of citizens and the obligations owed to citizens, as there is a distinction between citizens and customers_GV.OC-02_GV.SC-02___Low_definition
5_Moreover, there is a familiar problem and risk that data in both traditional databases and machine-learning training sets might be biased. Such bias could lead to allocation of resources that discriminates against, for example, people of colour; decisions related to gender, ethnicity or socioeconomic status might similarly be biased_ID.RA-04_ID.RA-05_GV.OC-03__High_
5_Ethical design could mitigate these risks and ensure that AI technologies are used to assist humans by appropriate resource allocation and prioritization_GV.PO-01_ID.RA-06_GV.RM-04__High_
5_Furthermore, such technologies must be maintained as a means of aiding human decision-making and assuring that humans ultimately make the right critical life-and-death decisions by adequately addressing the risks of such uses of AI and providing those affected by such decisions with contestation rights_GV.RR-02_ID.RA-06_GV.RM-04__High_
6_While AI-based diagnosis is near term and its efficiency can be tested, thereby mitigating potential harm, efficacy and accuracy in long-term predictions may be more difficult or impossible to achieve_ID.RA-04_ID.RA-05___Medium_
6_The risk of harm therefore increases dramatically, as predictions of limited reliability could affect an individual's health and well-being and result in unnecessary expenditure of scarce resources_ID.RA-04_ID.RA-05_GV.RM-02__High_
7_The inadequacy of the data on people of colour is due to several structural factors, including lack of medical professionals and of adequate information in communities of colour and economic barriers that prevent marginalized communities from seeking health care or participating in research that would allow such individuals to contribute data_ID.RA-03_GV.OC-02___Medium_definition
13_Patient safety could be at risk from use of AI that may not be foreseen during regulatory review of the technology for approval. Errors in AI systems, including incorrect recommendations and recommendations based on false-negative or false-positive results, can cause injury to a patient or a group of people with the same health condition_ID.RA-01; ID.RA-04_DE.AE-04_GV.OC-03__High_
13_Model resilience, or how an AI technology performs over time, is a related risk_ID.RA-04_DE.CM-09___Medium_definition
13_As health-care systems become increasingly dependent on AI, these technologies may be expected to be targeted for malicious attacks and hacking in order to shut down certain systems, to manipulate the data used for training the algorithm, thereby changing its performance and recommendations, or to "kidnap" data for ransom_ID.RA-03_PR.DS-01; PR.DS-02__data protection_High_
14_It is also possible that a developer (or an entity that funds or directs the design of AI technology) designs an AI technology unethically, to optimize an outcome that would generate profits for the provider or conceal certain practices_ID.RA-03_GV.SC-07_GV.OC-03__High_
14_Use of computers carries an inherent risk of flaws in safety due to insufficient attention to minimizing risk in the design of machines and also to flaws in the computer code and associated bugs and glitches_ID.RA-01_PR.PS-06___High_
14_Breaches of health data, which are some of the most sensitive data about individuals, could harm privacy and dignity and the broader exercise of human rights_ID.RA-03_PR.DS-01; PR.DS-02_GV.OC-03_privacy_High_
14_An algorithm, especially one that runs independently of human oversight, could be hacked to generate revenue for certain recipients_ID.RA-03_PR.DS-01___Medium_
18_A general problem is lack of transparency. While many firms know much about their users, their users, civil society and regulators know little about the activities of the firms, including how they (and governments) operate in PPPs, which have a significant impact on the public interest_GV.OC-02_GV.SC-02__transparency_Medium_definition
18_Without transparency (and accountability), these firms have little incentive to act in a way that does not cross certain ethical boundaries or to disclose deeper problems in their technology, data or models_GV.RR-01_GV.OC-02__transparency_High_