text_extract;highlight_color
"This paper and the taxonomy of trustworthiness it introduces can ideally supplement use of the NIST AI RMF because it provides an approach for connecting what are currently three relatively disparate elements: the core framework, the AI lifecycle, and the characteristics of trustworthiness.";red
"The overall trustworthiness of an AI system is dependent upon the holistic consideration of all properties. For example, an AI system that is reliable and safe, but is not made transparent or explainable to users, is unlikely to be trusted.";yellow
"There are also tensions between properties that can arise, for example between explainability and security.";red
"In some cases an organization will need to make tradeoffs between some of the properties, either due to resource constraints or conflicts between two or more properties. Which properties to prioritize will depend on the context of the particular organization, AI system, and use case.";yellow
"The people best suited to address a particular property will vary depending on the organization and the type of system being developed. In general, we expect that multidisciplinary and diverse teams will be critical, and that many roles will have relevant input on how to effectively consider the properties.";green
"We expect that in many cases, decisions about a particular property will not be made by a single person or team, but rather there will be chains of interactions among people with different roles who bring unique expertise.";yellow
"It will also be critical that the teams exploring the trustworthiness of AI systems have the power to influence or implement necessary changes.";green
"If risks and impact are deemed to be unacceptable, how will we ensure the AI system is adjusted or rejected?";green
"Rather than looking at a small number of final high-risk use cases to determine the relevancy of properties, we opted instead to focus on a set of questions that reveal more about the nature of the interaction between the system and people.";yellow
"An AI system may change its degree of human engagement at some point during its lifecycle, and so any assessment of human engagement should be revisited at regular intervals.";green
"Conducting a risk and impact assessment is still a critical process for any AI system, and should be done in addition to considering the degree to which an AI system engages with people.";green
"Security-by-Design How will we build security into the AI system design, testing, deployment, and operation? How often will we provide security updates to the AI system?";green
"Availability How will we ensure that information for and about the AI system is available to authorized personnel when it is needed?";green
"Confidentiality How will we ensure that information is not made available or disclosed to unauthorized individuals, entities, or processes?";green
"Integrity How will we maintain and ensure the accuracy, completeness, and appropriateness of data, models, and procedures informing the AI system?";green
"This paper and the taxonomy of trustworthiness it introduces can ideally supplement use of the NIST AI RMF because it provides an approach for connecting what are currently three relatively disparate elements: the core framework, the AI lifecycle, and the characteristics of trustworthiness.";red
"The overall trustworthiness of an AI system is dependent upon the holistic consideration of all properties. For example, an AI system that is reliable and safe, but is not made transparent or explainable to users, is unlikely to be trusted.";yellow
"There are also tensions between properties that can arise, for example between explainability and security.";red
"In some cases an organization will need to make tradeoffs between some of the properties, either due to resource constraints or conflicts between two or more properties. Which properties to prioritize will depend on the context of the particular organization, AI system, and use case.";yellow
"The people best suited to address a particular property will vary depending on the organization and the type of system being developed. In general, we expect that multidisciplinary and diverse teams will be critical, and that many roles will have relevant input on how to effectively consider the properties.";green
"We expect that in many cases, decisions about a particular property will not be made by a single person or team, but rather there will be chains of interactions among people with different roles who bring unique expertise.";yellow
"It will also be critical that the teams exploring the trustworthiness of AI systems have the power to influence and implement necessary changes.";green
"If risks and impact are deemed to be unacceptable, how will we ensure the AI system is adjusted or rejected?";green
"Rather than looking at a small number of final high-risk use cases to determine the relevancy of properties, we opted instead to focus on a set of questions that reveal more about the nature of the interaction between the system and people.";yellow
"An AI system may change its degree of human engagement at some point during its lifecycle, and so any assessment of human engagement should be revisited at regular intervals.";green
"Conducting a risk and impact assessment is still a critical process for any AI system, and should be done in addition to considering the degree to which an AI system engages with people.";green
"Security-by-Design How will we build security into the AI system design, testing, deployment, and operation? How often will we provide security updates to the AI system?";green
"Availability How will we ensure that information for and about the AI system is available to authorized personnel when it is needed?";green
"Confidentiality How will we ensure that information is not made available or disclosed to unauthorized individuals, entities, or processes?";green
"Integrity How will we maintain and ensure the accuracy, completeness, and appropriateness of data, models, and procedures informing the AI system?";green
"High Quality AI System Configuration How will we assess the quality of the AI system design and configuration and ensure consistently high quality?";green
"High Quality Network Resources and Services How will we assess and ensure the quality of shared network resources and services, e.g., distributed dataset access?";green
"Trusted Dependencies on External Parties How will we identify, assess, and monitor our dependencies on external parties?";green
"Foresight and Scenario Planning How will we assess and navigate possible futures and the evolving risk landscape?";green
"Protection of Physical and Psychological Safety How will we ensure that the AI system will not cause physical or psychological harm or lead to a state in which human life, health, property, or the environment is endangered?";green
"Assurance / Management of Uncertainty If we do not know all of the elements required for the safe development and deployment of the AI system, how will we manage this uncertainty?";green
"Assurance / Management of Multi-Capability / Multi-Modal Systems If an AI system has multiple capabilities or works across multiple modalities, how will we document and manage this complexity?";green
"Alignment with Human Values How will we ensure that the AI system abides by desired human values and does not sacrifice human values to achieve its narrow goals?";yellow
"Governable How will we ensure an AI system is designed and engineered to achieve its goals while maintaining the ability to disengage or deactivate the system if necessary? How will we ensure an AI system would not have incentives to resist or deceive its operators?";green
"Diverse How will we ensure that gender, racial, age, ability, religious, cultural, disciplinary, and other relevant types of diversity are represented within the teams influencing AI development and use, throughout all stages of the AI lifecycle?";green
"Inclusive How will we ensure inclusivity of all relevant experts and communities in the design and development of the AI system?";green
"Equitable How will we navigate structural power dynamics and promote equity in the design and use of the AI system?";green
"Just How will we ensure justice in the design and use of the AI system?";green
"Mitigation of Systemic and Human Bias How will we assess and mitigate ways in which systemic and human bias may influence the design, development, and deployment of the AI system?";green
"Solidarity How will we ensure the design and use of the AI system respects the solidarity of groups and communities, such as workers, women, people with disabilities, ethnic minorities, children, or others?";green
"Privacy-by-Design How will privacy be built into the AI system design, testing, deployment, and operation?";green
"Data Privacy or Protection Impact Assessment What is the impact of the AI system on privacy? When and how will we conduct a data privacy or data protection impact assessment?";green
"Effective Policy and Governance How will we analyze and follow or implement relevant or desired AI and data standards, policies, principles, and guidance?";green
"Adherence to the Rule of Law How will we analyze and ensure compliance with all relevant laws and regulations across every jurisdiction of use?";green
"Coordination (Public-Private; International) How will we identify and coordinate with relevant institutions, nationally and internationally?";green
"Effective Risk Assessments and Impact Assessments How will we assess, document, and communicate the expected, potential, and actual risks and impacts of the AI system on people, organizations, and society?";green
"Community Engagement How will we identify communities interested in, engaged in, or impacted by the AI system, and how will we encourage their participation throughout the AI lifecycle?";green
"Open How can we promote openness and transparency about our development and governance of AI technologies, internally and externally?";green
"Documentation How will we document the AI system's design, datasets, training, characteristics, capabilities, limitations, predictable failures, intended uses, etc?";green
"Internal Reporting / Culture of Safety How will we incentivize internal reporting of challenges or concerns, and promote a culture of safety among teams?";green
"Internal Reviews How will internal reviews be conducted to assess trustworthy AI practices?";green
"Responsible Use in Government, Education, Health, Finance, Workplace, Identification and Detection, and other High-stakes Settings How will we ensure responsible potential and actual uses in high-stakes settings?";green
"Responsible Use in Critical Infrastructure and Safety-Critical Systems How will we ensure responsible potential and actual uses for critical infrastructure and safety-critical systems?";green
"Responsible Use in the Criminal Legal System and by Law Enforcement How will we ensure responsible potential and actual uses in the criminal legal system or by law enforcement?";green
"Responsible Use in Defense and National Security How will we promote peace and ensure responsible and controlled uses for defense, military, border control, and national security purposes, including for weapons systems?";green
"Verified Supply Chain How will we assess and verify the relevant components of the supply chain?";green
"Appropriate Assignment of Organizational Roles, Authorities, and Responsibilities How will we assign and document organizational roles, authorities, and responsibilities?";green
"Effective Capabilities How will we obtain the necessary resources and knowledge to achieve our trustworthy AI objectives?";yellow
"Collaboration How will we enable multi-stakeholder collaboration?";green
"Supportive Governance and Organizational Structure How can our governance and organizational structure support trustworthy AI?";green
"Effective Hiring and Training How will we support the hiring and training of individuals who can carry out trustworthy AI objectives?";green
"Responsible Labor Practices and Rights How can we support labor rights in our use of AI? How will the supply chain of the AI system be monitored to evaluate working conditions?";green
"Leadership Commitment How will we ensure long-term commitment to trustworthy AI from organizational leadership?";green
"Supportive Organizational Culture How will our organizational culture support our trustworthy AI objectives?";yellow
"Procurement Standards How will we implement/ensure AI procurement standards that support trustworthy AI if we are procuring the AI system or providing it to others?";green
"Appropriate Relationships, Interdependencies, and Interconnections What relationships, interdependencies, and interconnections will be involved in the development and use of the AI system?";green
"Alignment with Organizational Vision, Mission, and Values How will we ensure the AI system is true to our vision, mission, and values?";green
"Socially Responsible How will our AI system and its use align with our social responsibility efforts?";green
"Supportive of Fair Competition How will we support fair competition among a variety of actors in the domain in which our AI system is applied?";green
"Supportive of Civil Rights How will we protect and promote civil rights throughout the AI lifecycle, including protection from unlawful discrimination?";green
"Supportive of Democratic Values and Processes How will we ensure the design and use of the AI system are consistent with democratic values such as freedom and equality?";green
"Protection of Human Autonomy and Freedom How will we ensure that the AI system respects the freedom and autonomy of individuals and does not intrude on people's self-determination?";green
"Protection of Human Dignity How will we ensure that the development and use of the AI system respect human dignity and treat people as having intrinsic worth, and not merely as objects?";green
"Protection of Human Rights How will we ensure the AI system does not threaten human rights? For example, how will we ensure the right to privacy?";green
"Supportive of Wellbeing How will we ensure the AI system supports individual, community, and societal wellbeing, including mental or emotional wellbeing?";green
"Reduction of Carbon Emissions How can we reduce the carbon emissions from the design and use of AI systems in general?";yellow
"Assessment of Economic, Social, Cultural, Political, and Global Implications How will we assess the economic implications of the AI system, including whether use of the system could impact jobs or reduce the need for human labor?";green