2_While AI increases the importance of embedding data protection by design and default into an organisation's culture and processes, the technical complexities of AI systems can make this more difficult. Demonstrating how you have addressed these complexities is an important element of accountability_GV.PO-01_GV.RR-01_GV.OC-02_None_High_No
2_You cannot delegate these issues to data scientists or engineering teams. Your senior management, including DPOs, are also accountable for understanding and addressing them appropriately and promptly_GV.RR-01_GV.RR-02_GV.OV-01_None_High_No
2_To do so, in addition to their own upskilling, your senior management will need diverse, well-resourced teams to support them in carrying out their responsibilities_GV.RR-03_PR.AT-02_None_None_High_No
2_It is important that you do not underestimate the initial and ongoing level of investment of resources and effort that is required. You must be able to demonstrate, on an ongoing basis, how you have addressed data protection by design and default obligations_GV.RR-03_GV.PO-01_ID.IM-01_None_Medium_No
2_Your governance and risk management capabilities need to be proportionate to your use of AI. This is particularly true now while AI adoption is still in its initial stages_GV.RM-01_GV.OV-02_None_None_Medium_No
2_The risk-based approach of data protection law requires you to comply with your obligations and implement appropriate measures in the context of your particular circumstances_GV.RM-01; GV.RM-02_ID.RA-05_None_privacy_High_No
2_That is to say, you need to identify the risks to people's data protection rights associated with your processing activities_ID.RA-01; ID.RA-03_GV.RM-06_None_privacy_High_No
2_Your compliance considerations therefore involve assessing the risks to the rights and freedoms of individuals and judging what is appropriate in those circumstances_ID.RA-05_GV.RM-06_None_None_Medium_No
2_In the context of AI, the specific nature of the risks posed and the circumstances of your processing will require you to strike an appropriate balance between competing interests_ID.RA-05_GV.RM-04_None_None_High_No
2_It is unrealistic to adopt a 'zero tolerance' approach to risks to rights and freedoms, and indeed the law does not require you to do so. It is about ensuring that these risks are identified, managed and mitigated_GV.RM-02_ID.RA-06_None_None_High_No
3_assess the risks to individual rights that your use of AI poses; determine how you will address these; and establish the impact this has on your use of AI_ID.RA-05_ID.RA-06_GV.RM-04_None_High_No
3_This is a complex task, which can take time to get right. However, it will give you, as well as the ICO, a fuller and more meaningful view of your risk positions_ID.RA-05_GV.OV-03_None_None_Medium_No
4_Beyond this, AI can also involve several processing operations that are themselves likely to result in a high risk, such as use of new technologies or novel application of existing technologies, data matching, invisible processing, and tracking of location or behaviour_ID.RA-01_ID.RA-03_GV.RM-06_None_Medium_Yes
5_When considering the impact your processing has on individuals, it is important to consider both allocative harms and representational harms_ID.RA-04_ID.RA-05_None_None_High_No
5_Allocative harms are the result of a decision to allocate goods and opportunities among a group. The impact of allocative decisions may be loss of financial opportunity, loss of livelihood, loss of freedom, or in extreme circumstances, loss of life_ID.RA-04_None_None_None_Medium_Yes
5_Representational harms occur when systems reinforce the subordination of groups along identity lines. For example, through stereotyping, under-representation, or denigration, meaning belittling or undermining their human dignity_ID.RA-04_None_None_None_Medium_Yes
6_In the context of the AI lifecycle, a DPIA will best serve its purpose if you undertake it at the earliest stages of project development_GV.RM-01_ID.RA-01_None_None_High_No
6_Your DPIA should identify and record the degree of any human involvement in the decision-making process and at what stage this takes place_ID.RA-04_GV.RR-02_None_transparency_High_No
6_You should ensure your approach fits both your organisation and the circumstances of your processing. Where appropriate, you should also use risk assessment frameworks_GV.RM-06_ID.RA-05_GV.RM-01_None_High_No
7_You can help to identify the potential risks of your systems by engaging with: independent domain experts who have a deep understanding of the context in which your system will be deployed; and people with lived experience within that context_GV.RR-02_PR.AT-02_ID.RA-01_None_High_No
7_The deployment of an AI system to process personal data needs to be driven by evidence that there is a problem, and a reasoned argument that AI is a sensible solution to that problem_GV.OC-01_GV.RM-01_None_None_High_No
8_You can use a DPIA to document the safeguards you put in place to ensure the individuals responsible for the development, testing, validation, deployment, and monitoring of AI systems are adequately trained_PR.AT-01_PR.AT-02_GV.RR-02_None_High_No
8_Your DPIA can also evidence the organisational measures you have put in place, such as appropriate training, to mitigate risks associated with human error_PR.AT-01_PR.AT-02_ID.RA-01_None_High_No
8_It is important that DPOs or other information governance professionals or both are involved in AI projects from the earliest stages_GV.RR-02_PR.AT-02_None_None_High_No
8_Data protection should not be an afterthought, and a DPO's professional opinion should not come as a surprise at the eleventh hour_GV.RR-01_GV.RR-02_None_None_Medium_Yes
14_Whatever choices you make, you need to be accountable for them. Your efforts should be proportionate to the risks the AI system you are considering to deploy poses to individuals_GV.RR-01_ID.RA-05_None_None_High_No
14_identify and assess any existing or potential trade-offs, when designing or procuring an AI system, and assess the impact it may have on individuals_ID.RA-04; ID.RA-05_GV.RM-06_None_None_High_No
14_consider any techniques which you can implement with a proportionate level of investment and effort; have clear criteria and lines of accountability about the final trade-off decisions_GV.RR-03_GV.RM-06_None_None_High_No
15_You should ensure that any system you procure aligns with what you consider to be the appropriate trade-offs_GV.SC-06_ID.RA-09_GV.SC-05_privacy_High_No
15_Since new risks and compliance considerations may arise during the course of the deployment, you should regularly review any outsourced services_GV.SC-07_ID.RA-07_DE.CM-06_None_High_No
17_Before you begin your processing, you must consider your transparency obligations towards individuals whose personal data you plan to process_GV.OC-03_GV.PO-01_None_transparency_High_No
17_At a high level, you need to include the following in the privacy information: your purposes for processing their personal data; your retention periods for that personal data; and who you will share it with_GV.OC-02_GV.PO-01_None_privacy; transparency_High_No
28_If you collect data directly from individuals, you must provide that privacy information to them at the time you collect it, before you use it to train a model or apply that model on those individuals_GV.OC-02_PR.DS-01_None_privacy_High_No
41_Finally, statistical accuracy is not a static measure. While it is usually measured on static test data, in real life situations AI systems are applied to new and changing populations_ID.RA-07_DE.CM-09_None_None_Medium_Yes