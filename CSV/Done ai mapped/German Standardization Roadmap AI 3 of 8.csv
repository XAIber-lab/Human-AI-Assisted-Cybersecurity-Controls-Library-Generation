1_Safety stands for 'freedom from risk which is not tolerable', risk standing for the 'combination of the probability of occurrence of harm and the severity of that harm' and harm is defined as 'injury or damage to the health of people, or damage to property or the environment'_ID.RA-05_GV.RM-06_GV.RM-02_high_definition
2_The fundamental need for testing and certification of the safety, security and privacy properties of an AI system arises almost naturally from the context of the use of AI systems in existing processes and products and the existing requirements for risk minimization and secure/safe operation in that context_GV.SC-01; ID.RA-09_ID.RA-01_PR.DS-01_high_privacy
2_The task of this chapter is to develop recommendations for action that make it possible to use existing testing and certification models from product safety and IT security for AI systems as sensibly as possible. Also, AI systems should be provides with the possibility to increase their security/safety by means of suitable procedures (controls) and with the possibility to demonstrate an appropriate level of security/safety_ID.IM-02_GV.SC-09_ID.RA-09_high
2_ISO/IEC Guide 51:2014 gives guidance for work on standards and guidelines regarding the inclusion of safety. Work on standards deals with safety aspects in many different forms across a wide range of technologies_GV.PO-01_GV.OC-03_ID.RA-01_medium_definition
2_The debates about the meaning of the topics of safety and security have been and are still being debated in technical regulation and standardization, whereby there is consensus that both topics must be considered and that security is considered a basic prerequisite for safe operation in the sense of safety_GV.PO-01; GV.PO-02_GV.OC-03_ID.RA-01_medium_definition
3_Software itself does not represent a hazard in the sense of safety, but it is decisive and increasingly responsible for the behaviour of technical systems. Software can contribute to the emergence of hazardous situations due to system behaviour_ID.RA-01; ID.RA-04_PR.PS-02_DE.AE-02_high_definition
3_Risk assessment is the first and most important step in planning and evaluating suitable safety measures_ID.RA-05; ID.RA-06_GV.RM-06_GV.SC-07_high
3_Safety is achieved through an iterative process of risk identification, risk assessment and risk reduction. An AI system can play a role in this risk management process in a number of ways_ID.RA-05; GV.RM-06_ID.IM-01_GV.SC-03_high
5_Through this step-by-step refinement, the risk analysis process finally extracts, at the level of AI modules and AI components, target objects with minimum requirements compliance with which is indispensable for the risks of the overall system_ID.RA-05; ID.AM-05_GV.SC-07_ID.RA-04_high
6_In cases of AI directly related to safety, it is essential to examine very closely whether either AI as a functional component possibly increases the level of risk or whether AI as a safeguard component really achieves a necessary risk reduction_ID.RA-04; ID.RA-05_GV.SC-07_ID.AM-08_high
7_AI potentially increases the level of risk by: insufficient understanding of the system, changes to boundary conditions, direct influence on safety functions, changes in human behaviour associated with automation_ID.RA-03; ID.RA-04_PR.AT-01_DE.AE-02_high
7_At higher levels of automation, the person often still acts as a supervisor, with the system then in turn monitoring whether the person is still fulfilling their function as supervisor. AI offers special opportunities in this regard_PR.AT-02; DE.CM-03_PR.AA-05_GV.RR-02_medium
106_Just like IT security, AI security must also be regarded accordingly in terms of time (= over the entire life cycle) and scope (= for all components of the AI system). To stay with the example, a necessary protection against manipulation of the AI system includes protection against manipulation of the trained model and protection against manipulation of the training data_ID.AM-08; PR.DS-01_PR.PS-06_PR.DS-02_high
113_AI systems can harm individuals and groups of individuals, which Muhammad (2022) assigns to different types: allocation errors in that the system withholds or unfairly provides opportunities, resources, or information; service quality errors where the system does not perform similarly for all groups; representation error occurs when the development or use of a system over- or under-represents individual groups; stereotype error is listed, in which the system reproduces and reinforces stereotypes; disparagement error occurs when the system becomes actively derogatory or insulting; process error is the behaviour of a system that makes decisions based on characteristics that should not be relevant to the task_ID.RA-04; GV.OC-03_PR.AT-01_ID.RA-01_high_definition
122_For correctness criteria, the approach of defining test criteria in stages, with each stage building on the next stage down, is appropriate_ID.IM-02; PR.PS-06_ID.RA-09_GV.SC-09_high
122_The test quality considers aspects of the effectiveness of the measures and the correctness of the implementation_ID.IM-01; ID.IM-02_PR.PS-06_GV.OV-03_high
126_For the AI modules contained in the technical system or for the AI components contained in the supply chain, a separate document must specify which requirements which AI module or which AI component expects or must fulfil with regard to which test dimensions_GV.SC-01; GV.SC-05_ID.AM-08_PR.PS-06_high
127_The test specifications address the questions: What should be tested? With which test depth should it be tested?_ID.IM-02; GV.SC-09_PR.PS-06_ID.RA-09_high
136_Risk analysis in this context refers to the complete process of assessing (identifying, estimating and evaluating) risks_ID.RA-05; GV.RM-06_ID.RA-04_GV.SC-07_high_definition
146_The way we work is changing with the introduction of AI applications, and so are the demands on workers. Human attributes such as empathy or emotional dimensions will stand out in skill needs_PR.AT-01; PR.AT-02_GV.RR-04_GV.RR-02_medium_definition
147_There are target criteria for each of these interfaces. In addition, overarching target concepts can be formulated for sociotechnical design. For example, the concept 'adaptivity, human-in-the-loop and human-centred technology' for the human/technology interface could be accompanied by concepts such as 'holistic tasks and sense-making'_PR.AT-02; GV.RR-02_DE.CM-03_PR.AA-05_high
148_When designing AI applications, it must therefore be ensured that they meet sustainability criteria. This results in the requirement for the AI system to be parameterizable with regard to quantitative targets from sustainability specifications_GV.PO-01; ID.AM-08_PR.PS-06_GV.SC-09_high