page_text_First proposal_Second proposal_Third proposal_labels_confidence_definitions
1_When adopting delegated acts pursuant to the first subparagraph concerning artificial intelligence systems which are safety components within the meaning of Regulation (EU) 2024/... of the European Parliament and of the Council*+, the requirements set out in Chapter III, Section 2, of that Regulation shall be taken into account._GV.OC-03_GV.PO-01_GV.RR-02__medium_no
2_When adopting delegated acts pursuant to the first subparagraph concerning Artificial Intelligence systems which are safety components within the meaning of Regulation (EU) 2024/… of the European Parliament and of the Council*+, the requirements set out in Chapter III, Section 2, of that Regulation shall be taken into account._GV.OC-03_GV.PO-01_GV.RR-02__medium_no
3_For Artificial Intelligence systems which are safety components within the meaning of Regulation (EU) 2024/… of the European Parliament and of the Council*+, when carrying out its activities pursuant to paragraph 1 and when adopting technical specifications and testing standards in accordance with paragraphs 2 and 3, the Commission shall take into account the requirements set out in Chapter III, Section 2, of that Regulation._GV.OC-03_GV.PO-01_GV.RR-02__high_no
4_When adopting delegated acts pursuant to paragraph 1 and implementing acts pursuant to paragraph 11 concerning Artificial Intelligence systems which are safety components within the meaning of Regulation (EU) 2024/... of the European Parliament and of the Council*+, the requirements set out in Chapter III, Section 2, of that Regulation shall be taken into account._GV.OC-03_GV.PO-01_GV.RR-02__medium_no
5_When adopting delegated acts pursuant to paragraph 3 concerning Artificial Intelligence systems which are safety components within the meaning of Regulation (EU) 2024/… of the European Parliament and of the Council*+, the requirements set out in Chapter III, Section 2, of that Regulation shall be taken into account._GV.OC-03_GV.PO-01_GV.RR-02__medium_no
10_The Commission shall assess the need for amendment of the list set out in Annex III and of the list of prohibited AI practices laid down in Article 5, once a year following the entry into force of this Regulation, and until the end of the period of the delegation of power laid down in Article 97._GV.OV-01; GV.OV-02_ID.RA-05_GV.PO-02__high_no
11_Without prejudice to the application of Article 5 as referred to in Article 113(3), point (a), AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex X that have been placed on the market or put into service before ... [36 months from the date of entry into force of this Regulation] shall be brought into compliance with this Regulation by 31 December 2030._ID.AM-08_PR.PS-01_GV.PO-02__high_no
11_The requirements laid down in this Regulation shall be taken into account in the evaluation of each large-scale IT system established by the legal acts listed in Annex X to be undertaken as provided for in those legal acts and where those legal acts are replaced or amended._GV.OC-03_ID.RA-05_GV.PO-02__high_no
11_The providers and deployers of high-risk AI systems intended to be used by public authorities shall take the necessary steps to comply with the requirements and obligations of this Regulation by …[ six years from the date of entry into force of this Regulation]._GV.OC-03_GV.RR-02_ID.AM-08__high_no
11_Providers of general-purpose AI models that have been placed on the market before … [12 months from the date of entry into force of this Regulation] shall take the necessary steps in order to comply with the obligations laid down in this Regulation by … [36 months from the date of entry into force of this Regulation]._GV.OC-03_GV.RR-02_ID.AM-08__high_no
12_the need for amendments extending existing area headings or adding new area headings in Annex III_GV.OV-02_GV.PO-02___low_no
12_amendments to the list of AI systems requiring additional transparency measures in Article 50_GV.OV-02_GV.PO-02_PR.AT-01_transparency_medium_no
12_amendments enhancing the effectiveness of the supervision and governance system._GV.OV-03_GV.RR-02___medium_no
12_The report shall include an assessment with regard to the structure of enforcement and the possible need for a Union agency to resolve any identified shortcomings._GV.OV-03_GV.RR-02___low_no
13_cybersecurity measures put in place_PR.DS-01; PR.DS-02_PR.IR-01___high_no
24_Biometrics, in so far as their use is permitted under relevant Union or national law_GV.OC-03_PR.AA-01___low_definition
24_remote biometric identification systems_PR.AA-01_PR.AA-02___low_definition
24_AI systems intended to be used for biometric categorisation, according to sensitive or protected attributes or characteristics based on the inference of those attributes or characteristics_PR.AA-01_PR.AA-02_GV.OC-03_privacy_medium_definition
24_AI systems intended to be used for emotion recognition._PR.AA-01_PR.AA-02___low_definition
25_Critical infrastructure: AI systems intended to be used as safety components in the management and operation of critical digital infrastructure, road traffic, or in the supply of water, gas, heating or electricity._ID.AM-05_PR.IR-01___medium_definition
25_Education and vocational training: (a) AI systems intended to be used to determine access or admission or to assign natural persons to educational and vocational training institutions at all levels_PR.AA-01_GV.OC-03___medium_definition
25_AI systems intended to be used to evaluate learning outcomes, including when those outcomes are used to steer the learning process of natural persons in educational and vocational training institutions at all levels_ID.RA-05_GV.OC-03___medium_definition
25_AI systems intended to be used for the purpose of assessing the appropriate level of education that an individual will receive or will be able to access, in the context of or within educational and vocational training institutions at all levels_ID.RA-05_GV.OC-03___medium_definition
25_AI systems intended to be used for monitoring and detecting prohibited behaviour of students during tests in the context of or within educational and vocational training institutions at all levels._DE.CM-03_PR.AT-02___medium_definition
26_AI systems intended to be used for the recruitment or selection of natural persons, in particular to place targeted job advertisements, to analyse and filter job applications, and to evaluate candidates_ID.RA-05_PR.AA-01___medium_definition
26_AI systems intended to be used to make decisions affecting terms of work-related relationships, the promotion or termination of work-related contractual relationships, to allocate tasks based on individual behaviour or personal traits or characteristics or to monitor and evaluate the performance and behaviour of persons in such relationships._DE.CM-03_PR.AA-01_GV.RR-02__high_no
26_AI systems intended to be used by public authorities or on behalf of public authorities to evaluate the eligibility of natural persons for essential public assistance benefits and services, including healthcare services, as well as to grant, reduce, revoke, or reclaim such benefits and services_ID.RA-05_PR.AA-01_GV.OC-03__high_no
26_AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems used for the purpose of detecting financial fraud_ID.RA-05_PR.AA-01___medium_definition
27_AI systems intended to be used for risk assessment and pricing in relation to natural persons in the case of life and health insurance_ID.RA-05_PR.AA-01___medium_definition
27_AI systems intended to evaluate and classify emergency calls by natural persons or to be used to dispatch, or to establish priority in the dispatching of, emergency first response services, including by police, firefighters and medical aid, as well as of emergency healthcare patient triage systems._ID.RA-05_RS.MA-03___high_no
27_Law enforcement, in so far as their use is permitted under relevant Union or national law_GV.OC-03_PR.AA-01___low_definition
27_AI systems intended to be used by or on behalf of law enforcement authorities, or by Union institutions, bodies, offices or agencies in support of law enforcement authorities or on their behalf to assess the risk of a natural person becoming the victim of criminal offences_ID.RA-05_PR.AA-01_GV.OC-03__medium_definition
27_AI systems intended to be used by or on behalf of law enforcement authorities or by Union institutions, bodies, offices or agencies in support of law enforcement authorities as polygraphs or similar tools_ID.RA-05_PR.AA-01_GV.OC-03__medium_definition
28_AI systems intended to be used by or on behalf of law enforcement authorities to evaluate the reliability of evidence in the course of the investigation or prosecution of criminal offences_ID.RA-05_RS.AN-03___medium_definition
28_AI systems intended to be used by law enforcement authorities or on their behalf or by Union institutions, bodies, offices or agencies in support of law enforcement authorities for assessing the risk of a natural person offending or re-offending not solely on the basis of the profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680, or to assess personality traits and characteristics or past criminal behaviour of natural persons or groups_ID.RA-05_PR.AA-01_GV.OC-03__high_no
28_AI systems intended to be used by or on behalf of law enforcement authorities or by Union institutions, bodies, offices or agencies in support of law enforcement authorities for the profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 in the course of the detection, investigation or prosecution of criminal offences._ID.RA-05_PR.AA-01_GV.OC-03__high_no
29_Migration, asylum and border control management, in so far as their use is permitted under relevant Union or national law_GV.OC-03_PR.AA-01___low_definition
29_AI systems intended to be used by or on behalf of competent public authorities or by Union institutions, bodies, offices or agencies as polygraphs or similar tools_ID.RA-05_PR.AA-01_GV.OC-03__medium_definition
29_AI systems intended to be used by or on behalf of competent public authorities or by Union institutions, bodies, offices or agencies to assess a risk, including a security risk, a risk of irregular migration, or a health risk, posed by a natural person who intends to enter or who has entered into the territory of a Member State_ID.RA-05_PR.AA-01_GV.OC-03__high_no
29_AI systems intended to be used by or on behalf of competent public authorities or by Union institutions, bodies, offices or agencies to assist competent public authorities for the examination of applications for asylum, visa or residence permits and for associated complaints with regard to the eligibility of the natural persons applying for a status, including related assessments of the reliability of evidence_ID.RA-05_RS.AN-03_GV.OC-03__high_no
29_AI systems intended to be used by or on behalf of competent public authorities, or by Union institutions, bodies, offices or agencies, in the context of migration, asylum or border control management, for the purpose of detecting, recognising or identifying natural persons, with the exception of the verification of travel documents._PR.AA-01; PR.AA-02_ID.RA-05_GV.OC-03__high_no
30_Administration of justice and democratic processes_GV.OC-03_GV.RR-02___low_definition
30_AI systems intended to be used by a judicial authority or on their behalf to assist a judicial authority in researching and interpreting facts and the law and in applying the law to a concrete set of facts, or to be used in a similar way in alternative dispute resolution_ID.RA-05_RS.AN-03_GV.OC-03__medium_definition
30_AI systems intended to be used for influencing the outcome of an election or referendum or the voting behaviour of natural persons in the exercise of their vote in elections or referenda. This does not include AI systems to the output of which natural persons are not directly exposed, such as tools used to organise, optimise or structure political campaigns from an administrative or logistical point of view._ID.RA-05_GV.OC-03___high_no
31_The technical documentation referred to in Article 11(1) shall contain at least the following information, as applicable to the relevant AI system_ID.AM-08_GV.PO-01___medium_no
31_A general description of the AI system including: its intended purpose, the name of the provider and the version of the system reflecting its relation to previous versions_ID.AM-02_ID.AM-08___high_no
31_how the AI system interacts with, or can be used to interact with, hardware or software, including with other AI systems, that are not part of the AI system itself, where applicable_ID.AM-03_ID.AM-02___high_no
31_the versions of relevant software or firmware, and any requirements related to version updates_ID.AM-02_PR.PS-02___high_no
31_the description of all the forms in which the AI system is placed on the market or put into service, such as software packages embedded into hardware, downloads, or APIs_ID.AM-02_ID.AM-08___high_no
32_the description of the hardware on which the AI system is intended to run_ID.AM-01_ID.AM-02___high_no
32_where the AI system is a component of products, photographs or illustrations showing external features, the marking and internal layout of those products_ID.AM-01_ID.AM-02___high_no
32_a basic description of the user-interface provided to the deployer_ID.AM-02_PR.AA-01___high_no
32_instructions for use for the deployer, and a basic description of the user-interface provided to the deployer, where applicable_PR.AT-01_PR.AT-02___high_no
32_A detailed description of the elements of the AI system and of the process for its development, including: the methods and steps performed for the development of the AI system, including, where relevant, recourse to pre-trained systems or tools provided by third parties and how those were used, integrated or modified by the provider_ID.AM-02_ID.AM-08_PR.PS-06__high_no
32_the design specifications of the system, namely the general logic of the AI system and of the algorithms; the key design choices including the rationale and assumptions made, including with regard to persons or groups of persons in respect of who, the system is intended to be used; what the system is designed to optimise for, and the relevance of the different parameters; the description of the expected output and output quality of the system; the decisions about any possible trade-off made regarding the technical solutions adopted to comply with the requirements set out in Chapter III, Section 2_ID.AM-02_ID.AM-08_PR.PS-06__high_no
33_the description of the system architecture explaining how software components build on or feed into each other and integrate into the overall processing; the computational resources used to develop, train, test and validate the AI system_ID.AM-02_ID.AM-08___high_no
33_where relevant, the data requirements in terms of datasheets describing the training methodologies and techniques and the training data sets used, including a general description of these data sets, information about their provenance, scope and main characteristics; how the data was obtained and selected; labelling procedures (e.g. for supervised learning), data cleaning methodologies (e.g. outliers detection)_ID.AM-07_PR.DS-01_PR.DS-02__